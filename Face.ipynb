{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Define S3 bucket and key\n",
    "bucket_name = 'facial-detection054037105643'\n",
    "key = 'nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4'\n",
    "output_file = 'downloaded_video.mp4'  # or any name you prefer\n",
    "\n",
    "# Create S3 client (will use your AWS credentials)\n",
    "\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=\"AKIAQZFG4ZPVTUOX4FGC\",\n",
    "    aws_secret_access_key=\"MsFm8xTr1LKtpMy+844DkWaTc9ZezHXXRlcH7gPw\"\n",
    ")\n",
    "\n",
    "\n",
    "# Download the file\n",
    "s3.download_file(bucket_name, key, key)\n",
    "\n",
    "print(f\"Download complete: {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall insightface -y\n",
    "!pip uninstall opencv-python -y\n",
    "!pip uninstall opencv-python-headless -y\n",
    "!pip uninstall onnxruntime-gpu -y\n",
    "!pip uninstall ultralytics -y\n",
    "!pip install insightface\n",
    "!pip install opencv-python\n",
    "!pip install opencv-python-headless\n",
    "!pip install onnxruntime-gpu\n",
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_database_builder.py\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "import re\n",
    "# Initialize the face analysis model\n",
    "# app = FaceAnalysis(name=os.path.join(model_dir, \"buffalo_m\"), providers=['CUDAExecutionProvider'])\n",
    "app = FaceAnalysis(\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "app.prepare(ctx_id=0)\n",
    "# # Get default det_size from model\n",
    "# det_size = app.models['detection'].input_shape[2:]  # (w, h)\n",
    "# print(app.det_size[0])\n",
    "# Directory of known people\n",
    "KNOWN_FACES_DIR = \"known_faces\"  # each image should be named like \"Alice.jpg\", \"Bob.jpg\"\n",
    "face_database = []\n",
    "\n",
    "# Iterate through known face images\n",
    "for filename in os.listdir(KNOWN_FACES_DIR):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        name = os.path.splitext(filename)[0]\n",
    "        print(\"name\",name)\n",
    "        name = re.sub(r'\\(.*?\\)', '', filename)\n",
    "        print(\"name again\",name)\n",
    "        img_path = os.path.join(KNOWN_FACES_DIR, filename)\n",
    "        print(\"image path\",img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        # Resize image to match det_size\n",
    "        # resized_image = cv2.resize(image, det_size, interpolation=cv2.INTER_LINEAR)\n",
    "        if image is None:\n",
    "          print(f\"❌ Could not read image: {img_path}\")\n",
    "          continue\n",
    "        else:\n",
    "            # image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            faces = app.get(image)\n",
    "            if faces:\n",
    "                embedding = faces[0].embedding  # take the first face\n",
    "                face_database.append((name, embedding))\n",
    "            else:\n",
    "                print(f\"No face found in {filename}!\")\n",
    "\n",
    "# Save database to disk if needed\n",
    "# Use pickle to save for future use\n",
    "import pickle\n",
    "with open(\"face_database.pkl\", \"wb\") as f:\n",
    "    pickle.dump(face_database, f)\n",
    "\n",
    "print(\"✅ Face database created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "import re\n",
    "import pickle\n",
    " \n",
    "import re\n",
    " \n",
    "def clean_name(filename: str) -> str:\n",
    "    # Remove extension\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    # Remove anything in parentheses e.g. (1), (2) etc.\n",
    "    name = re.sub(r'\\(.*?\\)', '', name)\n",
    "    # Replace multiple spaces/dashes with a single space-dash-space\n",
    "    name = re.sub(r'\\s*-\\s*', ' - ', name)   # normalize \" - \"\n",
    "    # Remove extra spaces\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    " \n",
    "# Initialize the face analysis model\n",
    "app = FaceAnalysis(\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "app.prepare(ctx_id=0)\n",
    " \n",
    "# Directory of known people\n",
    "KNOWN_FACES_DIR = \"known_faces_nandhyala\"  # each image should be named like \"Alice.jpg\", \"Bob.jpg\"\n",
    "face_database = []\n",
    " \n",
    "# Iterate through known face images\n",
    "for filename in os.listdir(KNOWN_FACES_DIR):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        person_name = clean_name(filename)\n",
    "        print(f\"Processing: {filename} → Person: {person_name}\")\n",
    " \n",
    "        img_path = os.path.join(KNOWN_FACES_DIR, filename)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"❌ Could not read image: {img_path}\")\n",
    "            continue\n",
    " \n",
    "        faces = app.get(image)\n",
    "        if faces:\n",
    "            embedding = faces[0].embedding\n",
    "            face_database.append((person_name, embedding))\n",
    "        else:\n",
    "            print(f\"No face found in {filename}!\")\n",
    "# Save database to disk\n",
    "with open(\"face_database_nandhyala_large.pkl\", \"wb\") as f:\n",
    "    pickle.dump(face_database, f)\n",
    " \n",
    "print(\"✅ Face database created and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483be762",
   "metadata": {},
   "source": [
    "pickle file generation for the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "import re\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "def clean_name(filename: str) -> str:\n",
    "    # Remove extension\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    # Remove anything in parentheses e.g. (1), (2) etc.\n",
    "    name = re.sub(r'\\(.*?\\)', '', name)\n",
    "    # Replace multiple spaces/dashes with a single space-dash-space\n",
    "    name = re.sub(r'\\s*-\\s*', ' - ', name)   # normalize \" - \"\n",
    "    # Remove extra spaces\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "def get_role(name: str) -> str:\n",
    "    if \"supervisor\" in name.lower():\n",
    "        return \"Supervisor\"\n",
    "    elif \"worker\" in name.lower():\n",
    "        return \"Hamali\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def generate_hash_id(name: str) -> str:\n",
    "    # Generate stable hash based on cleaned name\n",
    "    return hashlib.md5(name.lower().encode()).hexdigest()[:8]  # short 8-char hash\n",
    "\n",
    "# Initialize the face analysis model\n",
    "app = FaceAnalysis(\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "app.prepare(ctx_id=0)\n",
    "\n",
    "# Directory of known people\n",
    "KNOWN_FACES_DIR = \"known_faces\"\n",
    "face_database = []\n",
    "\n",
    "# Cache to avoid regenerating hash IDs for same names\n",
    "name_to_hash = {}\n",
    "\n",
    "# Iterate through known face images\n",
    "for filename in os.listdir(KNOWN_FACES_DIR):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        person_name = clean_name(filename)\n",
    "        print(f\"Processing: {filename} → Person: {person_name}\")\n",
    "\n",
    "        if person_name not in name_to_hash:\n",
    "            name_to_hash[person_name] = generate_hash_id(person_name)\n",
    "\n",
    "        unique_id = name_to_hash[person_name]\n",
    "        role = get_role(person_name)\n",
    "\n",
    "        img_path = os.path.join(KNOWN_FACES_DIR, filename)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"❌ Could not read image: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        faces = app.get(image)\n",
    "        if faces:\n",
    "            embedding = faces[0].embedding\n",
    "            face_database.append((unique_id, person_name, role, embedding))\n",
    "        else:\n",
    "            print(f\"No face found in {filename}!\")\n",
    "\n",
    "# Save database to disk\n",
    "with open(\"face_database.pkl\", \"wb\") as f:\n",
    "    pickle.dump(face_database, f)\n",
    "\n",
    "print(\"✅ Face database created and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec1adb",
   "metadata": {},
   "source": [
    "code without Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# Set timezone to IST\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "# Initialize face recognition model\n",
    "# face_app = FaceAnalysis(name=os.path.join(model_dir, \"buffalo_m\"), providers=['CUDAExecutionProvider'])\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "face_app.prepare(ctx_id=0)\n",
    "\n",
    "# Load face database\n",
    "with open(\"/content/face_database.pkl\", \"rb\") as f:\n",
    "    face_db_list = pickle.load(f)\n",
    "\n",
    "names, embeddings = zip(*face_db_list)\n",
    "names = np.array(names)\n",
    "embeddings = np.stack(embeddings)\n",
    "\n",
    "# Similarity threshold\n",
    "SIMILARITY_THRESHOLD = 0.40\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "model.to('cuda')\n",
    "\n",
    "# Prepare output directory for crops\n",
    "os.makedirs(\"id_frames\", exist_ok=True)\n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now(ist)\n",
    "print(\"Start Time (IST):\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# Video setup\n",
    "video_path = \"/content/gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "output_fps = fps / 5  # Adjust for skipping every other frame\n",
    "out = cv2.VideoWriter(\n",
    "    \"gudivada+yolo+v8l+ReIDON+timestamps.avi\",\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    output_fps,\n",
    "    (width, height)\n",
    ")\n",
    "\n",
    "# ID → Name map\n",
    "id_name_map = {}\n",
    "frame_count = 0\n",
    "\n",
    "# Logging\n",
    "entry_log = set()\n",
    "entry_data = []\n",
    "\n",
    "# Store bounding boxes for authorized & unknown IDs\n",
    "id_bboxes = {}\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        break   # stop if no frame is returned\n",
    "\n",
    "    # # create clean copy before drawing\n",
    "    # raw_frame = frame.copy()\n",
    "\n",
    "    raw_frame = frame.copy()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        tracker=\"botsort.yaml\",\n",
    "        persist=True,\n",
    "        classes=[0],  # person only\n",
    "        conf=0.5,\n",
    "        iou=0.8,\n",
    "        verbose=False\n",
    "    )\n",
    "    if frame_count%5!=0:\n",
    "        # out.write(frame)\n",
    "        frame_count+=1\n",
    "        continue\n",
    "\n",
    "    if results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            tid = int(box.id[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            dx, dy = 5, 0\n",
    "            new_x1, new_y1 = x1 + dx, y1 + dy\n",
    "            new_x2, new_y2 = x2 - dx, y2 - dy\n",
    "\n",
    "            if h < 100:\n",
    "                draw_y2 = new_y2\n",
    "            else:\n",
    "                face_ratio = 0.2 if h > 450 else 0.5\n",
    "                draw_y2 = y1 + int(h * face_ratio)\n",
    "\n",
    "            # Ensure valid crop\n",
    "            face_crop = frame[new_y1:draw_y2, new_x1:new_x2]\n",
    "\n",
    "            if tid not in id_name_map or id_name_map[tid] in ['Unknown', 'No face']:\n",
    "                faces = face_app.get(face_crop)\n",
    "                if len(faces) > 0 and faces[0]['det_score'] > 0.55:\n",
    "                    emb = faces[0]['embedding']\n",
    "                    sims = cosine_similarity([emb], embeddings)[0]\n",
    "                    best_idx = sims.argmax()\n",
    "                    best_score = sims[best_idx]\n",
    "                    best_match = names[best_idx].replace(\"jpg\", \"\")\n",
    "                    if best_score >= SIMILARITY_THRESHOLD:\n",
    "                        id_name_map[tid] = best_match\n",
    "                    else:\n",
    "                        id_name_map[tid] = \"Unknown\"\n",
    "                else:\n",
    "                    id_name_map[tid] = \"No face\"\n",
    "\n",
    "            # # Logging\n",
    "            # name_to_display = id_name_map[tid]\n",
    "            # timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            # timestamp = str(timedelta(milliseconds=timestamp_ms)).split(\".\")[0]\n",
    "\n",
    "            # if f\"{tid}-{name_to_display}\" not in entry_log:\n",
    "            #     entry_log.add(f\"{tid}-{name_to_display}\")\n",
    "            #     if name_to_display != \"Unknown\" and name_to_display != \"No face\":\n",
    "            #         entry_data.append({\n",
    "            #             \"name\": name_to_display,\n",
    "            #             \"status\": \"entered\",\n",
    "            #             \"timestamp\": timestamp\n",
    "            #         })\n",
    "            #     elif name_to_display == \"Unknown\":\n",
    "            #         entry_data.append({\n",
    "            #             \"name\": \"Unknown\",\n",
    "            #             \"status\": \"unauthorized\",\n",
    "            #             \"timestamp\": timestamp\n",
    "            #         })\n",
    "\n",
    "            # ✅ Store bounding boxes and save crop for first occurrence\n",
    "\n",
    "            # if name_to_display != \"No face\":\n",
    "            #     if tid not in id_bboxes:\n",
    "            #         # first occurrence → save it\n",
    "            #         id_bboxes[tid] = {\n",
    "            #             \"frame\": frame_count,\n",
    "            #             \"bbox\": [x1, y1, x2, y2],\n",
    "            #             \"name\": name_to_display\n",
    "            #         }\n",
    "\n",
    "            #         # Save crop directly into id_frames folder\n",
    "            #         crop = raw_frame[y1:y2, x1:x2]\n",
    "            #         if crop.size != 0:\n",
    "            #             cv2.imwrite(f\"id_frames/id_{tid}_{name_to_display}.jpg\", crop)\n",
    "\n",
    "            #     else:\n",
    "            #         # if already stored but name is \"Unknown\" or \"No face\", update with new name\n",
    "            #         if id_bboxes[tid][\"name\"] in [\"Unknown\", \"No face\"] and name_to_display not in [\"Unknown\", \"No face\"]:\n",
    "            #             id_bboxes[tid][\"name\"] = name_to_display\n",
    "            #             id_bboxes[tid][\"frame\"] = frame_count\n",
    "            #             id_bboxes[tid][\"bbox\"] = [x1, y1, x2, y2]\n",
    "\n",
    "            #             # Save crop directly into id_frames folder\n",
    "            #             crop = raw_frame[y1:y2, x1:x2]\n",
    "            #             if crop.size != 0:\n",
    "            #                 cv2.imwrite(f\"id_frames/id_{tid}_{name_to_display}.jpg\", crop)\n",
    "\n",
    "    #         # Draw box\n",
    "    #         if name_to_display == \"No face\":\n",
    "    #             color = (0, 255, 0)\n",
    "    #             label = f\"No face (ID:{tid})\"\n",
    "    #         elif name_to_display != \"Unknown\":\n",
    "    #             color = (255, 0, 0)\n",
    "    #             label = f\"{name_to_display} (ID:{tid})\"\n",
    "    #         else:\n",
    "    #             color = (0, 0, 255)\n",
    "    #             label = f\"Unknown (ID:{tid})\"\n",
    "\n",
    "    #         cv2.rectangle(frame, (new_x1, new_y1), (new_x2, new_y2), color, 2)\n",
    "    #         cv2.putText(frame, label, (new_x1, new_y1 - 10),\n",
    "    #                     cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # out.write(frame)\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "# out.release()\n",
    "\n",
    "# End time\n",
    "end_time = datetime.now(ist)\n",
    "print(\"End Time (IST):\", end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "print(\"Execution Time (seconds):\", execution_time)\n",
    "print(\"Execution Time (minutes):\", execution_time / 60)\n",
    "\n",
    "# Save ID-name map & entry log\n",
    "with open(\"id_name_map.json\", \"w\") as f:\n",
    "    json.dump(id_name_map, f, indent=2)\n",
    "\n",
    "with open(\"entry_log.json\", \"w\") as f:\n",
    "    json.dump(entry_data, f, indent=2)\n",
    "\n",
    "# # Save filtered bounding boxes\n",
    "# with open(\"id_bboxes.json\", \"w\") as f:\n",
    "#     json.dump(id_bboxes, f, indent=4)\n",
    "\n",
    "# print(f\"✅ Saved video, crops in 'id_frames/', id_name_map.json, entry_log.json, and id_bboxes.json\")\n",
    "print(f\"✅ Saved video, crops in id_name_map.json, entry_log.json\")\n",
    "print(f\"Number of stored IDs: {len(id_bboxes)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a0520",
   "metadata": {},
   "source": [
    "Code with Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d8ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime\n",
    "import faiss\n",
    "import time\n",
    "# Set timezone to IST\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "# Initialize face recognition model\n",
    "# face_app = FaceAnalysis(name=os.path.join(model_dir, \"buffalo_m\"), providers=['CUDAExecutionProvider'])\n",
    "\n",
    "\n",
    "# Measure Buffalo Model Loading Time\n",
    "print(\"Loading Buffalo Model...\")\n",
    "buffalo_start = time.time()\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "face_app.prepare(ctx_id=0)\n",
    "buffalo_end = time.time()\n",
    "buffalo_loading_time = buffalo_end - buffalo_start\n",
    "print(f\"Buffalo Model loaded in: {buffalo_loading_time:.3f} seconds\")\n",
    "\n",
    "# Load face database\n",
    "with open(\"face_database_nandhyala.pkl\", \"rb\") as f:\n",
    "    face_db_list = pickle.load(f)\n",
    "\n",
    "names, embeddings = zip(*face_db_list)\n",
    "names = np.array(names)\n",
    "embeddings = np.stack(embeddings).astype('float32')  # FAISS requires float32\n",
    " \n",
    "# Build FAISS index for cosine similarity\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product for cosine similarity\n",
    "faiss.normalize_L2(embeddings)  # Normalize embeddings for cosine similarity\n",
    "index.add(embeddings)  # Add embeddings to the index\n",
    "\n",
    "# Similarity threshold\n",
    "SIMILARITY_THRESHOLD = 0.40\n",
    "\n",
    "# Measure YOLO Model Loading Time\n",
    "print(\"Loading YOLO Model...\")\n",
    "yolo_start = time.time()\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "model.to('cuda')\n",
    "yolo_end = time.time()\n",
    "yolo_loading_time = yolo_end - yolo_start\n",
    "print(f\"YOLO Model loaded in: {yolo_loading_time:.3f} seconds\")\n",
    "\n",
    "\n",
    "# Prepare output directory for crops\n",
    "os.makedirs(\"id_frames\", exist_ok=True)\n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now(ist)\n",
    "print(\"Start Time (IST):\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# Video setup\n",
    "video_path = \"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "output_fps = fps / 5  # Adjust for skipping every other frame\n",
    "out = cv2.VideoWriter(\n",
    "    \"gudivada+yolo+v8l+ReIDON+timestamps.avi\",\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    output_fps,\n",
    "    (width, height)\n",
    ")\n",
    "\n",
    "# ID → Name map\n",
    "id_name_map = {}\n",
    "frame_count = 0\n",
    "\n",
    "# Logging\n",
    "entry_log = set()\n",
    "entry_data = []\n",
    "\n",
    "# Store bounding boxes for authorized & unknown IDs\n",
    "id_bboxes = {}\n",
    "# Sets to store unique IDs\n",
    "skipped_ids_set = set()\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break   # stop if no frame is returned\n",
    "    if frame_count%3!=0:\n",
    "        # out.write(frame)\n",
    "        frame_count+=1\n",
    "        continue\n",
    "    \n",
    "\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        tracker=\"botsort_1.yaml\",\n",
    "        persist=True,\n",
    "        classes=[0],  # person only\n",
    "        conf=0.5,\n",
    "        iou=0.8,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "\n",
    "    if results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            skipped_ids_set.add(tid)\n",
    "            tid = int(box.id[0])\n",
    "            \n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            dx, dy = 5, 0\n",
    "            new_x1, new_y1 = x1 + dx, y1 + dy\n",
    "            new_x2, new_y2 = x2 - dx, y2 - dy\n",
    "\n",
    "            if h < 100:\n",
    "                draw_y2 = new_y2\n",
    "            else:\n",
    "                face_ratio = 0.2 if h > 450 else 0.5\n",
    "                draw_y2 = y1 + int(h * face_ratio)\n",
    "\n",
    "            # Ensure valid crop\n",
    "            face_crop = frame[new_y1:draw_y2, new_x1:new_x2]\n",
    "\n",
    "            if tid not in id_name_map or id_name_map[tid] in ['Unknown', 'No face']:\n",
    "                faces = face_app.get(face_crop)\n",
    "                if len(faces) > 0 and faces[0]['det_score'] > 0.55:\n",
    "                    emb = faces[0]['embedding'].astype('float32')\n",
    "                    faiss.normalize_L2(emb.reshape(1, -1))  # Normalize query embedding\n",
    "                    scores, indices = index.search(emb.reshape(1, -1), 1)  # Search top-1\n",
    "                    best_score = scores[0][0]\n",
    "                    best_idx = indices[0][0]\n",
    "                    best_match = names[best_idx].replace(\"jpg\", \"\")\n",
    "                    if best_score >= SIMILARITY_THRESHOLD:\n",
    "                        id_name_map[tid] = best_match\n",
    "                    else:\n",
    "                        id_name_map[tid] = \"Unknown\"\n",
    "                else:\n",
    "                    id_name_map[tid] = \"No face\"\n",
    "            # # Logging\n",
    "            # name_to_display = id_name_map[tid]\n",
    "            # timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            # timestamp = str(timedelta(milliseconds=timestamp_ms)).split(\".\")[0]\n",
    "\n",
    "            # if f\"{tid}-{name_to_display}\" not in entry_log:\n",
    "            #     entry_log.add(f\"{tid}-{name_to_display}\")\n",
    "            #     if name_to_display != \"Unknown\" and name_to_display != \"No face\":\n",
    "            #         entry_data.append({\n",
    "            #             \"name\": name_to_display,\n",
    "            #             \"status\": \"entered\",\n",
    "            #             \"timestamp\": timestamp\n",
    "            #         })\n",
    "            #     elif name_to_display == \"Unknown\":\n",
    "            #         entry_data.append({\n",
    "            #             \"name\": \"Unknown\",\n",
    "            #             \"status\": \"unauthorized\",\n",
    "            #             \"timestamp\": timestamp\n",
    "            #         })\n",
    "\n",
    "            # ✅ Store bounding boxes and save crop for first occurrence\n",
    "\n",
    "            # if name_to_display != \"No face\":\n",
    "            #     if tid not in id_bboxes:\n",
    "            #         # first occurrence → save it\n",
    "            #         id_bboxes[tid] = {\n",
    "            #             \"frame\": frame_count,\n",
    "            #             \"bbox\": [x1, y1, x2, y2],\n",
    "            #             \"name\": name_to_display\n",
    "            #         }\n",
    "\n",
    "            #         # Save crop directly into id_frames folder\n",
    "            #         crop = raw_frame[y1:y2, x1:x2]\n",
    "            #         if crop.size != 0:\n",
    "            #             cv2.imwrite(f\"id_frames/id_{tid}_{name_to_display}.jpg\", crop)\n",
    "\n",
    "            #     else:\n",
    "            #         # if already stored but name is \"Unknown\" or \"No face\", update with new name\n",
    "            #         if id_bboxes[tid][\"name\"] in [\"Unknown\", \"No face\"] and name_to_display not in [\"Unknown\", \"No face\"]:\n",
    "            #             id_bboxes[tid][\"name\"] = name_to_display\n",
    "            #             id_bboxes[tid][\"frame\"] = frame_count\n",
    "            #             id_bboxes[tid][\"bbox\"] = [x1, y1, x2, y2]\n",
    "\n",
    "            #             # Save crop directly into id_frames folder\n",
    "            #             crop = raw_frame[y1:y2, x1:x2]\n",
    "            #             if crop.size != 0:\n",
    "            #                 cv2.imwrite(f\"id_frames/id_{tid}_{name_to_display}.jpg\", crop)\n",
    "\n",
    "    #         # Draw box\n",
    "    #         if name_to_display == \"No face\":\n",
    "    #             color = (0, 255, 0)\n",
    "    #             label = f\"No face (ID:{tid})\"\n",
    "    #         elif name_to_display != \"Unknown\":\n",
    "    #             color = (255, 0, 0)\n",
    "    #             label = f\"{name_to_display} (ID:{tid})\"\n",
    "    #         else:\n",
    "    #             color = (0, 0, 255)\n",
    "    #             label = f\"Unknown (ID:{tid})\"\n",
    "\n",
    "    #         cv2.rectangle(frame, (new_x1, new_y1), (new_x2, new_y2), color, 2)\n",
    "    #         cv2.putText(frame, label, (new_x1, new_y1 - 10),\n",
    "    #                     cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # out.write(frame)\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# End time\n",
    "end_time = datetime.now(ist)\n",
    "print(\"End Time (IST):\", end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "print(\"Execution Time (seconds):\", execution_time)\n",
    "print(\"Execution Time (minutes):\", execution_time / 60)\n",
    "\n",
    "# Save ID-name map & entry log\n",
    "with open(\"id_name_map.json\", \"w\") as f:\n",
    "    json.dump(id_name_map, f, indent=2)\n",
    "\n",
    "with open(\"entry_log.json\", \"w\") as f:\n",
    "    json.dump(entry_data, f, indent=2)\n",
    "\n",
    "# # Save filtered bounding boxes\n",
    "# with open(\"id_bboxes.json\", \"w\") as f:\n",
    "#     json.dump(id_bboxes, f, indent=4)\n",
    "\n",
    "# print(f\"✅ Saved video, crops in 'id_frames/', id_name_map.json, entry_log.json, and id_bboxes.json\")\n",
    "print(f\"✅ Saved video, crops in id_name_map.json, entry_log.json\")\n",
    "print(f\"Number of stored IDs: {len(id_bboxes)}\")\n",
    "print(len(skipped_ids_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7980a366",
   "metadata": {},
   "source": [
    "code with faiss (brute force) & parallel crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import faiss\n",
    "\n",
    "# Set timezone to IST\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "# Initialize face recognition model\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "face_app.prepare(ctx_id=0)\n",
    "\n",
    "# Load face database\n",
    "with open(\"/content/face_database.pkl\", \"rb\") as f:\n",
    "    face_db_list = pickle.load(f)\n",
    "\n",
    "names, embeddings = zip(*face_db_list)\n",
    "names = np.array(names)\n",
    "embeddings = np.stack(embeddings).astype('float32')  # FAISS requires float32\n",
    "\n",
    "# Build FAISS index for cosine similarity\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product for cosine similarity\n",
    "faiss.normalize_L2(embeddings)  # Normalize embeddings for cosine similarity\n",
    "index.add(embeddings)  # Add embeddings to the index\n",
    "# Similarity threshold\n",
    "SIMILARITY_THRESHOLD = 0.40\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "model.to('cuda')\n",
    "\n",
    "# Prepare output directory for crops\n",
    "os.makedirs(\"id_frames\", exist_ok=True)\n",
    "\n",
    "# Start time\n",
    "start_time = datetime.now(ist)\n",
    "print(\"Start Time (IST):\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# Video setup\n",
    "video_path = \"/content/gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "output_fps = fps / 5  # Adjust for skipping every other frame\n",
    "out = cv2.VideoWriter(\n",
    "    \"gudivada+yolo+v8l+ReIDON+timestamps.avi\",\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    output_fps,\n",
    "    (width, height)\n",
    ")\n",
    "\n",
    "# ID → Name map\n",
    "id_name_map = {}\n",
    "frame_count = 0\n",
    "\n",
    "# Logging\n",
    "entry_log = set()\n",
    "entry_data = []\n",
    "\n",
    "# Store bounding boxes for authorized & unknown IDs\n",
    "id_bboxes = {}\n",
    "\n",
    "# ---------- ThreadPool setup ----------\n",
    "executor = ThreadPoolExecutor(max_workers=4)\n",
    "\n",
    "def process_crop(tid, crop):\n",
    "    faces = face_app.get(crop)\n",
    "    if len(faces) > 0 and faces[0]['det_score'] > 0.55:\n",
    "        emb = faces[0]['embedding'].astype('float32')\n",
    "        faiss.normalize_L2(emb.reshape(1, -1))  # Normalize query embedding\n",
    "        scores, indices = index.search(emb.reshape(1, -1), 1)  # Search top-1\n",
    "        best_score = scores[0][0]\n",
    "        best_idx = indices[0][0]\n",
    "        best_match = names[best_idx].replace(\"jpg\", \"\")\n",
    "        if best_score >= SIMILARITY_THRESHOLD:\n",
    "          return tid,best_match\n",
    "        else:\n",
    "            return tid,\"Unknown\"\n",
    "    return tid,\"No face\"\n",
    "# ---------- Main loop ----------\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        break   # stop if no frame is returned\n",
    "\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        tracker=\"botsort.yaml\",\n",
    "        persist=True,\n",
    "        classes=[0],  # person only\n",
    "        conf=0.5,\n",
    "        iou=0.8,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    if frame_count % 5 != 0:\n",
    "        frame_count += 1\n",
    "        continue\n",
    "\n",
    "    crops, tids, bboxes = [], [], []\n",
    "    if results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            tid = int(box.id[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            dx, dy = 5, 0\n",
    "            new_x1, new_y1 = x1 + dx, y1 + dy\n",
    "            new_x2, new_y2 = x2 - dx, y2 - dy\n",
    "\n",
    "            if h < 100:\n",
    "                draw_y2 = new_y2\n",
    "            else:\n",
    "                face_ratio = 0.2 if h > 450 else 0.5\n",
    "                draw_y2 = y1 + int(h * face_ratio)\n",
    "\n",
    "            face_crop = frame[new_y1:draw_y2, new_x1:new_x2]\n",
    "\n",
    "            if tid not in id_name_map or id_name_map[tid] in ['Unknown', 'No face']:\n",
    "                if face_crop.size != 0:\n",
    "                    crops.append(face_crop)\n",
    "                    tids.append(tid)\n",
    "                    bboxes.append((new_x1, new_y1, new_x2, new_y2))\n",
    "\n",
    "        # ---------- Parallel face recognition ----------\n",
    "        futures = [executor.submit(process_crop, tid, crop) for tid, crop in zip(tids, crops)]\n",
    "        for f in futures:\n",
    "            tid, name = f.result()\n",
    "            id_name_map[tid] = name\n",
    "\n",
    "    #     # # ---------- Draw + logging ----------\n",
    "    #     for tid, (new_x1, new_y1, new_x2, new_y2) in zip(tids, bboxes):\n",
    "    #         name_to_display = id_name_map[tid]\n",
    "    #     #     timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    #     #     timestamp = str(timedelta(milliseconds=timestamp_ms)).split(\".\")[0]\n",
    "\n",
    "    #     #     if f\"{tid}-{name_to_display}\" not in entry_log:\n",
    "    #     #         entry_log.add(f\"{tid}-{name_to_display}\")\n",
    "    #     #         if name_to_display != \"Unknown\" and name_to_display != \"No face\":\n",
    "    #     #             entry_data.append({\n",
    "    #     #                 \"name\": name_to_display,\n",
    "    #     #                 \"status\": \"entered\",\n",
    "    #     #                 \"timestamp\": timestamp\n",
    "    #     #             })\n",
    "    #     #         elif name_to_display == \"Unknown\":\n",
    "    #     #             entry_data.append({\n",
    "    #     #                 \"name\": \"Unknown\",\n",
    "    #     #                 \"status\": \"unauthorized\",\n",
    "    #     #                 \"timestamp\": timestamp\n",
    "    #     #             })\n",
    "\n",
    "    #         if name_to_display == \"No face\":\n",
    "    #             color = (0, 255, 0)\n",
    "    #             label = f\"No face (ID:{tid})\"\n",
    "    #         elif name_to_display != \"Unknown\":\n",
    "    #             color = (255, 0, 0)\n",
    "    #             label = f\"{name_to_display} (ID:{tid})\"\n",
    "    #         else:\n",
    "    #             color = (0, 0, 255)\n",
    "    #             label = f\"Unknown (ID:{tid})\"\n",
    "\n",
    "    #         cv2.rectangle(frame, (new_x1, new_y1), (new_x2, new_y2), color, 2)\n",
    "    #         cv2.putText(frame, label, (new_x1, new_y1 - 10),\n",
    "    #                     cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # out.write(frame)\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "# out.release()\n",
    "\n",
    "# End time\n",
    "end_time = datetime.now(ist)\n",
    "print(\"End Time (IST):\", end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "print(\"Execution Time (seconds):\", execution_time)\n",
    "print(\"Execution Time (minutes):\", execution_time / 60)\n",
    "\n",
    "# Save ID-name map & entry log\n",
    "with open(\"id_name_map.json\", \"w\") as f:\n",
    "    json.dump(id_name_map, f, indent=2)\n",
    "\n",
    "with open(\"entry_log.json\", \"w\") as f:\n",
    "    json.dump(entry_data, f, indent=2)\n",
    "\n",
    "print(f\"✅ Saved video, crops in id_name_map.json, entry_log.json\")\n",
    "print(f\"Number of stored IDs: {len(id_bboxes)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933e815",
   "metadata": {},
   "source": [
    "code with Faiss IFV & parallel crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8931db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import faiss\n",
    "import torch\n",
    "# Set timezone to IST\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    " \n",
    "# Initialize face recognition model\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "face_app.prepare(ctx_id=0)\n",
    " \n",
    "# Load face database\n",
    "with open(\"face_database_nandhyala.pkl\", \"rb\") as f:\n",
    "    face_db_list = pickle.load(f)\n",
    " \n",
    "names, embeddings = zip(*face_db_list)\n",
    "names = np.array(names)\n",
    "embeddings = np.stack(embeddings).astype('float32')\n",
    " \n",
    "# --- FAISS: Switch from IndexFlatIP (brute force) to IndexIVFFlat (IVF) ---\n",
    "dimension = embeddings.shape[1]\n",
    " \n",
    "# Optimized parameters for N=103 embeddings\n",
    "nlist = 10  # Number of clusters (approx. 4 * sqrt(103))\n",
    "nprobe = 5  # Number of clusters to search (higher for better accuracy on small datasets)\n",
    " \n",
    "# Step 1: Create a Flat (brute-force) index for training the clusters\n",
    "quantizer = faiss.IndexFlatIP(dimension)\n",
    " \n",
    "# Step 2: Create the IVF index\n",
    "index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    " \n",
    "# Step 3: Train the index on the embeddings\n",
    "print(\"Training FAISS Index...\")\n",
    "index.train(embeddings)\n",
    "print(\"Training complete.\")\n",
    " \n",
    "# Step 4: Add the embeddings to the trained index\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    " \n",
    "# Similarity threshold\n",
    "SIMILARITY_THRESHOLD = 0.40\n",
    " \n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "# model.export(format=\"onnx\", imgsz=[640,640])\n",
    "# model.to('cuda')\n",
    " \n",
    "# Prepare output directory for crops\n",
    "os.makedirs(\"id_frames\", exist_ok=True)\n",
    " \n",
    "# Start time\n",
    "start_time = datetime.now(ist)\n",
    "print(\"Start Time (IST):\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    " \n",
    "# Video setup\n",
    "# video_path = \"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "video_path = \"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    " \n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file. Please check the file path and integrity.\")\n",
    "    exit()\n",
    " \n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "output_fps = fps / 3\n",
    "out = cv2.VideoWriter(\n",
    "    \"gudivada+yolo+v8l+ReIDON+timestamps.avi\",\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    fps,\n",
    "    (width, height)\n",
    ")\n",
    " \n",
    "# ID → Name map\n",
    "id_name_map = {}\n",
    "frame_count = 0\n",
    " \n",
    "#Logging\n",
    "entry_log = set()\n",
    "entry_data = []\n",
    " \n",
    "# Store bounding boxes for authorized & unknown IDs\n",
    "id_bboxes = {}\n",
    " \n",
    "# ---------- ThreadPool setup for parallel processing ----------\n",
    "executor = ThreadPoolExecutor(max_workers=4)\n",
    " \n",
    "def process_crop(tid, crop):\n",
    "    \"\"\"Performs face recognition on a single crop.\"\"\"\n",
    "    faces = face_app.get(crop)\n",
    "    if len(faces) > 0 and faces[0]['det_score'] > 0.55:\n",
    "        print(faces[0])\n",
    "        emb = faces[0]['embedding'].astype('float32')\n",
    "        faiss.normalize_L2(emb.reshape(1, -1))\n",
    "        scores, indices = index.search(emb.reshape(1, -1), 1)\n",
    "        best_score = scores[0][0]\n",
    "        best_idx = indices[0][0]\n",
    "        best_match = names[best_idx].replace(\"jpg\", \"\")\n",
    "        if best_score >= SIMILARITY_THRESHOLD:\n",
    "            return tid, best_match\n",
    "        else:\n",
    "            return tid, \"Unknown\"\n",
    "    return tid, \"No face\"\n",
    "    \n",
    " \n",
    "# ---------- Main loop ----------\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret :\n",
    "        break\n",
    "        \n",
    "    # if frame_count % 3 != 0:\n",
    "    #     # out.write(frame)\n",
    "    #     frame_count += 1\n",
    "    #     continue\n",
    "        \n",
    "    results = model.track(\n",
    "        frame,\n",
    "        tracker=\"botsort_1.yaml\",\n",
    "        persist=True,\n",
    "        classes=[0],\n",
    "        conf=0.5,\n",
    "        iou=0.8,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "\n",
    "        \n",
    "    crops, tids = [], []\n",
    "    if results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            tid = int(box.id[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            # print(\"heights are\",h)\n",
    "            dx, dy = 0, 5\n",
    "            new_x1, new_y1 = x1 + dx, y1 + dy\n",
    "            new_x2, new_y2 = x2 - dx, y2 - dy\n",
    " \n",
    "            if h < 100:\n",
    "                draw_y2 = new_y2\n",
    "            else:\n",
    "                # h is the person bbox height/\n",
    "                if h > 450:\n",
    "                    face_ratio = 0.25        # very tall boxes: tighter head region  \n",
    "                elif h>350:\n",
    "                    face_crop=0.35\n",
    "                elif h > 300:\n",
    "                    face_ratio = 0.15        # medium-tall: in-between ratio\n",
    "                else:\n",
    "                    face_ratio = 0.50         # small/normal: larger top area\n",
    "\n",
    "                draw_y2 = y1 + int(h * face_ratio)\n",
    " \n",
    "            face_crop = frame[new_y1:draw_y2, new_x1:new_x2]\n",
    "            \n",
    "            # # --- Display the cropped face ---\n",
    "            # import matplotlib.pyplot as plt\n",
    "            # plt.imshow(cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB))\n",
    "            # plt.title(f\"Track ID: {tid}\")\n",
    "            # plt.axis(\"off\")\n",
    "            # plt.show()\n",
    " \n",
    "            # Only process if ID is new or recognition was previously uncertain\n",
    "            if tid not in id_name_map or id_name_map[tid] in ['Unknown', 'No face']:\n",
    "                if face_crop.size != 0:\n",
    "                    crops.append(face_crop)\n",
    "                    tids.append(tid)\n",
    " \n",
    "        # ---------- Parallel face recognition and FAISS search ----------\n",
    "        futures = [executor.submit(process_crop, tid, crop) for tid, crop in zip(tids, crops)]\n",
    "       \n",
    "        # Wait for all tasks to complete and update the map\n",
    "        for f in futures:\n",
    "            tid, name = f.result()\n",
    "            id_name_map[tid] = name\n",
    " \n",
    "    # ---------- Draw and save based on updated id_name_map ----------\n",
    "    if results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            tid = int(box.id[0])\n",
    "           \n",
    "            name_to_display = id_name_map.get(tid, \"No face\")\n",
    "    #         timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    #         timestamp = str(timedelta(milliseconds=timestamp_ms)).split(\".\")[0]\n",
    " \n",
    "            # if f\"{tid}-{name_to_display}\" not in entry_log:\n",
    "            #     entry_log.add(f\"{tid}-{name_to_display}\")\n",
    "            #     if name_to_display != \"Unknown\" and name_to_display != \"No face\":\n",
    "            #         entry_data.append({\n",
    "            #             \"name\": name_to_display,\n",
    "            #             \"status\": \"entered\",\n",
    "            #             \"timestamp\": timestamp\n",
    "            #         })\n",
    "            #     elif name_to_display == \"Unknown\":\n",
    "            #         entry_data.append({\n",
    "            #             \"name\": \"Unknown\",\n",
    "            #             \"status\": \"unauthorized\",\n",
    "            #             \"timestamp\": timestamp\n",
    "            #         })\n",
    " \n",
    "  \n",
    " \n",
    "            if name_to_display == \"No face\":\n",
    "                color = (0, 255, 0)\n",
    "                label = f\"No face (ID:{tid})\"\n",
    "            elif name_to_display != \"Unknown\":\n",
    "                color = (255, 0, 0)\n",
    "                label = f\"{name_to_display} (ID:{tid})\"\n",
    "            else:\n",
    "                color = (0, 0, 255)\n",
    "                label = f\"Unknown (ID:{tid})\"\n",
    " \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    " \n",
    "    out.write(frame)\n",
    "    frame_count += 1\n",
    " \n",
    "cap.release()\n",
    "out.release()\n",
    " \n",
    "end_time = datetime.now(ist)\n",
    "print(\"End Time (IST):\", end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "print(\"Execution Time (seconds):\", execution_time)\n",
    "print(\"Execution Time (minutes):\", execution_time / 60)\n",
    " \n",
    "with open(\"id_name_map.json\", \"w\") as f:\n",
    "    json.dump(id_name_map, f, indent=2)\n",
    " \n",
    "# with open(\"entry_log.json\", \"w\") as f:\n",
    "#     json.dump(entry_data, f, indent=2)\n",
    " \n",
    " \n",
    "print(f\"✅ Saved video, crops in 'id_frames/', id_name_map.json, and id_bboxes.json\")\n",
    "print(f\"Number of stored IDs: {len(id_bboxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e87f8b",
   "metadata": {},
   "source": [
    "finetuning the code with handling multiple faces in a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "# from ultralytics import YOLO\n",
    "# from insightface.app import FaceAnalysis\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import json\n",
    "# import pytz\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# from datetime import timedelta, datetime\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# import faiss\n",
    "# import torch\n",
    "# # Set timezone to IST\n",
    "# ist = pytz.timezone('Asia/Kolkata')\n",
    " \n",
    "# # Initialize face recognition model\n",
    "# face_app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "# face_app.prepare(ctx_id=0)\n",
    " \n",
    "# # Load face database\n",
    "# with open(\"face_database_gudivada.pkl\", \"rb\") as f:\n",
    "#     face_db_list = pickle.load(f)\n",
    " \n",
    "# names, embeddings = zip(*face_db_list)\n",
    "# names = np.array(names)\n",
    "# embeddings = np.stack(embeddings).astype('float32')\n",
    " \n",
    "# # --- FAISS: Switch from IndexFlatIP (brute force) to IndexIVFFlat (IVF) ---\n",
    "# dimension = embeddings.shape[1]\n",
    " \n",
    "# # Optimized parameters for N=103 embeddings\n",
    "# nlist = 40  # Number of clusters (approx. 4 * sqrt(103))\n",
    "# nprobe = 10  # Number of clusters to search (higher for better accuracy on small datasets)\n",
    " \n",
    "# # Step 1: Create a Flat (brute-force) index for training the clusters\n",
    "# quantizer = faiss.IndexFlatIP(dimension)\n",
    " \n",
    "# # Step 2: Create the IVF index\n",
    "# index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    " \n",
    "# # Step 3: Train the index on the embeddings\n",
    "# print(\"Training FAISS Index...\")\n",
    "# index.train(embeddings)\n",
    "# print(\"Training complete.\")\n",
    " \n",
    "# # Step 4: Add the embeddings to the trained index\n",
    "# faiss.normalize_L2(embeddings)\n",
    "# index.add(embeddings)\n",
    " \n",
    "# # Similarity threshold\n",
    "# SIMILARITY_THRESHOLD = 0.40\n",
    " \n",
    "# # Load YOLOv8 model\n",
    "# model = YOLO(\"yolov8l.pt\")\n",
    "# # model.export(format=\"onnx\", imgsz=[640,640])\n",
    "# # model.to('cuda')\n",
    " \n",
    "# # Prepare output directory for crops\n",
    "# os.makedirs(\"id_frames\", exist_ok=True)\n",
    " \n",
    "# # Start time\n",
    "# start_time = datetime.now(ist)\n",
    "# print(\"Start Time (IST):\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    " \n",
    "# # Video setup\n",
    "# video_path = \"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "# # video_path = \"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    " \n",
    "# if not cap.isOpened():\n",
    "#     print(\"Error: Could not open video file. Please check the file path and integrity.\")\n",
    "#     exit()\n",
    " \n",
    "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# output_fps = fps / 3\n",
    "# out = cv2.VideoWriter(\n",
    "#     \"gudivada+yolo+v8l+ReIDON+timestamps.avi\",\n",
    "#     cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "#     fps,\n",
    "#     (width, height)\n",
    "# )\n",
    " \n",
    "# # ID → Name map\n",
    "# id_name_map = {}\n",
    "# frame_count = 0\n",
    " \n",
    "# #Logging\n",
    "# entry_log = set()\n",
    "# entry_data = []\n",
    " \n",
    "# # Store bounding boxes for authorized & unknown IDs\n",
    "# id_bboxes = {}\n",
    " \n",
    "# # ---------- ThreadPool setup for parallel processing ----------\n",
    "# executor = ThreadPoolExecutor(max_workers=4)\n",
    " \n",
    "# def process_crop(tid, crop):\n",
    "#     \"\"\"Performs face recognition on a crop that may contain multiple faces.\n",
    "#        Returns the best match across all faces in the crop.\"\"\"\n",
    "#     faces = face_app.get(crop)\n",
    "#     if len(faces) == 0:\n",
    "#         return tid, \"No face\"\n",
    "\n",
    "#     best_score = -1.0\n",
    "#     best_match = \"Unknown\"\n",
    "\n",
    "#     for face in faces:\n",
    "#         x1, y1, x2, y2 = face.bbox.astype(int)  # convert to ints\n",
    "#         if face['det_score'] > 0.55:\n",
    "#             emb = face['embedding'].astype('float32')\n",
    "#             faiss.normalize_L2(emb.reshape(1, -1))\n",
    "#             scores, indices = index.search(emb.reshape(1, -1), 1)\n",
    "\n",
    "#             score = scores[0][0]\n",
    "#             idx = indices[0][0]\n",
    "#             match_name = names[idx].replace(\".jpg\", \"\")\n",
    "\n",
    "#             # Keep the face with the best score\n",
    "#             if score > best_score:\n",
    "#                 best_score = score\n",
    "#                 best_match = match_name if score >= SIMILARITY_THRESHOLD else \"Unknown\"\n",
    "\n",
    "#     return tid, best_match\n",
    "\n",
    "    \n",
    " \n",
    "# # ---------- Main loop ----------\n",
    "# while cap.isOpened():\n",
    "    \n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret :\n",
    "#         break\n",
    "        \n",
    "#     # if frame_count % 3 != 0:\n",
    "#     #     # out.write(frame)\n",
    "#     #     frame_count += 1\n",
    "#     #     continue\n",
    "        \n",
    "#     results = model.track(\n",
    "#         frame,\n",
    "#         tracker=\"botsort_1.yaml\",\n",
    "#         persist=True,\n",
    "#         classes=[0],\n",
    "#         conf=0.5,\n",
    "#         iou=0.8,\n",
    "#         verbose=False\n",
    "#     )\n",
    "    \n",
    "\n",
    "        \n",
    "#     crops, tids = [], []\n",
    "#     if results[0].boxes is not None:\n",
    "#         for box in results[0].boxes:\n",
    "#             x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "#             tid = int(box.id[0])\n",
    "#             w, h = x2 - x1, y2 - y1\n",
    "#             # print(\"heights are\",h)\n",
    "#             dx, dy = 0, 5\n",
    "#             new_x1, new_y1 = x1 + dx, y1 + dy\n",
    "#             new_x2, new_y2 = x2 - dx, y2 - dy\n",
    " \n",
    "#             if h < 100:\n",
    "#                 draw_y2 = new_y2\n",
    "#             else:\n",
    "#                 face_ratio = 0.2 if h > 450 else 0.5\n",
    "#                 draw_y2 = y1 + int(h * face_ratio)\n",
    "\n",
    " \n",
    "#             face_crop = frame[new_y1:draw_y2, new_x1:new_x2]\n",
    "            \n",
    "#             # # --- Display the cropped face ---\n",
    "#             # import matplotlib.pyplot as plt\n",
    "#             # plt.imshow(cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB))\n",
    "#             # plt.title(f\"Track ID: {tid}\")\n",
    "#             # plt.axis(\"off\")\n",
    "#             # plt.show()\n",
    " \n",
    "#             # Only process if ID is new or recognition was previously uncertain\n",
    "#             if tid not in id_name_map or id_name_map[tid] in ['Unknown', 'No face']:\n",
    "#                 if face_crop.size != 0:\n",
    "#                     crops.append(face_crop)\n",
    "#                     tids.append(tid)\n",
    " \n",
    "#         # ---------- Parallel face recognition and FAISS search ----------\n",
    "#         futures = [executor.submit(process_crop, tid, crop) for tid, crop in zip(tids, crops)]\n",
    "       \n",
    "#         # Wait for all tasks to complete and update the map\n",
    "#         for f in futures:\n",
    "#             tid, name = f.result()\n",
    "#             id_name_map[tid] = name\n",
    " \n",
    "#     # ---------- Draw and save based on updated id_name_map ----------\n",
    "#     if results[0].boxes is not None:\n",
    "#         for box in results[0].boxes:\n",
    "#             x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "#             tid = int(box.id[0])\n",
    "           \n",
    "#             name_to_display = id_name_map.get(tid, \"No face\")\n",
    "#     #         timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "#     #         timestamp = str(timedelta(milliseconds=timestamp_ms)).split(\".\")[0]\n",
    " \n",
    "#             # if f\"{tid}-{name_to_display}\" not in entry_log:\n",
    "#             #     entry_log.add(f\"{tid}-{name_to_display}\")\n",
    "#             #     if name_to_display != \"Unknown\" and name_to_display != \"No face\":\n",
    "#             #         entry_data.append({\n",
    "#             #             \"name\": name_to_display,\n",
    "#             #             \"status\": \"entered\",\n",
    "#             #             \"timestamp\": timestamp\n",
    "#             #         })\n",
    "#             #     elif name_to_display == \"Unknown\":\n",
    "#             #         entry_data.append({\n",
    "#             #             \"name\": \"Unknown\",\n",
    "#             #             \"status\": \"unauthorized\",\n",
    "#             #             \"timestamp\": timestamp\n",
    "#             #         })\n",
    " \n",
    "  \n",
    " \n",
    "#             if name_to_display == \"No face\":\n",
    "#                 color = (0, 255, 0)\n",
    "#                 label = f\"No face (ID:{tid})\"\n",
    "#             elif name_to_display != \"Unknown\":\n",
    "#                 color = (255, 0, 0)\n",
    "#                 label = f\"{name_to_display} (ID:{tid})\"\n",
    "#             else:\n",
    "#                 color = (0, 0, 255)\n",
    "#                 label = f\"Unknown (ID:{tid})\"\n",
    " \n",
    "#             cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "#             cv2.putText(frame, label, (x1, y1 - 10),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    " \n",
    "#     out.write(frame)\n",
    "#     frame_count += 1\n",
    " \n",
    "# cap.release()\n",
    "# out.release()\n",
    " \n",
    "# end_time = datetime.now(ist)\n",
    "# print(\"End Time (IST):\", end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "# execution_time = (end_time - start_time).total_seconds()\n",
    "# print(\"Execution Time (seconds):\", execution_time)\n",
    "# print(\"Execution Time (minutes):\", execution_time / 60)\n",
    " \n",
    "# with open(\"id_name_map.json\", \"w\") as f:\n",
    "#     json.dump(id_name_map, f, indent=2)\n",
    " \n",
    "# # with open(\"entry_log.json\", \"w\") as f:\n",
    "# #     json.dump(entry_data, f, indent=2)\n",
    " \n",
    " \n",
    "# print(f\"✅ Saved video, crops in 'id_frames/', id_name_map.json, and id_bboxes.json\")\n",
    "# print(f\"Number of stored IDs: {len(id_bboxes)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d195b62",
   "metadata": {},
   "source": [
    "code with changes in id assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c302a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "# from ultralytics import YOLO\n",
    "# from insightface.app import FaceAnalysis\n",
    "# import json\n",
    "# import pytz\n",
    "# import os\n",
    "# from datetime import timedelta, datetime\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# import faiss\n",
    "# import torch\n",
    "# import time  # For timing\n",
    "\n",
    "# # Set timezone to IST\n",
    "# ist = pytz.timezone('Asia/Kolkata')\n",
    " \n",
    "# # Initialize face recognition model\n",
    "# face_app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "# face_app.prepare(ctx_id=0)\n",
    " \n",
    "# # Load face database\n",
    "# with open(\"face_database_nandhyala.pkl\", \"rb\") as f:\n",
    "#     face_db_list = pickle.load(f)\n",
    " \n",
    "# names, embeddings = zip(*face_db_list)\n",
    "# names = np.array(names)\n",
    "# embeddings = np.stack(embeddings).astype('float32')\n",
    " \n",
    "# # --- FAISS: IVF index ---\n",
    "# dimension = embeddings.shape[1]\n",
    "# nlist = 10\n",
    "# nprobe = 5\n",
    "# quantizer = faiss.IndexFlatIP(dimension)\n",
    "# index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "# print(\"Training FAISS Index...\")\n",
    "# index.train(embeddings)\n",
    "# print(\"Training complete.\")\n",
    "# faiss.normalize_L2(embeddings)\n",
    "# index.add(embeddings)\n",
    "# SIMILARITY_THRESHOLD = 0.40\n",
    " \n",
    "# # Load YOLOv8 model\n",
    "# model = YOLO(\"yolov8l.pt\")\n",
    "# os.makedirs(\"id_frames\", exist_ok=True)\n",
    " \n",
    "# # Start time\n",
    "# start_time = datetime.now(ist)\n",
    "# print(\"Start Time (IST):\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    " \n",
    "# # Video setup\n",
    "# # video_path = \"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "# video_path = \"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "# if not cap.isOpened():\n",
    "#     print(\"Error: Could not open video file. Please check the file path and integrity.\")\n",
    "#     exit()\n",
    " \n",
    "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "# out = cv2.VideoWriter(\n",
    "#     \"gudivada+yolo+v8l+ReIDON+timestamps.avi\",\n",
    "#     cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "#     fps,\n",
    "#     (width, height)\n",
    "# )\n",
    " \n",
    "# id_name_map = {}\n",
    "# frame_count = 0\n",
    "# entry_log = set()\n",
    "# entry_data = []\n",
    "# id_bboxes = {}\n",
    "# executor = ThreadPoolExecutor(max_workers=4)\n",
    "\n",
    "# # Timing dictionary\n",
    "# timing = {\n",
    "#     \"frame_extraction\": 0.0,\n",
    "#     \"yolo_inference\": 0.0,\n",
    "#     \"crop_creation\": 0.0,\n",
    "#     \"parallel_face\": 0.0,\n",
    "#     \"draw_and_write\": 0.0\n",
    "# }\n",
    "\n",
    "# def process_crop(tid, crop):\n",
    "#     \"\"\"Face recognition and FAISS search per crop\"\"\"\n",
    "#     faces = face_app.get(crop)\n",
    "#     if len(faces) == 0:\n",
    "#         return tid, \"No face\"\n",
    "\n",
    "#     best_score = -1.0\n",
    "#     best_match = \"Unknown\"\n",
    "\n",
    "#     for face in faces:\n",
    "#         x1, y1, x2, y2 = face.bbox.astype(int)\n",
    "#         if face['det_score'] > 0.55:\n",
    "#             emb = face['embedding'].astype('float32')\n",
    "#             faiss.normalize_L2(emb.reshape(1, -1))\n",
    "#             scores, indices = index.search(emb.reshape(1, -1), 1)\n",
    "#             score = scores[0][0]\n",
    "#             idx = indices[0][0]\n",
    "#             match_name = names[idx].replace(\".jpg\", \"\")\n",
    "\n",
    "#             if score > best_score:\n",
    "#                 best_score = score\n",
    "#                 best_match = match_name if score >= SIMILARITY_THRESHOLD else \"Unknown\"\n",
    "\n",
    "#     return tid, best_match\n",
    "\n",
    "# # ---------- Main loop ----------\n",
    "# while cap.isOpened():\n",
    "#     start_frame = time.perf_counter()\n",
    "#     ret, frame = cap.read()\n",
    "#     end_frame = time.perf_counter()\n",
    "#     timing[\"frame_extraction\"] += end_frame - start_frame\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     start_yolo = time.perf_counter()\n",
    "#     results = model.track(\n",
    "#         frame,\n",
    "#         tracker=\"botsort_1.yaml\",\n",
    "#         persist=True,\n",
    "#         classes=[0],\n",
    "#         conf=0.4,\n",
    "#         iou=0.7,\n",
    "#         verbose=False\n",
    "#     )\n",
    "#     end_yolo = time.perf_counter()\n",
    "#     timing[\"yolo_inference\"] += end_yolo - start_yolo\n",
    "\n",
    "#     # Crop creation\n",
    "#     start_crop = time.perf_counter()\n",
    "#     crops, tids = [], []\n",
    "#     if results[0].boxes is not None:\n",
    "#         for box in results[0].boxes:\n",
    "#             x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "#             tid = int(box.id[0])\n",
    "#             w, h = x2 - x1, y2 - y1\n",
    "#             dx, dy = 0, 5\n",
    "#             new_x1, new_y1 = x1 + dx, y1 + dy\n",
    "#             new_x2, new_y2 = x2 - dx, y2 - dy\n",
    "#             draw_y2 = new_y2 if h < 100 else y1 + int(h * (0.2 if h > 450 else 0.5))\n",
    "#             face_crop = frame[new_y1:draw_y2, new_x1:new_x2]\n",
    "#             if tid not in id_name_map or id_name_map[tid] in ['Unknown', 'No face']:\n",
    "#                 if face_crop.size != 0:\n",
    "#                     crops.append(face_crop)\n",
    "#                     tids.append(tid)\n",
    "#     end_crop = time.perf_counter()\n",
    "#     timing[\"crop_creation\"] += end_crop - start_crop\n",
    "\n",
    "#     # Submit tasks and measure parallel execution\n",
    "#     start_parallel_total = time.perf_counter()\n",
    "#     futures = [executor.submit(process_crop, tid, crop) for tid, crop in zip(tids, crops)]\n",
    "#     for f in futures:\n",
    "#         tid, name = f.result()\n",
    "#         id_name_map[tid] = name\n",
    "#     end_parallel_total = time.perf_counter()\n",
    "#     timing[\"parallel_face\"] += end_parallel_total - start_parallel_total\n",
    "\n",
    "#     # Draw and write\n",
    "#     start_draw = time.perf_counter()\n",
    "#     if results[0].boxes is not None:\n",
    "#         for box in results[0].boxes:\n",
    "#             x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "#             tid = int(box.id[0])\n",
    "#             name_to_display = id_name_map.get(tid, \"No face\")\n",
    "#             if name_to_display == \"No face\":\n",
    "#                 color = (0, 255, 0)\n",
    "#                 label = f\"No face (ID:{tid})\"\n",
    "#             elif name_to_display != \"Unknown\":\n",
    "#                 color = (255, 0, 0)\n",
    "#                 label = f\"{name_to_display} (ID:{tid})\"\n",
    "#             else:\n",
    "#                 color = (0, 0, 255)\n",
    "#                 label = f\"Unknown (ID:{tid})\"\n",
    "#             cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "#             cv2.putText(frame, label, (x1, y1 - 10),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "#     out.write(frame)\n",
    "#     end_draw = time.perf_counter()\n",
    "#     timing[\"draw_and_write\"] += end_draw - start_draw\n",
    "\n",
    "#     frame_count += 1\n",
    "\n",
    "# cap.release()\n",
    "# out.release()\n",
    "\n",
    "# end_time = datetime.now(ist)\n",
    "# print(\"End Time (IST):\", end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "# execution_time = (end_time - start_time).total_seconds()\n",
    "# print(\"Execution Time (seconds):\", execution_time)\n",
    "# print(\"Execution Time (minutes):\", execution_time / 60)\n",
    "\n",
    "# with open(\"id_name_map.json\", \"w\") as f:\n",
    "#     json.dump(id_name_map, f, indent=2)\n",
    "\n",
    "# print(f\"✅ Saved video, crops in 'id_frames/', id_name_map.json, and id_bboxes.json\")\n",
    "# print(f\"Number of stored IDs: {len(id_bboxes)}\")\n",
    "\n",
    "# # Timing summary\n",
    "# print(\"\\n===== Timing Summary (seconds) =====\")\n",
    "# for key, val in timing.items():\n",
    "#     print(f\"{key}: {val:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "from datetime import timedelta, datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import faiss\n",
    "import torch\n",
    "import time  # For timing\n",
    "\n",
    "# Set timezone to IST\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    " \n",
    "# Initialize face recognition model\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "face_app.prepare(ctx_id=0)\n",
    " \n",
    "# # Load face database\n",
    "# with open(\"face_database.pkl\", \"rb\") as f:\n",
    "#     face_db_list = pickle.load(f)\n",
    " \n",
    "# names, embeddings = zip(*face_db_list)\n",
    "# names = np.array(names)\n",
    "# embeddings = np.stack(embeddings).astype('float32')\n",
    " \n",
    "# # --- FAISS: IVF index ---\n",
    "# dimension = embeddings.shape[1]\n",
    "# nlist = 3\n",
    "# nprobe = 1\n",
    "# quantizer = faiss.IndexFlatIP(dimension)\n",
    "# index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "# print(\"Training FAISS Index...\")\n",
    "# index.train(embeddings)\n",
    "# print(\"Training complete.\")\n",
    "# faiss.normalize_L2(embeddings)\n",
    "# index.add(embeddings)\n",
    "# SIMILARITY_THRESHOLD = 0.40\n",
    "\n",
    "# Load face database\n",
    "with open(\"face_database.pkl\", \"rb\") as f:\n",
    "    face_db_list = pickle.load(f)\n",
    " \n",
    "names, embeddings = zip(*face_db_list)\n",
    "names = np.array(names)\n",
    "embeddings = np.stack(embeddings).astype('float32')\n",
    " \n",
    "# --- FAISS: Dynamic Parameter Calculation ---\n",
    "N = len(embeddings)\n",
    "dimension = embeddings.shape[1]\n",
    " \n",
    "# Dynamically calculate nlist using the 4*sqrt(N) rule of thumb\n",
    "if N > 0:\n",
    "    nlist = int(4 * np.sqrt(N))\n",
    "    nlist = min(N, nlist)\n",
    "    nlist = max(1, nlist)\n",
    "else:\n",
    "    nlist = 1\n",
    " \n",
    "# Dynamically calculate nprobe as ~25% of nlist\n",
    "nprobe = max(1, nlist // 4)\n",
    " \n",
    "print(\"--- FAISS Configuration ---\")\n",
    "print(f\"Database has {N} embeddings.\")\n",
    "print(f\"Dynamically calculated parameters: nlist = {nlist}, nprobe = {nprobe}\")\n",
    "print(\"--------------------------\")\n",
    " \n",
    "# Step 1: Create a Flat (brute-force) index for training the clusters\n",
    "quantizer = faiss.IndexFlatIP(dimension)\n",
    " \n",
    "# Step 2: Create the IVF index\n",
    "index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    " \n",
    "# Step 3: Train the index on the embeddings\n",
    "print(\"Training FAISS Index...\")\n",
    "index.train(embeddings)\n",
    "print(\"Training complete.\")\n",
    " \n",
    "# Step 4: Add the embeddings to the trained index\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    "index.nprobe = nprobe\n",
    "\n",
    "SIMILARITY_THRESHOLD=0.40\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "os.makedirs(\"id_frames\", exist_ok=True)\n",
    " \n",
    "# Start time\n",
    "start_time = datetime.now(ist)\n",
    "print(\"Start Time (IST):\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    " \n",
    "# Video setup\n",
    "# video_path = \"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "# video_path=\"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "video_path=\"private_wh_cam2.avi\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file. Please check the file path and integrity.\")\n",
    "    exit()\n",
    " \n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "output_fps=fps/5\n",
    "out = cv2.VideoWriter(\n",
    "    \"gudivada+yolo+v8l+ReIDON+timestamps.avi\",\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    fps,\n",
    "    (width, height)\n",
    ")\n",
    " \n",
    "id_name_map = {}  # store all results per ID\n",
    "frame_count = 0\n",
    "id_bboxes = {}\n",
    "executor = ThreadPoolExecutor(max_workers=4)\n",
    "\n",
    "# Timing dictionary\n",
    "timing = {\n",
    "    \"frame_extraction\": 0.0,\n",
    "    \"yolo_inference\": 0.0,\n",
    "    \"crop_creation\": 0.0,\n",
    "    \"parallel_face\": 0.0,\n",
    "    \"draw_and_write\": 0.0\n",
    "}\n",
    "\n",
    "def process_crop(tid, crop):\n",
    "    \"\"\"Face recognition and FAISS search per crop\"\"\"\n",
    "    faces = face_app.get(crop)\n",
    "    if len(faces) == 0:\n",
    "        return tid, \"No face\"\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_match = \"Unknown\"\n",
    "\n",
    "    for face in faces:\n",
    "        # x1, y1, x2, y2 = face.bbox.astype(int)\n",
    "        if face['det_score'] > 0.55:\n",
    "            emb = face['embedding'].astype('float32')\n",
    "            faiss.normalize_L2(emb.reshape(1, -1))\n",
    "            scores, indices = index.search(emb.reshape(1, -1), 1)\n",
    "            score = scores[0][0]\n",
    "            idx = indices[0][0]\n",
    "            match_name = names[idx].replace(\".jpg\", \"\")\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = match_name if score >= SIMILARITY_THRESHOLD else \"Unknown\"\n",
    "\n",
    "    return tid, best_match\n",
    "\n",
    "# ---------- Main loop ----------\n",
    "while cap.isOpened():\n",
    "    start_frame = time.perf_counter()\n",
    "    ret, frame = cap.read()\n",
    "    end_frame = time.perf_counter()\n",
    "    timing[\"frame_extraction\"] += end_frame - start_frame\n",
    "    if not ret:\n",
    "        break\n",
    "    # if frame_count%5!=0:\n",
    "    #     frame_count+=1\n",
    "    #     continue\n",
    "\n",
    "    start_yolo = time.perf_counter()\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        tracker=\"botsort_1.yaml\",\n",
    "        persist=True,\n",
    "        classes=[0],\n",
    "        conf=0.4,\n",
    "        iou=0.7,\n",
    "        verbose=False\n",
    "    )\n",
    "    end_yolo = time.perf_counter()\n",
    "    timing[\"yolo_inference\"] += end_yolo - start_yolo\n",
    "\n",
    "    # Crop creation\n",
    "    start_crop = time.perf_counter()\n",
    "    crops, tids = [], []\n",
    "    if results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            if box.id is None:\n",
    "                continue  # skip this box if no track ID\n",
    "            # tid = int(box.id.item())  # safer way to convert\n",
    "\n",
    "            tid = int(box.id[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            dx, dy = 0, 5\n",
    "            new_x1, new_y1 = x1 + dx, y1 + dy\n",
    "            new_x2, new_y2 = x2 - dx, y2 - dy\n",
    "\n",
    "            # Top 50% crop\n",
    "            draw_y2 = new_y1 + int(h * 0.5)\n",
    "            face_crop = frame[new_y1:draw_y2, new_x1:new_x2]\n",
    "            if face_crop.size != 0:\n",
    "                crops.append(face_crop)\n",
    "                tids.append(tid)\n",
    "    end_crop = time.perf_counter()\n",
    "    timing[\"crop_creation\"] += end_crop - start_crop\n",
    "\n",
    "    # Parallel face recognition\n",
    "    start_parallel_total = time.perf_counter()\n",
    "    futures = [executor.submit(process_crop, tid, crop) for tid, crop in zip(tids, crops)]\n",
    "    for f in futures:\n",
    "        tid, name = f.result()\n",
    "        if tid not in id_name_map:\n",
    "            id_name_map[tid] = []\n",
    "        id_name_map[tid].append(name)  # append every result\n",
    "    end_parallel_total = time.perf_counter()\n",
    "    timing[\"parallel_face\"] += end_parallel_total - start_parallel_total\n",
    "\n",
    "    # Draw and write\n",
    "    start_draw = time.perf_counter()\n",
    "    if results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            if box.id is None:\n",
    "                continue  # skip this box if no track ID\n",
    "            tid = int(box.id[0])\n",
    "            # show latest name in this frame\n",
    "            name_to_display = id_name_map[tid][-1] if tid in id_name_map else \"No face\"\n",
    "            if name_to_display == \"No face\":\n",
    "                color = (0, 255, 0)\n",
    "                label = f\"No face (ID:{tid})\"\n",
    "            elif name_to_display != \"Unknown\":\n",
    "                color = (255, 0, 0)\n",
    "                label = f\"{name_to_display} (ID:{tid})\"\n",
    "            else:\n",
    "                color = (0, 0, 255)\n",
    "                label = f\"Unknown (ID:{tid})\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    out.write(frame)\n",
    "    end_draw = time.perf_counter()\n",
    "    timing[\"draw_and_write\"] += end_draw - start_draw\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# ---------- Finalize ID -> Name mapping ----------\n",
    "finalized_id_name_map = {}\n",
    "for tid, names_list in id_name_map.items():\n",
    "    # Keep only valid names\n",
    "    valid_names = [n for n in names_list if n not in [\"Unknown\", \"No face\"]]\n",
    "    if valid_names:\n",
    "        # pick most frequent valid name\n",
    "        final_name = max(set(valid_names), key=valid_names.count)\n",
    "    elif \"Unknown\" in names_list:\n",
    "        final_name = \"Unknown\"\n",
    "    else:\n",
    "        final_name = \"No face\"\n",
    "    finalized_id_name_map[tid] = final_name\n",
    "\n",
    "# Save finalized mapping\n",
    "with open(\"finalized_id_name_map.json\", \"w\") as f:\n",
    "    json.dump(finalized_id_name_map, f, indent=2)\n",
    "\n",
    "with open(\"id_name_map.json\", \"w\") as f:\n",
    "    json.dump(id_name_map, f, indent=2)\n",
    "\n",
    "\n",
    "end_time = datetime.now(ist)\n",
    "print(\"End Time (IST):\", end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "print(\"Execution Time (seconds):\", execution_time)\n",
    "print(\"Execution Time (minutes):\", execution_time / 60)\n",
    "\n",
    "print(f\"✅ Saved video, crops in 'id_frames/', id_name_map.json, and finalized_id_name_map.json\")\n",
    "print(f\"Number of unique IDs: {len(finalized_id_name_map)}\")\n",
    "\n",
    "# Timing summary\n",
    "print(\"\\n===== Timing Summary (seconds) =====\")\n",
    "print(\"Execution Time (seconds):\", execution_time)\n",
    "for key, val in timing.items():\n",
    "    print(f\"{key}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369febd5",
   "metadata": {},
   "source": [
    "OOP version of above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import faiss\n",
    "import time\n",
    "\n",
    "\n",
    "class FaceReIDPipeline:\n",
    "    def __init__(self, video_path, db_path, output_path, yolo_model=\"yolov8l.pt\", sim_threshold=0.40):\n",
    "        # Config\n",
    "        self.ist = pytz.timezone(\"Asia/Kolkata\")\n",
    "        self.video_path = video_path\n",
    "        self.output_path = output_path\n",
    "        self.sim_threshold = sim_threshold\n",
    "        self.executor = ThreadPoolExecutor(max_workers=4)\n",
    "\n",
    "        # Init models\n",
    "        self.face_app = FaceAnalysis(name=\"buffalo_l\",root=\"insightface\", providers=['CUDAExecutionProvider'])\n",
    "        self.face_app.prepare(ctx_id=0)\n",
    "        self.model = YOLO(yolo_model)\n",
    "\n",
    "        # Load DB + FAISS\n",
    "        self.names, self.index = self._load_faiss_index(db_path)\n",
    "\n",
    "        # Bookkeeping\n",
    "        self.id_name_map = {}\n",
    "        self.timing = {\n",
    "            \"frame_extraction\": 0.0,\n",
    "            \"yolo_inference\": 0.0,\n",
    "            \"crop_creation\": 0.0,\n",
    "            \"parallel_face\": 0.0,\n",
    "            \"draw_and_write\": 0.0\n",
    "        }\n",
    "\n",
    "    def _load_faiss_index(self, db_path):\n",
    "        with open(db_path, \"rb\") as f:\n",
    "            face_db_list = pickle.load(f)\n",
    "        names, embeddings = zip(*face_db_list)\n",
    "        names = np.array(names)\n",
    "        embeddings = np.stack(embeddings).astype(\"float32\")\n",
    "\n",
    "        N, dim = len(embeddings), embeddings.shape[1]\n",
    "        nlist = max(1, min(N, int(4 * np.sqrt(N))))\n",
    "        nprobe = max(1, nlist // 4)\n",
    "\n",
    "        quantizer = faiss.IndexFlatIP(dim)\n",
    "        index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "        print(\"Training FAISS index...\")\n",
    "        index.train(embeddings)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        index.add(embeddings)\n",
    "        index.nprobe = nprobe\n",
    "\n",
    "        print(f\"--- FAISS Config: N={N}, dim={dim}, nlist={nlist}, nprobe={nprobe} ---\")\n",
    "        return names, index\n",
    "\n",
    "    def _process_crop(self, tid, crop):\n",
    "        faces = self.face_app.get(crop)\n",
    "        if not faces:\n",
    "            return tid, \"No face\"\n",
    "\n",
    "        best_score, best_match = -1.0, \"Unknown\"\n",
    "        for face in faces:\n",
    "            if face['det_score'] > 0.55:\n",
    "                emb = face['embedding'].astype('float32')\n",
    "                faiss.normalize_L2(emb.reshape(1, -1))\n",
    "                scores, indices = self.index.search(emb.reshape(1, -1), 1)\n",
    "                score, idx = scores[0][0], indices[0][0]\n",
    "                match_name = self.names[idx].replace(\".jpg\", \"\")\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = match_name if score >= self.sim_threshold else \"Unknown\"\n",
    "\n",
    "        return tid, best_match\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Error: Could not open video file.\")\n",
    "\n",
    "        width, height = int(cap.get(3)), int(cap.get(4))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "        out = cv2.VideoWriter(\n",
    "            self.output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "            fps,\n",
    "            (width, height)\n",
    "        )\n",
    "\n",
    "        start_time = datetime.now(self.ist)\n",
    "        print(\"Start Time:\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "        frame_count = 0\n",
    "        while cap.isOpened():\n",
    "            # Frame extraction\n",
    "            t0 = time.perf_counter()\n",
    "            ret, frame = cap.read()\n",
    "            self.timing[\"frame_extraction\"] += time.perf_counter() - t0\n",
    "            if not ret:\n",
    "                break\n",
    "            if frame_count&5!=0:\n",
    "                frame_count+=1\n",
    "                continue\n",
    "            # YOLO detection + tracking\n",
    "            t0 = time.perf_counter()\n",
    "            results = self.model.track(\n",
    "                frame,\n",
    "                tracker=\"botsort_1.yaml\",\n",
    "                persist=True,\n",
    "                classes=[0],\n",
    "                conf=0.4,\n",
    "                iou=0.7,\n",
    "                verbose=False\n",
    "            )\n",
    "            self.timing[\"yolo_inference\"] += time.perf_counter() - t0\n",
    "\n",
    "            # Crop creation\n",
    "            t0 = time.perf_counter()\n",
    "            crops, tids = [], []\n",
    "            if results[0].boxes is not None:\n",
    "                for box in results[0].boxes:\n",
    "                    if box.id is None:\n",
    "                        continue\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    tid = int(box.id[0])\n",
    "                    h = y2 - y1\n",
    "                    face_crop = frame[y1:y1 + int(h * 0.5), x1:x2]\n",
    "                    if face_crop.size:\n",
    "                        crops.append(face_crop)\n",
    "                        tids.append(tid)\n",
    "            self.timing[\"crop_creation\"] += time.perf_counter() - t0\n",
    "\n",
    "            # Face recognition (parallel)\n",
    "            t0 = time.perf_counter()\n",
    "            futures = [self.executor.submit(self._process_crop, tid, crop) for tid, crop in zip(tids, crops)]\n",
    "            for f in futures:\n",
    "                tid, name = f.result()\n",
    "                if tid not in self.id_name_map:\n",
    "                    self.id_name_map[tid] = []\n",
    "                self.id_name_map[tid].append(name)\n",
    "            self.timing[\"parallel_face\"] += time.perf_counter() - t0\n",
    "\n",
    "            # Draw + write\n",
    "            t0 = time.perf_counter()\n",
    "            if results[0].boxes is not None:\n",
    "                for box in results[0].boxes:\n",
    "                    if box.id is None:\n",
    "                        continue\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    tid = int(box.id[0])\n",
    "                    name = self.id_name_map[tid][-1] if tid in self.id_name_map else \"No face\"\n",
    "                    color, label = self._get_color_label(name, tid)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            out.write(frame)\n",
    "            self.timing[\"draw_and_write\"] += time.perf_counter() - t0\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        self._finalize_results(start_time)\n",
    "\n",
    "    def _get_color_label(self, name, tid):\n",
    "        if name == \"No face\":\n",
    "            return (0, 255, 0), f\"No face (ID:{tid})\"\n",
    "        elif name != \"Unknown\":\n",
    "            return (255, 0, 0), f\"{name} (ID:{tid})\"\n",
    "        else:\n",
    "            return (0, 0, 255), f\"Unknown (ID:{tid})\"\n",
    "\n",
    "    def _finalize_results(self, start_time):\n",
    "        finalized = {}\n",
    "        for tid, names_list in self.id_name_map.items():\n",
    "            valid_names = [n for n in names_list if n not in [\"Unknown\", \"No face\"]]\n",
    "            if valid_names:\n",
    "                final_name = max(set(valid_names), key=valid_names.count)\n",
    "            elif \"Unknown\" in names_list:\n",
    "                final_name = \"Unknown\"\n",
    "            else:\n",
    "                final_name = \"No face\"\n",
    "            finalized[tid] = final_name\n",
    "\n",
    "        with open(\"id_name_map.json\", \"w\") as f:\n",
    "            json.dump(self.id_name_map, f, indent=2)\n",
    "        with open(\"finalized_id_name_map.json\", \"w\") as f:\n",
    "            json.dump(finalized, f, indent=2)\n",
    "        print(f\"Unique IDs: {len(finalized)}\")\n",
    "        end_time = datetime.now(self.ist)\n",
    "        exec_time = (end_time - start_time).total_seconds()\n",
    "        print(\"End Time:\", end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        print(f\"Execution Time: {exec_time:.2f}s ({exec_time/60:.2f}m)\")\n",
    "        \n",
    "\n",
    "        print(\"===== Timing Summary =====\")\n",
    "        for k, v in self.timing.items():\n",
    "            print(f\"{k}: {v:.4f}s\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = FaceReIDPipeline(\n",
    "        video_path=\"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\",\n",
    "        db_path=\"face_database_gudivada.pkl\",\n",
    "        output_path=\"gudivada+yolo+v8l+ReIDON+timestamps.avi\"\n",
    "    )\n",
    "    pipeline.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e8ce2",
   "metadata": {},
   "source": [
    "yolo detector and botsort seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54226533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from types import SimpleNamespace\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.trackers.bot_sort import BOTSORT\n",
    "from ultralytics.engine.results import Boxes\n",
    "\n",
    "# ------------------------------\n",
    "# Device\n",
    "# ------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ------------------------------\n",
    "# Load YOLOv8 model\n",
    "# ------------------------------\n",
    "model = YOLO(\"yolov8l.pt\").to(device)\n",
    "\n",
    "# ------------------------------\n",
    "# Tracker arguments (BoT-SORT)\n",
    "# ------------------------------\n",
    "tracker_args = {\n",
    "    \"tracker_type\": \"botsort\",\n",
    "    \"track_high_thresh\": 0.5,\n",
    "    \"track_low_thresh\": 0.3,\n",
    "    \"new_track_thresh\": 0.5,\n",
    "    \"track_buffer\": 700,\n",
    "    \"match_thresh\": 0.95,\n",
    "    \"fuse_score\": True,\n",
    "    \"gmc_method\": \"sparseOptFlow\",\n",
    "    \"proximity_thresh\": 0.5,\n",
    "    \"appearance_thresh\": 0.8,\n",
    "    \"with_reid\":False ,\n",
    "    \"model\": \"yolo11n-cls.pt\",\n",
    "    \"device\":device\n",
    "}\n",
    "\n",
    "args = SimpleNamespace(**tracker_args)\n",
    "\n",
    "# ------------------------------\n",
    "# Initialize tracker\n",
    "# ------------------------------\n",
    "tracker = BOTSORT(args=args, frame_rate=25)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Video paths\n",
    "# ------------------------------\n",
    "input_video_path = \"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "output_video_path = \"annotated_output.mp4\"\n",
    "output_json_path = \"tracks.json\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# ------------------------------\n",
    "# Data structures for JSON\n",
    "# ------------------------------\n",
    "track_data = []\n",
    "track_lengths = defaultdict(int)\n",
    "unique_ids = set()  # Store unique IDs\n",
    "\n",
    "# ------------------------------\n",
    "# Timing accumulators\n",
    "# ------------------------------\n",
    "yolo_time_total = 0.0\n",
    "tracker_time_total = 0.0\n",
    "\n",
    "frame_idx = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "    # ---------------- YOLO inference ----------------\n",
    "    start_yolo = time.time()\n",
    "    results = model(frame, classes=[0], conf=0.4, iou=0.7)[0]\n",
    "    end_yolo = time.time()\n",
    "    yolo_time_total += (end_yolo - start_yolo)\n",
    "\n",
    "    if results.boxes is None or len(results.boxes) == 0:\n",
    "        out.write(frame)\n",
    "        continue\n",
    "\n",
    "    # Convert YOLO output to CPU tensors for tracker\n",
    "    bboxes = results.boxes.xyxy.detach().cpu()\n",
    "    confs = results.boxes.conf.detach().cpu()\n",
    "    cls = results.boxes.cls.detach().cpu()\n",
    "\n",
    "    dets_tensor = torch.hstack([bboxes, confs.unsqueeze(1), cls.unsqueeze(1)])\n",
    "    dets = Boxes(dets_tensor, frame.shape[:2])\n",
    "\n",
    "    # ---------------- Tracker update ----------------\n",
    "    start_tracker = time.time()\n",
    "    tracks = tracker.update(dets, frame.copy())\n",
    "    end_tracker = time.time()\n",
    "    tracker_time_total += (end_tracker - start_tracker)\n",
    "\n",
    "    # Annotate frame & record JSON\n",
    "    for t in tracks:\n",
    "        x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"ID:{int(track_id)}\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "        unique_ids.add(int(track_id))\n",
    "\n",
    "        track_data.append({\n",
    "            \"frame\": frame_idx,\n",
    "            \"track_id\": int(track_id),\n",
    "            \"class_id\": int(cls_id),\n",
    "            \"conf\": float(conf),\n",
    "            \"bbox\": [x1, y1, x2, y2]\n",
    "        })\n",
    "\n",
    "        track_lengths[int(track_id)] += 1\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Add total frame length per track_id\n",
    "for td in track_data:\n",
    "    td[\"track_length\"] = track_lengths[td[\"track_id\"]]\n",
    "\n",
    "# Save JSON file\n",
    "with open(output_json_path, \"w\") as f:\n",
    "    json.dump(track_data, f, indent=4)\n",
    "\n",
    "print(f\"Annotated video saved to {output_video_path}\")\n",
    "print(f\"Track JSON saved to {output_json_path}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Print summary\n",
    "# ------------------------------\n",
    "print(f\"Number of unique track IDs: {len(unique_ids)}\")\n",
    "print(f\"Total YOLO inference time: {yolo_time_total:.2f} sec\")\n",
    "print(f\"Total Tracker update time: {tracker_time_total:.2f} sec\")\n",
    "print(f\"Overall processing time: {yolo_time_total + tracker_time_total:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3f780",
   "metadata": {},
   "source": [
    "oop version with detector and yolo separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import faiss\n",
    "import torch\n",
    "from ultralytics.engine.results import Boxes\n",
    "from ultralytics.trackers.bot_sort import BOTSORT\n",
    "from types import SimpleNamespace\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "class FaceReIDPipeline:\n",
    "    def __init__(self, video_path, db_path, output_path, yolo_model=\"yolov8l.pt\", sim_threshold=0.40):\n",
    "        # Config\n",
    "        self.ist = pytz.timezone(\"Asia/Kolkata\")\n",
    "        self.video_path = video_path\n",
    "        self.output_path = output_path\n",
    "        self.sim_threshold = sim_threshold\n",
    "        self.executor = ThreadPoolExecutor(max_workers=4)\n",
    "\n",
    "        # ---------------- YOLO Detector ----------------\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = YOLO(yolo_model).to(self.device)\n",
    "\n",
    "        # ---------------- Tracker (BoT-SORT) ----------------\n",
    "        tracker_args = {\n",
    "            \"tracker_type\": \"botsort\",\n",
    "            \"track_high_thresh\": 0.5,\n",
    "            \"track_low_thresh\": 0.3,\n",
    "            \"new_track_thresh\": 0.5,\n",
    "            \"track_buffer\": 500,\n",
    "            \"match_thresh\": 0.95,\n",
    "            \"fuse_score\": True,\n",
    "            \"gmc_method\": \"sparseOptFlow\",\n",
    "            \"proximity_thresh\": 0.5,\n",
    "            \"appearance_thresh\": 0.8,\n",
    "            \"with_reid\": False,\n",
    "            \"model\": \"yolo11n-cls.pt\",\n",
    "            \"device\": self.device\n",
    "        }\n",
    "        args = SimpleNamespace(**tracker_args)\n",
    "        self.tracker = BOTSORT(args=args, frame_rate=25)\n",
    "\n",
    "        # ---------------- Face Recognition ----------------\n",
    "        self.face_app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "        self.face_app.prepare(ctx_id=0)\n",
    "\n",
    "        # Load DB + FAISS\n",
    "        self.names, self.index = self._load_faiss_index(db_path)\n",
    "\n",
    "        # Bookkeeping\n",
    "        self.id_name_map = {}\n",
    "        self.timing = defaultdict(float)\n",
    "\n",
    "    def _load_faiss_index(self, db_path):\n",
    "        with open(db_path, \"rb\") as f:\n",
    "            face_db_list = pickle.load(f)\n",
    "        names, embeddings = zip(*face_db_list)\n",
    "        names = np.array(names)\n",
    "        embeddings = np.stack(embeddings).astype(\"float32\")\n",
    "\n",
    "        N, dim = len(embeddings), embeddings.shape[1]\n",
    "        nlist = max(1, min(N, int(4 * np.sqrt(N))))\n",
    "        nprobe = max(1, nlist // 4)\n",
    "\n",
    "        quantizer = faiss.IndexFlatIP(dim)\n",
    "        index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "        print(\"Training FAISS index...\")\n",
    "        index.train(embeddings)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        index.add(embeddings)\n",
    "        index.nprobe = nprobe\n",
    "\n",
    "        print(f\"--- FAISS Config: N={N}, dim={dim}, nlist={nlist}, nprobe={nprobe} ---\")\n",
    "        return names, index\n",
    "\n",
    "    def _process_crop(self, tid, crop):\n",
    "        faces = self.face_app.get(crop)\n",
    "        if not faces:\n",
    "            return tid, \"No face\"\n",
    "\n",
    "        best_score, best_match = -1.0, \"Unknown\"\n",
    "        for face in faces:\n",
    "            if face['det_score'] > 0.55:\n",
    "                emb = face['embedding'].astype('float32')\n",
    "                faiss.normalize_L2(emb.reshape(1, -1))\n",
    "                scores, indices = self.index.search(emb.reshape(1, -1), 1)\n",
    "                score, idx = scores[0][0], indices[0][0]\n",
    "                match_name = self.names[idx].replace(\".jpg\", \"\")\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = match_name if score >= self.sim_threshold else \"Unknown\"\n",
    "\n",
    "        return tid, best_match\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Error: Could not open video file.\")\n",
    "\n",
    "        width, height = int(cap.get(3)), int(cap.get(4))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "        out = cv2.VideoWriter(\n",
    "            self.output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "            fps,\n",
    "            (width, height)\n",
    "        )\n",
    "\n",
    "        frame_idx = 0\n",
    "        start_time = time.perf_counter()  # <-- start timer\n",
    "        while cap.isOpened():\n",
    "            t0 = time.perf_counter()\n",
    "            ret, frame = cap.read()\n",
    "            self.timing[\"frame_extraction\"] += time.perf_counter() - t0\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_idx += 1\n",
    "\n",
    "            # ---------------- YOLO Detection ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            results = self.model(frame, classes=[0], conf=0.4, iou=0.7)[0]\n",
    "            self.timing[\"yolo_inference\"] += time.perf_counter() - t0\n",
    "\n",
    "            if results.boxes is None or len(results.boxes) == 0:\n",
    "                out.write(frame)\n",
    "                continue\n",
    "\n",
    "            # Convert YOLO boxes to tracker input\n",
    "            bboxes = results.boxes.xyxy.detach().cpu()\n",
    "            confs = results.boxes.conf.detach().cpu()\n",
    "            cls = results.boxes.cls.detach().cpu()\n",
    "            dets_tensor = torch.hstack([bboxes, confs.unsqueeze(1), cls.unsqueeze(1)])\n",
    "            dets = Boxes(dets_tensor, frame.shape[:2])\n",
    "\n",
    "            # ---------------- Tracker Update ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            tracks = self.tracker.update(dets, frame.copy())\n",
    "            self.timing[\"tracker_update\"] += time.perf_counter() - t0\n",
    "\n",
    "            # ---------------- Face Crops ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            crops, tids = [], []\n",
    "            for t in tracks:\n",
    "                x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                h = y2 - y1\n",
    "                face_crop = frame[y1:y1 + int(h * 0.5), x1:x2]\n",
    "                if face_crop.size:\n",
    "                    crops.append(face_crop)\n",
    "                    tids.append(int(track_id))\n",
    "            self.timing[\"crop_creation\"] += time.perf_counter() - t0\n",
    "\n",
    "            # ---------------- Parallel Face Recognition ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            futures = [self.executor.submit(self._process_crop, tid, crop) for tid, crop in zip(tids, crops)]\n",
    "            for f in futures:\n",
    "                tid, name = f.result()\n",
    "                if tid not in self.id_name_map:\n",
    "                    self.id_name_map[tid] = []\n",
    "                self.id_name_map[tid].append(name)\n",
    "            self.timing[\"parallel_face\"] += time.perf_counter() - t0\n",
    "\n",
    "            # ---------------- Draw and Write ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            for t in tracks:\n",
    "                x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                name = self.id_name_map.get(int(track_id), [\"No face\"])[-1]\n",
    "                color, label = self._get_color_label(name, track_id)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            out.write(frame)\n",
    "            self.timing[\"draw_and_write\"] += time.perf_counter() - t0\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        end_time = time.perf_counter()  # <-- end timer\n",
    "        total_exec_time = end_time - start_time\n",
    "        self._finalize_results()\n",
    "        print(f\"Total Execution Time: {total_exec_time:.2f} seconds ({total_exec_time/60:.2f} minutes)\")\n",
    "\n",
    "    def _get_color_label(self, name, tid):\n",
    "        if name == \"No face\":\n",
    "            return (0, 255, 0), f\"No face (ID:{tid})\"\n",
    "        elif name != \"Unknown\":\n",
    "            return (255, 0, 0), f\"{name} (ID:{tid})\"\n",
    "        else:\n",
    "            return (0, 0, 255), f\"Unknown (ID:{tid})\"\n",
    "\n",
    "    def _finalize_results(self):\n",
    "        finalized = {}\n",
    "        for tid, names_list in self.id_name_map.items():\n",
    "            valid_names = [n for n in names_list if n not in [\"Unknown\", \"No face\"]]\n",
    "            final_name = max(set(valid_names), key=valid_names.count) if valid_names else names_list[-1]\n",
    "            finalized[tid] = final_name\n",
    "\n",
    "        with open(\"id_name_map.json\", \"w\") as f:\n",
    "            json.dump(self.id_name_map, f, indent=2)\n",
    "        with open(\"finalized_id_name_map.json\", \"w\") as f:\n",
    "            json.dump(finalized, f, indent=2)\n",
    "\n",
    "        print(\"===== Timing Summary =====\")\n",
    "        for k, v in self.timing.items():\n",
    "            print(f\"{k}: {v:.4f}s\")\n",
    "        print(f\"Unique IDs: {len(finalized)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = FaceReIDPipeline(\n",
    "        video_path=\"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\",\n",
    "        db_path=\"face_database_nuzvid.pkl\",\n",
    "        output_path=\"gudivada+yolo+v8l+ReID_separated.avi\"\n",
    "    )\n",
    "    pipeline.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc052433",
   "metadata": {},
   "source": [
    "oop version with yolo and botsort separate and sequential face processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb529b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import faiss\n",
    "import torch\n",
    "from ultralytics.engine.results import Boxes\n",
    "from ultralytics.trackers.bot_sort import BOTSORT\n",
    "from types import SimpleNamespace\n",
    "import time\n",
    "\n",
    "class FaceReIDPipeline:\n",
    "    def __init__(self, video_path, db_path, output_path, yolo_model=\"yolov8l.pt\", sim_threshold=0.40):\n",
    "        # Config\n",
    "        self.ist = pytz.timezone(\"Asia/Kolkata\")\n",
    "        self.video_path = video_path\n",
    "        self.output_path = output_path\n",
    "        self.sim_threshold = sim_threshold\n",
    "\n",
    "        # ---------------- YOLO Detector ----------------\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = YOLO(yolo_model).to(self.device)\n",
    "\n",
    "        # ---------------- Tracker (BoT-SORT) ----------------\n",
    "        tracker_args = {\n",
    "            \"tracker_type\": \"botsort\",\n",
    "            \"track_high_thresh\": 0.5,\n",
    "            \"track_low_thresh\": 0.3,\n",
    "            \"new_track_thresh\": 0.5,\n",
    "            \"track_buffer\": 500,\n",
    "            \"match_thresh\": 0.95,\n",
    "            \"fuse_score\": True,\n",
    "            \"gmc_method\": None,\n",
    "            \"proximity_thresh\": 0.5,\n",
    "            \"appearance_thresh\": 0.8,\n",
    "            \"with_reid\": False,\n",
    "            \"model\": \"auto\"\n",
    "        }\n",
    "        \n",
    "        args = SimpleNamespace(**tracker_args)\n",
    "        self.tracker = BOTSORT(args=args)\n",
    "\n",
    "        # ---------------- Face Recognition ----------------\n",
    "        self.face_app = FaceAnalysis(name=\"buffalo_l\", root=\"insightface\", providers=['CUDAExecutionProvider'])\n",
    "        self.face_app.prepare(ctx_id=0)\n",
    "\n",
    "        # Load DB + FAISS\n",
    "        self.names, self.index = self._load_faiss_index(db_path)\n",
    "\n",
    "        # Bookkeeping\n",
    "        self.id_name_map = {}\n",
    "        self.timing = defaultdict(float)\n",
    "        self.timing[\"buffalo_processing\"] = 0.0\n",
    "        self.timing[\"faiss_search\"] = 0.0\n",
    "\n",
    "    def _load_faiss_index(self, db_path):\n",
    "        with open(db_path, \"rb\") as f:\n",
    "            face_db_list = pickle.load(f)\n",
    "        names, embeddings = zip(*face_db_list)\n",
    "        names = np.array(names)\n",
    "        embeddings = np.stack(embeddings).astype(\"float32\")\n",
    "\n",
    "        N, dim = len(embeddings), embeddings.shape[1]\n",
    "        nlist = max(1, min(N, int(4 * np.sqrt(N))))\n",
    "        nprobe = max(1, nlist // 4)\n",
    "\n",
    "        quantizer = faiss.IndexFlatIP(dim)\n",
    "        index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "        print(\"Training FAISS index...\")\n",
    "        index.train(embeddings)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        index.add(embeddings)\n",
    "        index.nprobe = nprobe\n",
    "\n",
    "        print(f\"--- FAISS Config: N={N}, dim={dim}, nlist={nlist}, nprobe={nprobe} ---\")\n",
    "        return names, index\n",
    "\n",
    "    def _process_crop(self, tid, crop):\n",
    "        t0_buffalo = time.perf_counter()\n",
    "        faces = self.face_app.get(crop)\n",
    "        self.timing[\"buffalo_processing\"] += time.perf_counter() - t0_buffalo\n",
    "\n",
    "        if not faces:\n",
    "            return tid, \"No face\"\n",
    "\n",
    "        best_score, best_match = -1.0, \"Unknown\"\n",
    "        for face in faces:\n",
    "            if face['det_score'] > 0.55:\n",
    "                emb = face['embedding'].astype('float32')\n",
    "                t0_faiss = time.perf_counter()\n",
    "                faiss.normalize_L2(emb.reshape(1, -1))\n",
    "                scores, indices = self.index.search(emb.reshape(1, -1), 1)\n",
    "                self.timing[\"faiss_search\"] += time.perf_counter() - t0_faiss\n",
    "\n",
    "                score, idx = scores[0][0], indices[0][0]\n",
    "                match_name = self.names[idx].replace(\".jpg\", \"\")\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = match_name if score >= self.sim_threshold else \"Unknown\"\n",
    "\n",
    "        return tid, best_match\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Error: Could not open video file.\")\n",
    "\n",
    "        width, height = int(cap.get(3)), int(cap.get(4))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        out = cv2.VideoWriter(\n",
    "            self.output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "            fps,\n",
    "            (width, height)\n",
    "        )\n",
    "\n",
    "        frame_idx = 0\n",
    "        start_time = time.perf_counter()  # <-- start timer\n",
    "        while cap.isOpened():\n",
    "            t0 = time.perf_counter()\n",
    "            ret, frame = cap.read()\n",
    "            self.timing[\"frame_extraction\"] += time.perf_counter() - t0\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # ---------------- YOLO Detection ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            results = self.model(frame, classes=[0], conf=0.4, iou=0.7, verbose=False)[0]\n",
    "            self.timing[\"yolo_inference\"] += time.perf_counter() - t0\n",
    "\n",
    "            if results.boxes is None or len(results.boxes) == 0:\n",
    "                out.write(frame)\n",
    "                continue\n",
    "\n",
    "            # Convert YOLO boxes to tracker input\n",
    "            bboxes = results.boxes.xyxy.detach().cpu()\n",
    "            confs = results.boxes.conf.detach().cpu()\n",
    "            cls = results.boxes.cls.detach().cpu()\n",
    "            dets_tensor = torch.hstack([bboxes, confs.unsqueeze(1), cls.unsqueeze(1)])\n",
    "            dets = Boxes(dets_tensor, frame.shape[:2])\n",
    "\n",
    "            # ---------------- Tracker Update ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            tracks = self.tracker.update(dets, frame)\n",
    "            self.timing[\"tracker_update\"] += time.perf_counter() - t0\n",
    "\n",
    "            # ---------------- Sequential Face Recognition per Track ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            for t in tracks:\n",
    "                x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                h = y2 - y1\n",
    "                face_crop = frame[y1:y1 + int(h * 0.5), x1:x2]  # Crop top half of person bbox\n",
    "                if face_crop.size:\n",
    "                    tid, name = self._process_crop(int(track_id), face_crop)\n",
    "                    if tid not in self.id_name_map:\n",
    "                        self.id_name_map[tid] = []\n",
    "                    self.id_name_map[tid].append(name)\n",
    "            self.timing[\"sequential_face\"] += time.perf_counter() - t0\n",
    "\n",
    "            # ---------------- Draw and Write ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            for t in tracks:\n",
    "                x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                name = self.id_name_map.get(int(track_id), [\"No face\"])[-1]\n",
    "                color, label = self._get_color_label(name, track_id)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            out.write(frame)\n",
    "            frame_idx += 1\n",
    "            self.timing[\"draw_and_write\"] += time.perf_counter() - t0\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        end_time = time.perf_counter()  # <-- end timer\n",
    "        total_exec_time = end_time - start_time\n",
    "        self._finalize_results()\n",
    "        print(f\"Total Execution Time: {total_exec_time:.2f} seconds ({total_exec_time/60:.2f} minutes)\")\n",
    "\n",
    "    def _get_color_label(self, name, tid):\n",
    "        if name == \"No face\":\n",
    "            return (0, 255, 0), f\"No face (ID:{tid})\"\n",
    "        elif name != \"Unknown\":\n",
    "            return (255, 0, 0), f\"{name} (ID:{tid})\"\n",
    "        else:\n",
    "            return (0, 0, 255), f\"Unknown (ID:{tid})\"\n",
    "\n",
    "    def _finalize_results(self):\n",
    "        finalized = {}\n",
    "        for tid, names_list in self.id_name_map.items():\n",
    "            # Remove invalid names first\n",
    "            valid_names = [n for n in names_list if n not in [\"Unknown\", \"No face\"]]\n",
    "    \n",
    "            if valid_names:\n",
    "                # Pick the most frequent valid name\n",
    "                final_name = max(set(valid_names), key=valid_names.count)\n",
    "            else:\n",
    "                # No valid names → check priority\n",
    "                if \"Unknown\" in names_list:\n",
    "                    final_name = \"Unknown\"\n",
    "                else:\n",
    "                    final_name = \"No face\"\n",
    "    \n",
    "            finalized[tid] = final_name\n",
    "    \n",
    "        with open(\"id_name_map.json\", \"w\") as f:\n",
    "            json.dump(self.id_name_map, f, indent=2)\n",
    "        with open(\"finalized_id_name_map.json\", \"w\") as f:\n",
    "            json.dump(finalized, f, indent=2)\n",
    "    \n",
    "        print(f\"Unique IDs: {len(finalized)}\")\n",
    "        \n",
    "        print(\"===== Timing Summary =====\")\n",
    "        for k, v in self.timing.items():\n",
    "            print(f\"{k}: {v:.4f}s\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = FaceReIDPipeline(\n",
    "        # video_path=\"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\",\n",
    "        # video_path=\"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\",\n",
    "        video_path=\"GunnyTest.mp4\",\n",
    "        db_path=\"face_database_gudivada.pkl\",\n",
    "        output_path=\"gudivada+yolo+v8l+ReID_sequential.avi\"\n",
    "    )\n",
    "    pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39de719",
   "metadata": {},
   "source": [
    "oop version with yolo and botsort separate and sequential face processing and printing detected persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import faiss\n",
    "import torch\n",
    "from ultralytics.engine.results import Boxes\n",
    "from ultralytics.trackers.bot_sort import BOTSORT\n",
    "from types import SimpleNamespace\n",
    "import time\n",
    " \n",
    "class FaceReIDPipeline:\n",
    "    def __init__(self, video_path, db_path, output_path, yolo_model=\"yolov8l.pt\", sim_threshold=0.40):\n",
    "        # Config\n",
    "        self.ist = pytz.timezone(\"Asia/Kolkata\")\n",
    "        self.video_path = video_path\n",
    "        self.output_path = output_path\n",
    "        self.sim_threshold = sim_threshold\n",
    " \n",
    "        # ---------------- YOLO Detector ----------------\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = YOLO(yolo_model).to(self.device)\n",
    " \n",
    "        # ---------------- Tracker (BoT-SORT) ----------------\n",
    "        tracker_args = {\n",
    "            \"tracker_type\": \"botsort\",\n",
    "            \"track_high_thresh\": 0.5,\n",
    "            \"track_low_thresh\": 0.3,\n",
    "            \"new_track_thresh\": 0.5,\n",
    "            \"track_buffer\": 500,\n",
    "            \"match_thresh\": 0.95,\n",
    "            \"fuse_score\": True,\n",
    "            \"gmc_method\": None,\n",
    "            \"proximity_thresh\": 0.5,\n",
    "            \"appearance_thresh\": 0.8,\n",
    "            \"with_reid\": False,\n",
    "            \"model\": \"auto\"\n",
    "        }\n",
    "        args = SimpleNamespace(**tracker_args)\n",
    "        self.tracker = BOTSORT(args=args)\n",
    " \n",
    "        # ---------------- Face Recognition ----------------\n",
    "        self.face_app = FaceAnalysis(name=\"buffalo_l\", root=\"face_recognition/insightface\", providers=['CUDAExecutionProvider'])\n",
    "        self.face_app.prepare(ctx_id=0)\n",
    " \n",
    "        # Load DB + FAISS\n",
    "        self.names, self.index = self._load_faiss_index(db_path)\n",
    " \n",
    "        # Bookkeeping\n",
    "        self.id_name_map = {}\n",
    "        # self.timing = defaultdict(float)\n",
    "        # self.timing[\"buffalo_processing\"] = 0.0\n",
    "        # self.timing[\"faiss_search\"] = 0.0\n",
    "        self.timing = defaultdict(float)\n",
    "        # self.timing.update({\n",
    "        #     \"frame_extraction\": 0.0,\n",
    "        #     \"yolo_inference\": 0.0,\n",
    "        #     \"tracker_update\": 0.0,\n",
    "        #     \"sequential_face\": 0.0,\n",
    "        #     \"draw_and_write\": 0.0,\n",
    "        #     \"buffalo_processing\": 0.0,\n",
    "        #     \"faiss_search\": 0.0\n",
    "        # })\n",
    "\n",
    "        self.timing.update({\n",
    "        \"frame_extraction\": 0.0,    # cap.read()\n",
    "        \"yolo_inference\": 0.0,\n",
    "        \"tracker_update\": 0.0,\n",
    "        \"sequential_face\": 0.0,\n",
    "        \"draw_and_write\": 0.0,\n",
    "        \"no_det\": 0.0,         # out.write()\n",
    "        \"buffalo_processing\": 0.0,\n",
    "        \"faiss_search\": 0.0,\n",
    "        \"skipped_frames\": 0.0,      # cost of skipping frames\n",
    "    })\n",
    "\n",
    " \n",
    "    def _load_faiss_index(self, db_path):\n",
    "        with open(db_path, \"rb\") as f:\n",
    "            face_db_list = pickle.load(f)\n",
    "        names, embeddings = zip(*face_db_list)\n",
    "        names = np.array(names)\n",
    "        embeddings = np.stack(embeddings).astype(\"float32\")\n",
    " \n",
    "        N, dim = len(embeddings), embeddings.shape[1]\n",
    "        nlist = max(1, min(N, int(4 * np.sqrt(N))))\n",
    "        nprobe = max(1, nlist // 4)\n",
    " \n",
    "        quantizer = faiss.IndexFlatIP(dim)\n",
    "        index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "        print(\"Training FAISS index...\")\n",
    "        index.train(embeddings)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        index.add(embeddings)\n",
    "        index.nprobe = nprobe\n",
    " \n",
    "        print(f\"--- FAISS Config: N={N}, dim={dim}, nlist={nlist}, nprobe={nprobe} ---\")\n",
    "        return names, index\n",
    " \n",
    "    def _process_crop(self, tid, crop):\n",
    "        t0_buffalo = time.perf_counter()\n",
    "        faces = self.face_app.get(crop)\n",
    "        self.timing[\"buffalo_processing\"] += time.perf_counter() - t0_buffalo\n",
    " \n",
    "        if not faces:\n",
    "            return tid, \"No face\"\n",
    " \n",
    "        best_score, best_match = -1.0, \"Unknown\"\n",
    "        for face in faces:\n",
    "            if face['det_score'] > 0.55:\n",
    "                emb = face['embedding'].astype('float32')\n",
    "                t0_faiss = time.perf_counter()\n",
    "                faiss.normalize_L2(emb.reshape(1, -1))\n",
    "                scores, indices = self.index.search(emb.reshape(1, -1), 1)\n",
    "                self.timing[\"faiss_search\"] += time.perf_counter() - t0_faiss\n",
    " \n",
    "                score, idx = scores[0][0], indices[0][0]\n",
    "                match_name = self.names[idx].replace(\".jpg\", \"\")\n",
    " \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = match_name if score >= self.sim_threshold else \"Unknown\"\n",
    " \n",
    "        return tid, best_match\n",
    " \n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Error: Could not open video file.\")\n",
    " \n",
    "        width, height = int(cap.get(3)), int(cap.get(4))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        output_fps=fps/5\n",
    "        out = cv2.VideoWriter(\n",
    "            self.output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "            output_fps,\n",
    "            (width, height)\n",
    "        )\n",
    " \n",
    "        frame_idx = 1\n",
    "        start = time.perf_counter()  # <-- start timer\n",
    "        while cap.isOpened():\n",
    "            t0 = time.perf_counter()\n",
    "            ret, frame = cap.read()\n",
    "            self.timing[\"frame_extraction\"] += time.perf_counter() - t0\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_idx%5!=0:\n",
    "                t0 = time.perf_counter()\n",
    "                frame_idx+=1\n",
    "                self.timing[\"skipped_frames\"] += time.perf_counter() - t0\n",
    "                continue\n",
    "            frame_idx += 1\n",
    "            print(\"processing frame:\", frame_idx)\n",
    "            \n",
    "            # ---------------- YOLO Detection ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            results = self.model(frame, classes=[0], conf=0.4, iou=0.7, verbose=False)[0]\n",
    "            self.timing[\"yolo_inference\"] += time.perf_counter() - t0\n",
    " \n",
    "            if results.boxes is None or len(results.boxes) == 0:\n",
    "                t0 = time.perf_counter()\n",
    "                out.write(frame)\n",
    "                self.timing[\"no_det\"] += time.perf_counter() - t0\n",
    "                continue\n",
    " \n",
    "            # Convert YOLO boxes to tracker input\n",
    "            bboxes = results.boxes.xyxy.detach().cpu()\n",
    "            confs = results.boxes.conf.detach().cpu()\n",
    "            cls = results.boxes.cls.detach().cpu()\n",
    "            dets_tensor = torch.hstack([bboxes, confs.unsqueeze(1), cls.unsqueeze(1)])\n",
    "            dets = Boxes(dets_tensor, frame.shape[:2])\n",
    " \n",
    "            # ---------------- Tracker Update ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            tracks = self.tracker.update(dets, frame)\n",
    "            self.timing[\"tracker_update\"] += time.perf_counter() - t0\n",
    " \n",
    "            # ---------------- Sequential Face Recognition per Track ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            for t in tracks:\n",
    "                x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                h = y2 - y1\n",
    "                face_crop = frame[y1:y1 + int(h * 0.5), x1:x2]  # Crop top half of person bbox\n",
    "                if face_crop.size:\n",
    "                    tid, name = self._process_crop(int(track_id), face_crop)\n",
    "                    if tid not in self.id_name_map:\n",
    "                        self.id_name_map[tid] = []\n",
    "                    self.id_name_map[tid].append(name)\n",
    "            self.timing[\"sequential_face\"] += time.perf_counter() - t0\n",
    " \n",
    "            # ---------------- Draw and Write ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            for t in tracks:\n",
    "                x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                name = self.id_name_map.get(int(track_id), [\"No face\"])[-1]\n",
    "                color, label = self._get_color_label(name, track_id)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            out.write(frame)\n",
    "            \n",
    "            self.timing[\"draw_and_write\"] += time.perf_counter() - t0\n",
    " \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        total_exec_time = time.perf_counter() - start\n",
    "        self._finalize_results()\n",
    "        print(f\"Total Execution Time: {total_exec_time:.4f} seconds ({total_exec_time/60:.2f} minutes)\")\n",
    " \n",
    "    def _get_color_label(self, name, tid):\n",
    "        if name == \"No face\":\n",
    "            return (0, 255, 0), f\"No face (ID:{tid})\"\n",
    "        elif name != \"Unknown\":\n",
    "            return (255, 0, 0), f\"{name} (ID:{tid})\"\n",
    "        else:\n",
    "            return (0, 0, 255), f\"Unknown (ID:{tid})\"\n",
    " \n",
    "\n",
    "\n",
    "    def _finalize_results(self):\n",
    "        finalized = {}\n",
    "        for tid, names_list in self.id_name_map.items():\n",
    "            # Remove invalid names first\n",
    "            valid_names = [n for n in names_list if n not in [\"Unknown\", \"No face\"]]\n",
    "    \n",
    "            if valid_names:\n",
    "                # Pick the most frequent valid name\n",
    "                final_name = max(set(valid_names), key=valid_names.count)\n",
    "            else:\n",
    "                # No valid names → check priority\n",
    "                if \"Unknown\" in names_list:\n",
    "                    final_name = \"Unknown\"\n",
    "                else:\n",
    "                    final_name = \"No face\"\n",
    "    \n",
    "            finalized[tid] = final_name\n",
    " \n",
    "        # Save raw + finalized mappings\n",
    "        with open(\"id_name_map.json\", \"w\") as f:\n",
    "            json.dump(self.id_name_map, f, indent=2)\n",
    "        with open(\"finalized_id_name_map.json\", \"w\") as f:\n",
    "            json.dump(finalized, f, indent=2)\n",
    " \n",
    "        print(f\"Unique IDs: {len(finalized)}\")\n",
    " \n",
    "        # ---- Collect unique person names ----\n",
    "        unique_names = sorted({name for name in finalized.values() if name not in [\"Unknown\", \"No face\"]})\n",
    " \n",
    "        if unique_names:\n",
    "            print(\", \".join(unique_names))\n",
    "            print(f\"total persons detected: {len(unique_names)}\")\n",
    "        else:\n",
    "            print(\"No valid persons detected\")\n",
    " \n",
    "        print(\"===== Timing Summary =====\")\n",
    "        for k, v in self.timing.items():\n",
    "            print(f\"{k}: {v:.4f}s\")\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = FaceReIDPipeline(\n",
    "        # video_path=\"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\",\n",
    "        # video_path=\"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\",\n",
    "        # video_path=\"gudivada_test_1.mp4\",\n",
    "        video_path=\"083ba5b4-4cf9-485c-ba69-f539e4f4ace4.mp4\",\n",
    "        db_path=\"face_database_gudivada.pkl\",\n",
    "        output_path=\"gudivada-testing1.avi\"\n",
    "    )\n",
    "    pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03858185",
   "metadata": {},
   "source": [
    "after processing save the detected persons in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be505182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import faiss\n",
    "import torch\n",
    "from ultralytics.engine.results import Boxes\n",
    "from ultralytics.trackers.bot_sort import BOTSORT\n",
    "from types import SimpleNamespace\n",
    "import time\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FaceReIDPipeline:\n",
    "    def __init__(self, video_path, db_path, output_path, yolo_model=\"yolov8l.pt\", sim_threshold=0.40):\n",
    "        # Config\n",
    "        self.ist = pytz.timezone(\"Asia/Kolkata\")\n",
    "        self.video_path = video_path\n",
    "        self.output_path = output_path\n",
    "        self.sim_threshold = sim_threshold\n",
    " \n",
    "        # ---------------- YOLO Detector ----------------\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = YOLO(yolo_model).to(self.device)\n",
    " \n",
    "        # ---------------- Tracker (BoT-SORT) ----------------\n",
    "        tracker_args = {\n",
    "            \"tracker_type\": \"botsort\",\n",
    "            \"track_high_thresh\": 0.5,\n",
    "            \"track_low_thresh\": 0.3,\n",
    "            \"new_track_thresh\": 0.5,\n",
    "            \"track_buffer\": 500,\n",
    "            \"match_thresh\": 0.95,\n",
    "            \"fuse_score\": True,\n",
    "            \"gmc_method\": None,\n",
    "            \"proximity_thresh\": 0.5,\n",
    "            \"appearance_thresh\": 0.8,\n",
    "            \"with_reid\": False,\n",
    "            \"model\": \"auto\"\n",
    "        }\n",
    "        args = SimpleNamespace(**tracker_args)\n",
    "        self.tracker = BOTSORT(args=args)\n",
    " \n",
    "        # ---------------- Face Recognition ----------------\n",
    "        self.face_app = FaceAnalysis(name=\"buffalo_l\", root=\"face_recognition/insightface\", providers=['CUDAExecutionProvider'])\n",
    "        self.face_app.prepare(ctx_id=0)\n",
    " \n",
    "        # Load DB + FAISS\n",
    "        self.names, self.index = self._load_faiss_index(db_path)\n",
    " \n",
    "        # Bookkeeping\n",
    "        self.id_name_map = {}\n",
    "        # self.timing = defaultdict(float)\n",
    "        # self.timing[\"buffalo_processing\"] = 0.0\n",
    "        # self.timing[\"faiss_search\"] = 0.0\n",
    "        self.timing = defaultdict(float)\n",
    "        # self.timing.update({\n",
    "        #     \"frame_extraction\": 0.0,\n",
    "        #     \"yolo_inference\": 0.0,\n",
    "        #     \"tracker_update\": 0.0,\n",
    "        #     \"sequential_face\": 0.0,\n",
    "        #     \"draw_and_write\": 0.0,\n",
    "        #     \"buffalo_processing\": 0.0,\n",
    "        #     \"faiss_search\": 0.0\n",
    "        # })\n",
    "\n",
    "        self.timing.update({\n",
    "        \"frame_extraction\": 0.0,    # cap.read()\n",
    "        \"yolo_inference\": 0.0,\n",
    "        \"tracker_update\": 0.0,\n",
    "        \"sequential_face\": 0.0,\n",
    "        \"draw_and_write\": 0.0,\n",
    "        \"no_det\": 0.0,         # out.write()\n",
    "        \"buffalo_processing\": 0.0,\n",
    "        \"faiss_search\": 0.0,\n",
    "        \"skipped_frames\": 0.0,      # cost of skipping frames\n",
    "    })\n",
    "        self.best_face_per_id = {}  # track_id -> (crop, name, conf)\n",
    "\n",
    "    # def _update_best_face(self, tid, crop, name, conf):\n",
    "    #     if name in [\"No face\"]:\n",
    "    #         return\n",
    "    #     if tid not in self.best_face_per_id or conf > self.best_face_per_id[tid][2]:\n",
    "    #         # store crop, name, conf\n",
    "    #         self.best_face_per_id[tid] = (crop.copy(), name, conf)\n",
    "\n",
    "    def _update_best_face(self, tid, crop, name, conf, embedding=None):\n",
    "        if name == \"No face\":\n",
    "            return\n",
    "        if name == \"Unknown\":\n",
    "            if tid not in self.best_face_per_id or self.best_face_per_id[tid][1] == \"Unknown\":\n",
    "                if tid not in self.best_face_per_id or conf > self.best_face_per_id[tid][2]:\n",
    "                    self.best_face_per_id[tid] = (crop.copy(), name, conf, embedding.copy() if embedding is not None else None)\n",
    "            return\n",
    "        if tid not in self.best_face_per_id:\n",
    "            self.best_face_per_id[tid] = (crop.copy(), name, conf, embedding.copy() if embedding is not None else None)\n",
    "        else:\n",
    "            if self.best_face_per_id[tid][1] == \"Unknown\":\n",
    "                self.best_face_per_id[tid] = (crop.copy(), name, conf, embedding.copy() if embedding is not None else None)\n",
    "\n",
    "    # def _save_all_best_faces(self):\n",
    "    #     os.makedirs(\"person_images\", exist_ok=True)\n",
    "    #     embeddings_list = []\n",
    "    #     for tid, (crop, name, conf, embedding) in self.best_face_per_id.items():\n",
    "    #         filename = f\"{name}_ID{tid}_{uuid.uuid4().hex[:8]}.jpg\"\n",
    "    #         filepath = os.path.join(\"person_images\", filename)\n",
    "    #         cv2.imwrite(filepath, crop)\n",
    "    #         print(f\"Saved best crop for ID:{tid} → {name} | conf={conf:.2f}\")\n",
    "    #         embeddings_list.append((filename, embedding))\n",
    "\n",
    "    #     # Save embeddings for all images\n",
    "    #     with open(\"person_images_embeddings.pkl\", \"wb\") as f:\n",
    "    #         pickle.dump(embeddings_list, f)\n",
    "    #     print(f\"Saved embeddings for {len(embeddings_list)} images.\")\n",
    "    def _save_all_best_faces(self):\n",
    "        os.makedirs(\"person_images\", exist_ok=True)\n",
    "\n",
    "        # Separate authorized (known names) and unauthorized (unknown/no face)\n",
    "        authorized_best = {}\n",
    "        unauthorized_best = {}\n",
    "\n",
    "        # Select best crop per category\n",
    "        for tid, (crop, name, conf, embedding) in self.best_face_per_id.items():\n",
    "            if name not in [\"Unknown\", \"No face\"]:\n",
    "                # For each known person, store the highest confidence\n",
    "                if name not in authorized_best or conf > authorized_best[name][2]:\n",
    "                    authorized_best[name] = (crop.copy(), name, conf, embedding.copy() if embedding is not None else None)\n",
    "            elif name in [\"Unknown\"]:\n",
    "                # For each unauthorized ID, store the highest confidence\n",
    "                if tid not in unauthorized_best or conf > unauthorized_best[tid][2]:\n",
    "                    unauthorized_best[tid] = (crop.copy(), name, conf, embedding.copy() if embedding is not None else None)\n",
    "\n",
    "        embeddings_list = []\n",
    "\n",
    "        # Save authorized crops\n",
    "        for name, (crop, _, conf, embedding) in authorized_best.items():\n",
    "            filename = f\"{name}_{uuid.uuid4().hex[:8]}.jpg\"\n",
    "            filepath = os.path.join(\"person_images\", filename)\n",
    "            cv2.imwrite(filepath, crop)\n",
    "            print(f\"✅ Saved best authorized crop for {name} | conf={conf:.2f}\")\n",
    "            embeddings_list.append((filename, embedding))\n",
    "\n",
    "        # Save unauthorized crops (Unknown/No face)\n",
    "        for tid, (crop, name, conf, embedding) in unauthorized_best.items():\n",
    "            filename = f\"{name}_ID{tid}_{uuid.uuid4().hex[:8]}.jpg\"\n",
    "            filepath = os.path.join(\"person_images\", filename)\n",
    "            cv2.imwrite(filepath, crop)\n",
    "            print(f\"⚠️  Saved best unauthorized crop for ID:{tid} ({name}) | conf={conf:.2f}\")\n",
    "            embeddings_list.append((filename, embedding))\n",
    "\n",
    "        # Save embeddings for all saved images\n",
    "        with open(\"person_images_embeddings (not triton).pkl\", \"wb\") as f:\n",
    "            pickle.dump(embeddings_list, f)\n",
    "        print(f\"💾 Saved embeddings for {len(embeddings_list)} images.\")\n",
    "\n",
    "\n",
    "    \n",
    "    def _load_faiss_index(self, db_path):\n",
    "        with open(db_path, \"rb\") as f:\n",
    "            face_db_list = pickle.load(f)\n",
    "        names, embeddings = zip(*face_db_list)\n",
    "        names = np.array(names)\n",
    "        embeddings = np.stack(embeddings).astype(\"float32\")\n",
    " \n",
    "        N, dim = len(embeddings), embeddings.shape[1]\n",
    "        nlist = max(1, min(N, int(4 * np.sqrt(N))))\n",
    "        nprobe = max(1, nlist // 4)\n",
    " \n",
    "        quantizer = faiss.IndexFlatIP(dim)\n",
    "        index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "        print(\"Training FAISS index...\")\n",
    "        index.train(embeddings)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        index.add(embeddings)\n",
    "        index.nprobe = nprobe\n",
    " \n",
    "        print(f\"--- FAISS Config: N={N}, dim={dim}, nlist={nlist}, nprobe={nprobe} ---\")\n",
    "        return names, index\n",
    " \n",
    "    def _process_crop(self, tid, crop):\n",
    "        t0_buffalo = time.perf_counter()\n",
    "        faces = self.face_app.get(crop)\n",
    "        self.timing[\"buffalo_processing\"] += time.perf_counter() - t0_buffalo\n",
    " \n",
    "        if not faces:\n",
    "            return tid, \"No face\", 0.0, None\n",
    " \n",
    "        best_score, best_match, best_conf = -1.0, \"Unknown\", 0.0\n",
    "        best_face_embedding = None\n",
    "        for face in faces:\n",
    "            if face['det_score'] > 0.50:\n",
    "                emb = face['embedding'].astype('float32')\n",
    "                t0_faiss = time.perf_counter()\n",
    "                faiss.normalize_L2(emb.reshape(1, -1))\n",
    "                scores, indices = self.index.search(emb.reshape(1, -1), 1)\n",
    "                self.timing[\"faiss_search\"] += time.perf_counter() - t0_faiss\n",
    " \n",
    "                score, idx = scores[0][0], indices[0][0]\n",
    "                match_name = self.names[idx].replace(\".jpg\", \"\")\n",
    " \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = match_name if score >= self.sim_threshold else \"Unknown\"\n",
    "                    best_conf = face.det_score\n",
    "                    best_face_embedding = emb  # store the embedding of the selected face\n",
    " \n",
    "        return tid, best_match, best_conf, best_face_embedding\n",
    " \n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Error: Could not open video file.\")\n",
    "\n",
    "        width, height = int(cap.get(3)), int(cap.get(4))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        output_fps=fps/1\n",
    "        out = cv2.VideoWriter(\n",
    "            self.output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "            output_fps,\n",
    "            (width, height)\n",
    "        )\n",
    "\n",
    "        frame_idx = 1\n",
    "        start = time.perf_counter()\n",
    "        while cap.isOpened():\n",
    "            t0 = time.perf_counter()\n",
    "            ret, frame = cap.read()\n",
    "            self.timing[\"frame_extraction\"] += time.perf_counter() - t0\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # if frame_idx % 5 != 0:\n",
    "            #     t0 = time.perf_counter()\n",
    "            #     frame_idx += 1\n",
    "            #     self.timing[\"skipped_frames\"] += time.perf_counter() - t0\n",
    "            #     continue\n",
    "            frame_idx += 1\n",
    "            \n",
    "            # ---------------- YOLO Detection ----------------\n",
    "            t0 = time.perf_counter()\n",
    "            results = self.model(frame, classes=[0], conf=0.4, iou=0.7, verbose=False)[0]\n",
    "            self.timing[\"yolo_inference\"] += time.perf_counter() - t0\n",
    "\n",
    "            if results.boxes is None or len(results.boxes) == 0:\n",
    "                t0 = time.perf_counter()\n",
    "                out.write(frame)\n",
    "                self.timing[\"no_det\"] += time.perf_counter() - t0\n",
    "                continue\n",
    "\n",
    "            # Tracker update & face processing\n",
    "            bboxes = results.boxes.xyxy.detach().cpu()\n",
    "            confs = results.boxes.conf.detach().cpu()\n",
    "            cls = results.boxes.cls.detach().cpu()\n",
    "            dets_tensor = torch.hstack([bboxes, confs.unsqueeze(1), cls.unsqueeze(1)])\n",
    "            dets = Boxes(dets_tensor, frame.shape[:2])\n",
    "\n",
    "            t0 = time.perf_counter()\n",
    "            tracks = self.tracker.update(dets, frame)\n",
    "            self.timing[\"tracker_update\"] += time.perf_counter() - t0\n",
    "\n",
    "            t0 = time.perf_counter()\n",
    "            for t in tracks:\n",
    "                x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                tid = int(track_id)  # ✅ make sure hashable INT\n",
    "                h = y2 - y1\n",
    "                face_crop = frame[y1:y1 + int(h * 0.5), x1:x2]\n",
    "                if face_crop.size:\n",
    "                    tid, name, conf, embedding = self._process_crop(tid, face_crop)\n",
    "                    if tid not in self.id_name_map:\n",
    "                        self.id_name_map[tid] = []\n",
    "                    self.id_name_map[tid].append(name)\n",
    "                    self._update_best_face(tid, face_crop, name, conf, embedding)\n",
    "            self.timing[\"sequential_face\"] += time.perf_counter() - t0\n",
    "\n",
    "            # Draw + write frame\n",
    "            t0 = time.perf_counter()\n",
    "            for t in tracks:\n",
    "                x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                name = self.id_name_map.get(int(track_id), [\"No face\"])[-1]\n",
    "                color, label = self._get_color_label(name, track_id)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            out.write(frame)\n",
    "            self.timing[\"draw_and_write\"] += time.perf_counter() - t0\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        # ✅ Save the best face per ID\n",
    "        self._save_all_best_faces()\n",
    "\n",
    "        total_exec_time = time.perf_counter() - start\n",
    "        self._finalize_results()\n",
    "        print(f\"Total Execution Time: {total_exec_time:.4f} seconds ({total_exec_time/60:.2f} minutes)\")\n",
    " \n",
    "    def _get_color_label(self, name, tid):\n",
    "        if name == \"No face\":\n",
    "            return (0, 255, 0), f\"No face (ID:{tid})\"\n",
    "        elif name != \"Unknown\":\n",
    "            return (255, 0, 0), f\"{name} (ID:{tid})\"\n",
    "        else:\n",
    "            return (0, 0, 255), f\"Unknown (ID:{tid})\"\n",
    " \n",
    "\n",
    "\n",
    "    def _finalize_results(self):\n",
    "        finalized = {}\n",
    "        for tid, names_list in self.id_name_map.items():\n",
    "            # Remove invalid names first\n",
    "            valid_names = [n for n in names_list if n not in [\"Unknown\", \"No face\"]]\n",
    "    \n",
    "            if valid_names:\n",
    "                # Pick the most frequent valid name\n",
    "                final_name = max(set(valid_names), key=valid_names.count)\n",
    "            else:\n",
    "                # No valid names → check priority\n",
    "                if \"Unknown\" in names_list:\n",
    "                    final_name = \"Unknown\"\n",
    "                else:\n",
    "                    final_name = \"No face\"\n",
    "    \n",
    "            finalized[tid] = final_name\n",
    " \n",
    "        # Save raw + finalized mappings\n",
    "        with open(\"id_name_map.json\", \"w\") as f:\n",
    "            json.dump(self.id_name_map, f, indent=2)\n",
    "        with open(\"finalized_id_name_map.json\", \"w\") as f:\n",
    "            json.dump(finalized, f, indent=2)\n",
    " \n",
    "        print(f\"Unique IDs: {len(finalized)}\")\n",
    " \n",
    "        # ---- Collect unique person names ----\n",
    "        unique_names = sorted({name for name in finalized.values() if name not in [\"Unknown\", \"No face\"]})\n",
    " \n",
    "        if unique_names:\n",
    "            print(\", \".join(unique_names))\n",
    "            print(f\"total persons detected: {len(unique_names)}\")\n",
    "        else:\n",
    "            print(\"No valid persons detected\")\n",
    " \n",
    "        print(\"===== Timing Summary =====\")\n",
    "        for k, v in self.timing.items():\n",
    "            print(f\"{k}: {v:.4f}s\")\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = FaceReIDPipeline(\n",
    "        # video_path=\"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\",\n",
    "        video_path=\"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\",\n",
    "        # video_path=\"gudivada_test_1.mp4\",\n",
    "        # video_path=\"083ba5b4-4cf9-485c-ba69-f539e4f4ace4.mp4\",\n",
    "        # video_path=\"17.mp4\",\n",
    "        db_path=\"face_database_nandhyala.pkl\",\n",
    "        output_path=\"gudivada-testing2.avi\"\n",
    "    )\n",
    "    pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bc074",
   "metadata": {},
   "source": [
    "clustering the images code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from insightface.app import FaceAnalysis\n",
    "import faiss\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- Setup Buffalo Model ----------------\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", root=\"face_recognition/insightface\", providers=['CUDAExecutionProvider'])\n",
    "face_app.prepare(ctx_id=0)\n",
    "\n",
    "# ---------------- Extract Embeddings ----------------\n",
    "person_dir = \"person_images\"\n",
    "images = [f for f in os.listdir(person_dir) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "embeddings = []\n",
    "img_names = []\n",
    "\n",
    "for img_name in images:\n",
    "    img_path = os.path.join(person_dir, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    faces = face_app.get(img)\n",
    "    if not faces:\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"no face found\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show(block=False)\n",
    "        plt.pause(1)\n",
    "        plt.close()\n",
    "        continue\n",
    "    \n",
    "    # take best face\n",
    "    face = max(faces, key=lambda f: f['det_score'])\n",
    "    # ✅ Draw bounding box\n",
    "    # x1, y1, x2, y2 = map(int, face['bbox'])\n",
    "    # annotated = img.copy()\n",
    "    # for face in faces:\n",
    "    x1, y1, x2, y2 = map(int, face['bbox'])\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        f\"{face['det_score']:.2f}\",\n",
    "        (x1, y1 - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.6,\n",
    "        (0, 255, 0),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    if face['det_score'] <= 0.50:\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"low score: {face['det_score']:.2f}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show(block=False)\n",
    "        plt.pause(1)\n",
    "        plt.close()\n",
    "        continue\n",
    "\n",
    "\n",
    "    # ✅ Display with matplotlib\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show(block=False)\n",
    "    plt.pause(1)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"det_score:\", face['det_score'])\n",
    "    emb = face['embedding'].astype(\"float32\")\n",
    "    embeddings.append(emb)\n",
    "    img_names.append(img_name)\n",
    "\n",
    "embeddings = np.array(embeddings, dtype=\"float32\")\n",
    "print(f\"Total embeddings extracted: {len(embeddings)}\")\n",
    "# ---------------- Group Embeddings ----------------\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# ---------------- Group Embeddings by Closest Match ----------------\n",
    "similarity_threshold = 0.4  # minimum similarity to consider same group\n",
    "groups = defaultdict(list)\n",
    "group_representatives = {}  # group_id → representative embedding\n",
    "assignments = {}  # embedding index → group id\n",
    "group_id_counter = 0\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    best_gid = None\n",
    "    best_sim = -1.0\n",
    "\n",
    "    # Compare this embedding with all existing group representatives\n",
    "    for gid, rep_emb in group_representatives.items():\n",
    "        sim = cosine_similarity(embeddings[i], rep_emb)\n",
    "        if sim > best_sim:\n",
    "            best_sim = sim\n",
    "            best_gid = gid\n",
    "\n",
    "    if best_sim >= similarity_threshold:\n",
    "        # Assign to closest group\n",
    "        groups[best_gid].append(img_names[i])\n",
    "        assignments[i] = best_gid\n",
    "    else:\n",
    "        # Create a new group\n",
    "        groups[group_id_counter].append(img_names[i])\n",
    "        assignments[i] = group_id_counter\n",
    "        group_representatives[group_id_counter] = embeddings[i]\n",
    "        group_id_counter += 1\n",
    "\n",
    "    # ---------------- Recompute representatives ----------------\n",
    "    # Update representative as the mean of current group embeddings\n",
    "    for gid, members in groups.items():\n",
    "        member_indices = [img_names.index(name) for name in members]\n",
    "        group_representatives[gid] = np.mean([embeddings[idx] for idx in member_indices], axis=0)\n",
    "\n",
    "# ---------------- Print Groups ----------------\n",
    "print(\"\\n✅ Grouped Faces (Best-Matching Assignment):\")\n",
    "for gid, members in groups.items():\n",
    "    print(f\"Group {gid}: {members}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "\n",
    "# =====================================================\n",
    "#                Load Embeddings\n",
    "# =====================================================\n",
    "# pkl_path = \"face_database_gudivada_trito.pkl\"\n",
    "# pkl_path = \"person_images_embeddings (not triton).pkl\"\n",
    "pkl_path=\"face_database_nandhyala_triton.pkl\"\n",
    "\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    embeddings_data = pickle.load(f)  # list of tuples: (filename, embedding)\n",
    "\n",
    "img_names = [item[0] for item in embeddings_data]\n",
    "embeddings = np.array([item[1] for item in embeddings_data], dtype=\"float32\")\n",
    "\n",
    "print(f\"✅ Loaded {len(embeddings)} embeddings from {pkl_path}\")\n",
    "\n",
    "# =====================================================\n",
    "#                Helper Functions\n",
    "# =====================================================\n",
    "\n",
    "def find_best_k(embeddings, max_k=10):\n",
    "    \"\"\"Automatically find best K using silhouette score\"\"\"\n",
    "    best_k, best_score = 2, -1\n",
    "    for k in range(2, min(max_k, len(embeddings))):\n",
    "        labels = KMeans(n_clusters=k, random_state=42).fit_predict(embeddings)\n",
    "        score = silhouette_score(embeddings, labels)\n",
    "        if score > best_score:\n",
    "            best_score, best_k = score, k\n",
    "    return best_k\n",
    "\n",
    "def find_best_threshold(embeddings, t_min=0.1, t_max=1.0, step=0.05):\n",
    "    \"\"\"Auto-tune Agglomerative threshold using silhouette\"\"\"\n",
    "    best_t, best_score = 0.5, -1\n",
    "    for t in np.arange(t_min, t_max, step):\n",
    "        model = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            distance_threshold=t,\n",
    "            metric=\"cosine\",\n",
    "            linkage=\"single\"\n",
    "            # linkage=\"average\"\n",
    "        )\n",
    "        labels = model.fit_predict(embeddings)\n",
    "        n_labels = len(set(labels))\n",
    "        if n_labels < 2 or n_labels >= len(embeddings):\n",
    "            continue\n",
    "        score = silhouette_score(embeddings, labels)\n",
    "        if score > best_score:\n",
    "            best_score, best_t = score, t\n",
    "    return best_t\n",
    "\n",
    "def run_kmeans(embeddings):\n",
    "    n_clusters = find_best_k(embeddings)\n",
    "    print(f\"➡ KMeans: Using dynamic n_clusters = {n_clusters}\")\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    return model.fit_predict(embeddings)\n",
    "\n",
    "def run_dbscan(embeddings, eps=0.35, min_samples=2):\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\")\n",
    "    labels = model.fit_predict(embeddings)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    print(f\"➡ DBSCAN: Found {n_clusters} clusters\")\n",
    "    return labels\n",
    "\n",
    "def run_agglomerative(embeddings):\n",
    "    best_t = find_best_threshold(embeddings)\n",
    "    print(f\"➡ Agglomerative: Using distance_threshold = {best_t:.3f}\")\n",
    "    model = AgglomerativeClustering(\n",
    "        n_clusters=None,\n",
    "        distance_threshold=best_t,\n",
    "        metric=\"cosine\",\n",
    "        linkage=\"single\"\n",
    "        # linkage=\"average\"\n",
    "    )\n",
    "    return model.fit_predict(embeddings)\n",
    "\n",
    "def print_groups(method_name, labels, img_names):\n",
    "    \"\"\"Print clusters with image names\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for name, lbl in zip(img_names, labels):\n",
    "        groups[lbl].append(name)\n",
    "    print(f\"\\n🔹 {method_name} Groups:\")\n",
    "    for lbl, members in groups.items():\n",
    "        if lbl == -1:\n",
    "            print(f\"  ❌ Noise: {members}\")\n",
    "        else:\n",
    "            print(f\"  Cluster {lbl}: {members}\")\n",
    "\n",
    "def plot_clusters(title, reduced_embeddings, labels, img_names):\n",
    "    \"\"\"Plot clusters with text labels\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    for color, lbl in zip(colors, unique_labels):\n",
    "        idxs = labels == lbl\n",
    "        plt.scatter(reduced_embeddings[idxs, 0], reduced_embeddings[idxs, 1],\n",
    "                    c=[color], label=f\"Cluster {lbl}\" if lbl != -1 else \"Noise\", s=40)\n",
    "        for i, name in enumerate(np.array(img_names)[idxs]):\n",
    "            plt.text(reduced_embeddings[idxs][i, 0],\n",
    "                     reduced_embeddings[idxs][i, 1],\n",
    "                     name, fontsize=8, color=\"black\", ha=\"center\", va=\"center\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# =====================================================\n",
    "#                Run and Visualize\n",
    "# =====================================================\n",
    "methods = {\n",
    "    \"KMeans\": run_kmeans(embeddings),\n",
    "    \"DBSCAN\": run_dbscan(embeddings, eps=0.35, min_samples=2),\n",
    "    \"Agglomerative\": run_agglomerative(embeddings)\n",
    "}\n",
    "\n",
    "# Reduce dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Print and visualize\n",
    "for name, labels in methods.items():\n",
    "    print_groups(name, labels, img_names)\n",
    "    plot_clusters(f\"{name} Clustering\", reduced_embeddings, labels, img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------------- Load embeddings ----------------\n",
    "person_dir = \"person_images\"\n",
    "pkl_path = os.path.join(\"person_images_embeddings.pkl\")\n",
    "\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    embeddings_data = pickle.load(f)  # list of tuples: (filename, embedding)\n",
    "\n",
    "img_names = [item[0] for item in embeddings_data]\n",
    "embeddings = np.array([item[1] for item in embeddings_data], dtype=\"float32\")\n",
    "\n",
    "print(f\"Loaded {len(embeddings)} embeddings from {pkl_path}\")\n",
    "\n",
    "# ---------------- Group Embeddings ----------------\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "similarity_threshold = 0.4  # minimum similarity to consider same group\n",
    "groups = defaultdict(list)\n",
    "assignments = {}  # embedding index → group id\n",
    "group_id_counter = 0\n",
    "used = set()  # track embeddings already assigned to a group\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    if i in used:\n",
    "        continue  # already grouped, skip\n",
    "\n",
    "    # create a new group with this embedding\n",
    "    groups[group_id_counter].append(img_names[i])\n",
    "    assignments[i] = group_id_counter\n",
    "    used.add(i)\n",
    "\n",
    "    # track best match for this embedding\n",
    "    best_j = None\n",
    "    best_sim = -1.0\n",
    "\n",
    "    # compare with all other embeddings (including ungrouped)\n",
    "    for j in range(len(embeddings)):\n",
    "        if j == i or j in used:\n",
    "            continue\n",
    "        sim = cosine_similarity(embeddings[i], embeddings[j])\n",
    "        if sim >= similarity_threshold and sim > best_sim:\n",
    "            best_sim = sim\n",
    "            best_j = j\n",
    "\n",
    "    # assign only the single best match\n",
    "    if best_j is not None:\n",
    "        groups[group_id_counter].append(img_names[best_j])\n",
    "        assignments[best_j] = group_id_counter\n",
    "        used.add(best_j)\n",
    "\n",
    "    group_id_counter += 1\n",
    "\n",
    "# ---------------- Print Groups ----------------\n",
    "print(\"\\n✅ Grouped Faces (Best Single Match):\")\n",
    "for gid, members in groups.items():\n",
    "    print(f\"Group {gid}: {members}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb27d80",
   "metadata": {},
   "source": [
    "Finetuning the code with conf thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import pytz\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import faiss\n",
    "import torch\n",
    "# Set timezone to IST\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    " \n",
    "# Initialize face recognition model\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "face_app.prepare(ctx_id=0)\n",
    " \n",
    "# Load face database\n",
    "with open(\"face_database_nandhyala.pkl\", \"rb\") as f:\n",
    "    face_db_list = pickle.load(f)\n",
    " \n",
    "names, embeddings = zip(*face_db_list)\n",
    "names = np.array(names)\n",
    "embeddings = np.stack(embeddings).astype('float32')\n",
    " \n",
    "# --- FAISS: Switch from IndexFlatIP (brute force) to IndexIVFFlat (IVF) ---\n",
    "dimension = embeddings.shape[1]\n",
    " \n",
    "# Optimized parameters for N=103 embeddings\n",
    "nlist = 10  # Number of clusters (approx. 4 * sqrt(103))\n",
    "nprobe = 5  # Number of clusters to search (higher for better accuracy on small datasets)\n",
    " \n",
    "# Step 1: Create a Flat (brute-force) index for training the clusters\n",
    "quantizer = faiss.IndexFlatIP(dimension)\n",
    " \n",
    "# Step 2: Create the IVF index\n",
    "index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    " \n",
    "# Step 3: Train the index on the embeddings\n",
    "print(\"Training FAISS Index...\")\n",
    "index.train(embeddings)\n",
    "print(\"Training complete.\")\n",
    " \n",
    "# Step 4: Add the embeddings to the trained index\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    " \n",
    "# Similarity threshold\n",
    "SIMILARITY_THRESHOLD = 0.40\n",
    " \n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "# model.export(format=\"onnx\", imgsz=[640,640])\n",
    "# model.to('cuda')\n",
    " \n",
    "# Prepare output directory for crops\n",
    "os.makedirs(\"id_frames\", exist_ok=True)\n",
    " \n",
    "# Start time\n",
    "start_time = datetime.now(ist)\n",
    "print(\"Start Time (IST):\", start_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    " \n",
    "# Video setup\n",
    "# video_path = \"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "video_path = \"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    " \n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file. Please check the file path and integrity.\")\n",
    "    exit()\n",
    " \n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "output_fps = fps / 3\n",
    "out = cv2.VideoWriter(\n",
    "    \"gudivada+yolo+v8l+ReIDON+timestamps.avi\",\n",
    "    cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "    fps,\n",
    "    (width, height)\n",
    ")\n",
    " \n",
    "# ID → Name map\n",
    "id_name_map = {}\n",
    "frame_count = 0\n",
    " \n",
    "#Logging\n",
    "entry_log = set()\n",
    "entry_data = []\n",
    " \n",
    "# Store bounding boxes for authorized & unknown IDs\n",
    "id_bboxes = {}\n",
    " \n",
    "# ---------- ThreadPool setup for parallel processing ----------\n",
    "executor = ThreadPoolExecutor(max_workers=4)\n",
    " \n",
    "# ---------- Modified process_crop ----------\n",
    "def process_crop(tid, crop, prev_score=0):\n",
    "    \"\"\"Performs face recognition on a single crop, returns (tid, name, score).\"\"\"\n",
    "    faces = face_app.get(crop)\n",
    "    if len(faces) > 0 and faces[0]['det_score'] > 0.55:\n",
    "        \n",
    "        emb = faces[0]['embedding'].astype('float32')\n",
    "        faiss.normalize_L2(emb.reshape(1, -1))\n",
    "        scores, indices = index.search(emb.reshape(1, -1), 1)\n",
    "        best_score = scores[0][0]\n",
    "        best_idx = indices[0][0]\n",
    "        best_match = names[best_idx].replace(\"jpg\", \"\")\n",
    "\n",
    "        if best_score >= SIMILARITY_THRESHOLD:\n",
    "            return tid, best_match, float(best_score)\n",
    "        else:\n",
    "            return tid, \"Unknown\", 0.0\n",
    "    return tid, \"No face\", 0.0\n",
    "    \n",
    " \n",
    "# ---------- Main loop ----------\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret :\n",
    "        break\n",
    "        \n",
    "    # if frame_count % 3 != 0:\n",
    "    #     # out.write(frame)\n",
    "    #     frame_count += 1\n",
    "    #     continue\n",
    "        \n",
    "    results = model.track(\n",
    "        frame,\n",
    "        tracker=\"botsort_1.yaml\",\n",
    "        persist=True,\n",
    "        classes=[0],\n",
    "        conf=0.5,\n",
    "        iou=0.8,\n",
    "        verbose=False\n",
    "    )\n",
    "       \n",
    "    crops, tids, prev_scores = [], [], []\n",
    "    if results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            tid = int(box.id[0])\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            dx, dy = 0, 5\n",
    "            new_x1, new_y1 = x1 + dx, y1 + dy\n",
    "            new_x2, new_y2 = x2 - dx, y2 - dy\n",
    "\n",
    "            if h < 100:\n",
    "                draw_y2 = new_y2\n",
    "            else:\n",
    "                face_ratio = 0.2 if h > 450 else 0.5\n",
    "                draw_y2 = y1 + int(h * face_ratio)\n",
    "\n",
    "            face_crop = frame[new_y1:draw_y2, new_x1:new_x2]\n",
    "\n",
    "            # --- Decision to run face recognition ---\n",
    "            need_recognition = False\n",
    "            prev_score = 0.0\n",
    "\n",
    "            if tid not in id_name_map:\n",
    "                need_recognition = True\n",
    "            else:\n",
    "                prev_entry = id_name_map[tid]\n",
    "                prev_name = prev_entry[\"name\"]\n",
    "                prev_score = prev_entry[\"score\"]\n",
    "\n",
    "                if prev_name in [\"Unknown\", \"No face\"]:\n",
    "                    need_recognition = True\n",
    "                else:\n",
    "                    # Always re-check, but only replace if confidence improves\n",
    "                    need_recognition = True\n",
    "\n",
    "            if need_recognition and face_crop.size != 0:\n",
    "                crops.append(face_crop)\n",
    "                tids.append(tid)\n",
    "                prev_scores.append(prev_score)\n",
    "\n",
    "        # ---------- Parallel face recognition ----------\n",
    "        futures = [executor.submit(process_crop, tid, crop, prev_score) \n",
    "                   for tid, crop, prev_score in zip(tids, crops, prev_scores)]\n",
    "\n",
    "        for f in futures:\n",
    "            tid, name, best_score = f.result()\n",
    "\n",
    "            if tid not in id_name_map:\n",
    "                id_name_map[tid] = {\"name\": name, \"score\": best_score}\n",
    "            else:\n",
    "                prev_entry = id_name_map[tid]\n",
    "                if name in [\"Unknown\", \"No face\"]:\n",
    "                    # Replace only if current is better than previous \"Unknown\"/\"No face\"\n",
    "                    if prev_entry[\"name\"] in [\"Unknown\", \"No face\"]:\n",
    "                        id_name_map[tid] = {\"name\": name, \"score\": best_score}\n",
    "                else:\n",
    "                    # Replace only if new detection is stronger\n",
    "                    if best_score > prev_entry[\"score\"]:\n",
    "                        id_name_map[tid] = {\"name\": name, \"score\": best_score}\n",
    "\n",
    "    # ---------- Draw and save based on updated id_name_map ----------\n",
    "    if results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            tid = int(box.id[0])\n",
    "            \n",
    "            entry = id_name_map.get(tid, {\"name\": \"No face\", \"score\": 0.0})\n",
    "            name_to_display = entry[\"name\"]\n",
    "            \n",
    "    #         timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    #         timestamp = str(timedelta(milliseconds=timestamp_ms)).split(\".\")[0]\n",
    " \n",
    "            # if f\"{tid}-{name_to_display}\" not in entry_log:\n",
    "            #     entry_log.add(f\"{tid}-{name_to_display}\")\n",
    "            #     if name_to_display != \"Unknown\" and name_to_display != \"No face\":\n",
    "            #         entry_data.append({\n",
    "            #             \"name\": name_to_display,\n",
    "            #             \"status\": \"entered\",\n",
    "            #             \"timestamp\": timestamp\n",
    "            #         })\n",
    "            #     elif name_to_display == \"Unknown\":\n",
    "            #         entry_data.append({\n",
    "            #             \"name\": \"Unknown\",\n",
    "            #             \"status\": \"unauthorized\",\n",
    "            #             \"timestamp\": timestamp\n",
    "            #         })\n",
    " \n",
    "  \n",
    " \n",
    "            if name_to_display == \"No face\":\n",
    "                color = (0, 255, 0)\n",
    "                label = f\"No face (ID:{tid})\"\n",
    "            elif name_to_display != \"Unknown\":\n",
    "                color = (255, 0, 0)\n",
    "                label = f\"{name_to_display} (ID:{tid})\"\n",
    "            else:\n",
    "                color = (0, 0, 255)\n",
    "                label = f\"Unknown (ID:{tid})\"\n",
    " \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    " \n",
    "    out.write(frame)\n",
    "    frame_count += 1\n",
    " \n",
    "cap.release()\n",
    "out.release()\n",
    " \n",
    "end_time = datetime.now(ist)\n",
    "print(\"End Time (IST):\", end_time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "print(\"Execution Time (seconds):\", execution_time)\n",
    "print(\"Execution Time (minutes):\", execution_time / 60)\n",
    "    \n",
    "with open(\"id_name_map.json\", \"w\") as f:\n",
    "    json.dump(id_name_map, f, indent=2)\n",
    " \n",
    "# with open(\"entry_log.json\", \"w\") as f:\n",
    "#     json.dump(entry_data, f, indent=2)\n",
    " \n",
    " \n",
    "print(f\"✅ Saved video, crops in 'id_frames/', id_name_map.json, and id_bboxes.json\")\n",
    "print(f\"Number of stored IDs: {len(id_bboxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37102c",
   "metadata": {},
   "source": [
    "to check the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e37901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Initialize face app\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\",providers=['CPUExecutionProvider'])\n",
    "face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "# Load image properly\n",
    "image_path = \"download (5).png\"\n",
    "img = cv2.imread(image_path)  # cv2 loads image as numpy array (BGR)\n",
    "\n",
    "# Run detection\n",
    "faces = face_app.get(img)\n",
    "if len(faces) > 0 and faces[0]['det_score'] > 0.55:\n",
    "    print(\"detected\")\n",
    "    emb = faces[0]['embedding'].astype('float32')\n",
    "print(\"no\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03b99b",
   "metadata": {},
   "source": [
    "just the yolo detections code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b105509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ---------------- Load YOLO model ----------------\n",
    "model = YOLO(\"yolov8l.pt\")   # Change to yolov8s.pt / yolov8m.pt / yolov8l.pt if needed\n",
    "\n",
    "# ---------------- Video Input/Output ----------------\n",
    "video_path = \"/content/nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"       # Input video\n",
    "output_path = \"output_annotated.mp4\"   # Output annotated video\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Video writer for saving output\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    \n",
    "    # Run YOLO inference\n",
    "    results = model(frame,classes=[0],conf=0.4,iou=0.7)\n",
    "\n",
    "    # Annotated frame\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Print bounding boxes\n",
    "    print(f\"Frame {frame_count}:\")\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = box.conf[0].cpu().numpy()\n",
    "        cls = int(box.cls[0].cpu().numpy())\n",
    "        print(f\"  Class: {cls}, Conf: {conf:.2f}, BBox: [{x1:.0f}, {y1:.0f}, {x2:.0f}, {y2:.0f}]\")\n",
    "\n",
    "    # Write annotated frame to output\n",
    "    frame_count += 1\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    # (Optional) show in real-time\n",
    "    # cv2.imshow(\"YOLO Annotated\", annotated_frame)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    #     break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Annotated video saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b70dbd8",
   "metadata": {},
   "source": [
    "only tracking code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a04498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "\n",
    "# Video input/output\n",
    "video_path = \"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "output_video = \"output_annotated.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_id = 0\n",
    "\n",
    "# Video writer setup\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))  # keep original fps\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "# Track unique IDs\n",
    "unique_ids = set()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        persist=True,\n",
    "        tracker=\"botsort.yaml\",  # ensure tracker config exists\n",
    "        classes=[0],   # only person\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    if results[0].boxes is not None:\n",
    "        print(f\"\\nFrame {frame_id}:\")\n",
    "        for box in results[0].boxes:\n",
    "            if box.id is not None:   # avoid None errors\n",
    "                tid = int(box.id[0])\n",
    "                unique_ids.add(tid)\n",
    "\n",
    "                # Bounding box coordinates\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "                # Print info\n",
    "                print(f\"  TrackID={tid}  BBox=({x1},{y1},{x2},{y2})\")\n",
    "\n",
    "                # Draw bounding box + ID\n",
    "                color = (0, 255, 0)\n",
    "                label = f\"ID: {tid}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    out.write(frame)\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"\\n✅ Done!\")\n",
    "print(\"Unique IDs:\", unique_ids)\n",
    "print(\"Total Unique IDs:\", len(unique_ids))\n",
    "print(f\"Annotated video saved as: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc92dea",
   "metadata": {},
   "source": [
    "Kalman filter + Hungarian matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb9b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import json\n",
    "\n",
    "class KalmanTracker:\n",
    "    \"\"\"Kalman Filter-based object tracker for person tracking\"\"\"\n",
    "\n",
    "    def __init__(self, initial_position, initial_box, track_id):\n",
    "        self.track_id = track_id\n",
    "        self.age = 0\n",
    "        self.total_visible_count = 1\n",
    "        self.consecutive_invisible_count = 0\n",
    "\n",
    "        # Ensure initial_position is a tuple of integers\n",
    "        if isinstance(initial_position, (list, np.ndarray)):\n",
    "            initial_position = (int(initial_position[0]), int(initial_position[1]))\n",
    "        \n",
    "        # Ensure initial_box is a list of integers\n",
    "        if isinstance(initial_box, np.ndarray):\n",
    "            initial_box = [int(x) for x in initial_box]\n",
    "        elif isinstance(initial_box, tuple):\n",
    "            initial_box = list(initial_box)\n",
    "\n",
    "        # Kalman filter setup\n",
    "        self.kf = cv2.KalmanFilter(4, 2)\n",
    "        self.kf.transitionMatrix = np.array([\n",
    "            [1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]\n",
    "        ], np.float32)\n",
    "        self.kf.measurementMatrix = np.array([\n",
    "            [1, 0, 0, 0], [0, 1, 0, 0]\n",
    "        ], np.float32)\n",
    "        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 10\n",
    "        self.kf.errorCovPost = np.eye(4, dtype=np.float32) * 100\n",
    "\n",
    "        self.kf.statePre = np.array([float(initial_position[0]), float(initial_position[1]), 0, 0], dtype=np.float32)\n",
    "        self.kf.statePost = self.kf.statePre.copy()\n",
    "\n",
    "        self.current_position = initial_position\n",
    "        self.predicted_position = initial_position\n",
    "        self.current_box = initial_box\n",
    "        self.trajectory = deque([initial_position], maxlen=50)\n",
    "        self.velocity_history = deque(maxlen=10)\n",
    "        self.box_history = deque([initial_box], maxlen=20)\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Predict next state\"\"\"\n",
    "        self.kf.predict()\n",
    "        predicted_state = self.kf.statePre\n",
    "        self.predicted_position = (int(predicted_state[0]), int(predicted_state[1]))\n",
    "        return self.predicted_position\n",
    "\n",
    "    def update(self, measurement_position, measurement_box=None):\n",
    "        \"\"\"Update with new measurement\"\"\"\n",
    "        if measurement_position is not None:\n",
    "            if isinstance(measurement_position, (list, np.ndarray)):\n",
    "                measurement_position = (float(measurement_position[0]), float(measurement_position[1]))\n",
    "            \n",
    "            measurement = np.array([[float(measurement_position[0])], [float(measurement_position[1])]], dtype=np.float32)\n",
    "            self.kf.correct(measurement)\n",
    "\n",
    "            self.current_position = (int(measurement_position[0]), int(measurement_position[1]))\n",
    "            \n",
    "            if measurement_box is not None:\n",
    "                if isinstance(measurement_box, np.ndarray):\n",
    "                    measurement_box = [int(x) for x in measurement_box]\n",
    "                elif isinstance(measurement_box, tuple):\n",
    "                    measurement_box = list(measurement_box)\n",
    "                \n",
    "                self.current_box = measurement_box\n",
    "                self.box_history.append(measurement_box)\n",
    "\n",
    "            self.trajectory.append(self.current_position)\n",
    "\n",
    "            if len(self.trajectory) >= 2:\n",
    "                prev_pos = self.trajectory[-2]\n",
    "                curr_pos = self.trajectory[-1]\n",
    "                velocity = (curr_pos[0] - prev_pos[0], curr_pos[1] - prev_pos[1])\n",
    "                self.velocity_history.append(velocity)\n",
    "\n",
    "            self.total_visible_count += 1\n",
    "            self.consecutive_invisible_count = 0\n",
    "        else:\n",
    "            self.consecutive_invisible_count += 1\n",
    "\n",
    "        self.age += 1\n",
    "\n",
    "    def get_current_position(self):\n",
    "        return self.current_position\n",
    "\n",
    "    def get_predicted_position(self):\n",
    "        return self.predicted_position\n",
    "\n",
    "    def get_velocity(self):\n",
    "        if len(self.velocity_history) == 0:\n",
    "            return (0, 0)\n",
    "        avg_vx = sum(v[0] for v in self.velocity_history) / len(self.velocity_history)\n",
    "        avg_vy = sum(v[1] for v in self.velocity_history) / len(self.velocity_history)\n",
    "        return (avg_vx, avg_vy)\n",
    "\n",
    "    def is_valid(self, max_invisible_count=15):\n",
    "        return self.consecutive_invisible_count <= max_invisible_count\n",
    "\n",
    "    def get_trajectory_points(self):\n",
    "        return list(self.trajectory)\n",
    "\n",
    "\n",
    "class PersonTracker:\n",
    "    \"\"\"Multi-person tracker using Kalman Filter and Hungarian algorithm\"\"\"\n",
    "\n",
    "    def __init__(self, max_disappeared=500, max_distance=250, min_hits=2):\n",
    "        self.max_disappeared = max_disappeared\n",
    "        self.max_distance = max_distance\n",
    "        self.min_hits = min_hits\n",
    "\n",
    "        self.tracks = []\n",
    "        self.next_track_id = 1\n",
    "\n",
    "    def create_track(self, position, box):\n",
    "        if isinstance(position, (list, np.ndarray)):\n",
    "            position = (int(position[0]), int(position[1]))\n",
    "        if isinstance(box, np.ndarray):\n",
    "            box = [int(x) for x in box]\n",
    "        elif isinstance(box, tuple):\n",
    "            box = list(box)\n",
    "        \n",
    "        track = KalmanTracker(position, box, self.next_track_id)\n",
    "        self.tracks.append(track)\n",
    "        self.next_track_id += 1\n",
    "        return track\n",
    "\n",
    "    def update(self, detections, boxes, confidences=None):\n",
    "        detection_points = [(int(d[0]), int(d[1])) for d in detections]\n",
    "        box_list = [[int(x) for x in b] if isinstance(b, (list, np.ndarray, tuple)) else b for b in boxes]\n",
    "        \n",
    "        for track in self.tracks:\n",
    "            track.predict()\n",
    "\n",
    "        if len(detection_points) == 0:\n",
    "            for track in self.tracks:\n",
    "                track.update(None)\n",
    "            self.tracks = [t for t in self.tracks if t.is_valid(self.max_disappeared)]\n",
    "            return self.get_confirmed_tracks()\n",
    "\n",
    "        if len(self.tracks) == 0:\n",
    "            for i, detection in enumerate(detection_points):\n",
    "                self.create_track(detection, box_list[i])\n",
    "            return self.get_confirmed_tracks()\n",
    "\n",
    "        predicted_positions = [track.get_predicted_position() for track in self.tracks]\n",
    "        cost_matrix = cdist(np.array(predicted_positions), np.array(detection_points), metric='euclidean')\n",
    "        cost_matrix[cost_matrix > self.max_distance] = 1e6\n",
    "\n",
    "        track_indices, detection_indices = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "        matched_detections = set()\n",
    "        for track_idx, det_idx in zip(track_indices, detection_indices):\n",
    "            if cost_matrix[track_idx, det_idx] < self.max_distance:\n",
    "                self.tracks[track_idx].update(detection_points[det_idx], box_list[det_idx])\n",
    "                matched_detections.add(det_idx)\n",
    "            else:\n",
    "                self.tracks[track_idx].update(None)\n",
    "\n",
    "        unmatched_tracks = set(range(len(self.tracks))) - set(track_indices)\n",
    "        for track_idx in unmatched_tracks:\n",
    "            self.tracks[track_idx].update(None)\n",
    "\n",
    "        unmatched_detections = set(range(len(detection_points))) - matched_detections\n",
    "        for det_idx in unmatched_detections:\n",
    "            self.create_track(detection_points[det_idx], box_list[det_idx])\n",
    "\n",
    "        self.tracks = [t for t in self.tracks if t.is_valid(self.max_disappeared)]\n",
    "        return self.get_confirmed_tracks()\n",
    "\n",
    "    def get_confirmed_tracks(self):\n",
    "        return {\n",
    "            track.track_id: {\n",
    "                'centroid': track.get_current_position(),\n",
    "                'box': track.current_box,\n",
    "                'trajectory': track.get_trajectory_points(),\n",
    "                'velocity': track.get_velocity(),\n",
    "                'age': track.age,\n",
    "                'hits': track.total_visible_count,\n",
    "                'confidence': min(track.total_visible_count / 10.0, 1.0)\n",
    "            }\n",
    "            for track in self.tracks if track.total_visible_count >= self.min_hits\n",
    "        }\n",
    "\n",
    "    def get_track_statistics(self):\n",
    "        total_tracks = len(self.tracks)\n",
    "        confirmed_tracks = len([t for t in self.tracks if t.total_visible_count >= self.min_hits])\n",
    "        active_tracks = len([t for t in self.tracks if t.consecutive_invisible_count == 0])\n",
    "        \n",
    "        return {\n",
    "            'total_tracks': total_tracks,\n",
    "            'confirmed_tracks': confirmed_tracks,\n",
    "            'active_tracks': active_tracks,\n",
    "            'next_id': self.next_track_id\n",
    "        }\n",
    "\n",
    "\n",
    "class PersonTrackingVisualizer:\n",
    "    \"\"\"Visualization utilities for person tracking\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.colors = [\n",
    "            (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
    "            (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
    "            (128, 0, 128), (255, 165, 0), (0, 128, 128), (128, 128, 0),\n",
    "        ]\n",
    "\n",
    "    def get_color_for_id(self, track_id):\n",
    "        return self.colors[track_id % len(self.colors)]\n",
    "\n",
    "    def draw_tracking_info(self, frame, tracked_objects, frame_num, total_frames):\n",
    "        for track_id, track_data in tracked_objects.items():\n",
    "            color = self.get_color_for_id(track_id)\n",
    "            box = track_data['box']\n",
    "            if len(box) >= 4:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "                confidence = track_data['confidence']\n",
    "                label = f\"Person {track_id} ({confidence:.2f})\"\n",
    "                (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w + 10, y1), color, -1)\n",
    "                cv2.putText(frame, label, (x1 + 5, y1 - 5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "                centroid = track_data['centroid']\n",
    "                cv2.circle(frame, (int(centroid[0]), int(centroid[1])), 4, color, -1)\n",
    "\n",
    "                trajectory = track_data['trajectory']\n",
    "                for i in range(1, len(trajectory)):\n",
    "                    pt1 = (int(trajectory[i-1][0]), int(trajectory[i-1][1]))\n",
    "                    pt2 = (int(trajectory[i][0]), int(trajectory[i][1]))\n",
    "                    cv2.line(frame, pt1, pt2, color, 2)\n",
    "\n",
    "        info_text = f\"Frame: {frame_num}/{total_frames} | Persons: {len(tracked_objects)}\"\n",
    "        cv2.rectangle(frame, (10, 10), (600, 40), (0, 0, 0), -1)\n",
    "        cv2.putText(frame, info_text, (15, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        return frame\n",
    "\n",
    "\n",
    "class PersonVideoTracker:\n",
    "    \"\"\"Main class for person tracking in videos\"\"\"\n",
    "\n",
    "    def __init__(self, model_path='yolov8l.pt', conf_threshold=0.5):\n",
    "        self.model_path = model_path\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.model = None\n",
    "        self.tracker = None\n",
    "        self.visualizer = PersonTrackingVisualizer()\n",
    "        self.tracking_data = []\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model is None:\n",
    "            self.model = YOLO(self.model_path)\n",
    "\n",
    "    def process_video(self, input_video_path, output_video_path=None, save_tracking_data=True):\n",
    "        self.load_model()\n",
    "        self.tracker = PersonTracker()\n",
    "        \n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise Exception(f\"Could not open video: {input_video_path}\")\n",
    "\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        out = None\n",
    "        if output_video_path:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "        frame_count = 0\n",
    "        start_time = time.time()\n",
    "        unique_person_ids = set()\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame_count += 1\n",
    "                results = self.model(frame, conf=self.conf_threshold, verbose=False)\n",
    "                \n",
    "                detections, boxes, confidences = [], [], []\n",
    "                if len(results) > 0:\n",
    "                    result = results[0]\n",
    "                    if hasattr(result, 'boxes') and result.boxes is not None and len(result.boxes) > 0:\n",
    "                        detected_boxes = result.boxes.xyxy.cpu().numpy()\n",
    "                        classes = result.boxes.cls.cpu().numpy()\n",
    "                        confs = result.boxes.conf.cpu().numpy()\n",
    "\n",
    "                        for box, cls_id, conf in zip(detected_boxes, classes, confs):\n",
    "                            if int(cls_id) == 0:\n",
    "                                box_coords = box.tolist()\n",
    "                                x1, y1, x2, y2 = map(int, box_coords)\n",
    "                                box_list = [x1, y1, x2, y2]\n",
    "\n",
    "                                center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                                detections.append(center)\n",
    "                                boxes.append(box_list)\n",
    "                                confidences.append(float(conf))\n",
    "\n",
    "                tracked_objects = self.tracker.update(detections, boxes, confidences)\n",
    "                unique_person_ids.update(tracked_objects.keys())\n",
    "\n",
    "                frame_data = {\n",
    "                    'frame': frame_count,\n",
    "                    'timestamp': frame_count / fps,\n",
    "                    'persons': {\n",
    "                        tid: {\n",
    "                            'box': t['box'],\n",
    "                            'centroid': t['centroid'],\n",
    "                            'confidence': t['confidence'],\n",
    "                            'velocity': t['velocity']\n",
    "                        }\n",
    "                        for tid, t in tracked_objects.items()\n",
    "                    }\n",
    "                }\n",
    "                self.tracking_data.append(frame_data)\n",
    "\n",
    "                annotated_frame = self.visualizer.draw_tracking_info(\n",
    "                    frame, tracked_objects, frame_count, total_frames\n",
    "                )\n",
    "                if out is not None:\n",
    "                    out.write(annotated_frame)\n",
    "\n",
    "        finally:\n",
    "            cap.release()\n",
    "            if out is not None:\n",
    "                out.release()\n",
    "\n",
    "        processing_time = time.time() - start_time\n",
    "        tracking_file = None\n",
    "        if save_tracking_data:\n",
    "            tracking_file = input_video_path.replace('.mp4', '_tracking_data.json')\n",
    "            self.save_tracking_data(tracking_file, unique_person_ids, processing_time)\n",
    "\n",
    "        return {\n",
    "            'processed_frames': frame_count,\n",
    "            'unique_persons': len(unique_person_ids),\n",
    "            'person_ids': sorted(list(unique_person_ids)),\n",
    "            'processing_time': processing_time,\n",
    "            'output_video': output_video_path,\n",
    "            'tracking_data_file': tracking_file\n",
    "        }\n",
    "\n",
    "    def save_tracking_data(self, filename, unique_ids, processing_time):\n",
    "        summary_data = {\n",
    "            'metadata': {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'model_path': self.model_path,\n",
    "                'confidence_threshold': self.conf_threshold,\n",
    "                'total_frames': len(self.tracking_data),\n",
    "                'unique_persons': len(unique_ids),\n",
    "                'person_ids': sorted(list(unique_ids)),\n",
    "                'processing_time': processing_time\n",
    "            },\n",
    "            'frame_data': self.tracking_data\n",
    "        }\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(summary_data, f, indent=2)\n",
    "\n",
    "\n",
    "def track_persons_in_video(input_video_path, output_video_path=None, model_path='yolov8l.pt', conf_threshold=0.5):\n",
    "    if output_video_path is None:\n",
    "        base_name = os.path.splitext(input_video_path)[0]\n",
    "        output_video_path = f\"{base_name}_tracked.mp4\"\n",
    "    \n",
    "    tracker = PersonVideoTracker(model_path=model_path, conf_threshold=conf_threshold)\n",
    "    results = tracker.process_video(input_video_path, output_video_path)\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_video = \"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "    output_video = \"output_tracked_video.mp4\"\n",
    "    \n",
    "    print(\"🚀 Starting person tracking...\")\n",
    "    try:\n",
    "        results = track_persons_in_video(\n",
    "            input_video_path=input_video,\n",
    "            output_video_path=output_video,\n",
    "            model_path='yolov8l.pt',\n",
    "            conf_threshold=0.5\n",
    "        )\n",
    "        print(f\"\\n🎉 Success! Results: {results}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac6e8f",
   "metadata": {},
   "source": [
    "Kalman filter + Hungarian matching with changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a41474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "import json\n",
    "\n",
    "\n",
    "class KalmanTracker:\n",
    "    \"\"\"Kalman Filter-based object tracker for person tracking\"\"\"\n",
    "\n",
    "    def __init__(self, initial_position, initial_box, track_id):\n",
    "        self.track_id = track_id\n",
    "        self.age = 0\n",
    "        self.total_visible_count = 1\n",
    "        self.consecutive_invisible_count = 0\n",
    "\n",
    "        if isinstance(initial_position, (list, np.ndarray)):\n",
    "            initial_position = (int(initial_position[0]), int(initial_position[1]))\n",
    "\n",
    "        if isinstance(initial_box, np.ndarray):\n",
    "            initial_box = [int(x) for x in initial_box]\n",
    "        elif isinstance(initial_box, tuple):\n",
    "            initial_box = list(initial_box)\n",
    "\n",
    "        # Kalman filter setup\n",
    "        self.kf = cv2.KalmanFilter(4, 2)\n",
    "        self.kf.transitionMatrix = np.array([\n",
    "            [1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]\n",
    "        ], np.float32)\n",
    "        self.kf.measurementMatrix = np.array([\n",
    "            [1, 0, 0, 0], [0, 1, 0, 0]\n",
    "        ], np.float32)\n",
    "        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 10\n",
    "        self.kf.errorCovPost = np.eye(4, dtype=np.float32) * 100\n",
    "\n",
    "        self.kf.statePre = np.array([float(initial_position[0]), float(initial_position[1]), 0, 0], dtype=np.float32)\n",
    "        self.kf.statePost = self.kf.statePre.copy()\n",
    "\n",
    "        self.current_position = initial_position\n",
    "        self.predicted_position = initial_position\n",
    "        self.current_box = initial_box\n",
    "        self.trajectory = deque([initial_position], maxlen=0)\n",
    "        self.velocity_history = deque(maxlen=10)\n",
    "        self.box_history = deque([initial_box], maxlen=20)\n",
    "\n",
    "    def predict(self):\n",
    "        self.kf.predict()\n",
    "        predicted_state = self.kf.statePre\n",
    "        self.predicted_position = (int(predicted_state[0]), int(predicted_state[1]))\n",
    "        return self.predicted_position\n",
    "\n",
    "    def update(self, measurement_position, measurement_box=None):\n",
    "        if measurement_position is not None:\n",
    "            if isinstance(measurement_position, (list, np.ndarray)):\n",
    "                measurement_position = (float(measurement_position[0]), float(measurement_position[1]))\n",
    "            measurement = np.array([[float(measurement_position[0])], [float(measurement_position[1])]], dtype=np.float32)\n",
    "            self.kf.correct(measurement)\n",
    "\n",
    "            self.current_position = (int(measurement_position[0]), int(measurement_position[1]))\n",
    "\n",
    "            if measurement_box is not None:\n",
    "                if isinstance(measurement_box, np.ndarray):\n",
    "                    measurement_box = [int(x) for x in measurement_box]\n",
    "                elif isinstance(measurement_box, tuple):\n",
    "                    measurement_box = list(measurement_box)\n",
    "                self.current_box = measurement_box\n",
    "                self.box_history.append(measurement_box)\n",
    "\n",
    "            self.trajectory.append(self.current_position)\n",
    "\n",
    "            if len(self.trajectory) >= 2:\n",
    "                prev_pos = self.trajectory[-2]\n",
    "                curr_pos = self.trajectory[-1]\n",
    "                velocity = (curr_pos[0] - prev_pos[0], curr_pos[1] - prev_pos[1])\n",
    "                self.velocity_history.append(velocity)\n",
    "\n",
    "            self.total_visible_count += 1\n",
    "            self.consecutive_invisible_count = 0\n",
    "        else:\n",
    "            self.consecutive_invisible_count += 1\n",
    "        self.age += 1\n",
    "\n",
    "    def get_current_position(self):\n",
    "        return self.current_position\n",
    "\n",
    "    def get_predicted_position(self):\n",
    "        return self.predicted_position\n",
    "\n",
    "    def get_velocity(self):\n",
    "        if len(self.velocity_history) == 0:\n",
    "            return (0, 0)\n",
    "        avg_vx = sum(v[0] for v in self.velocity_history) / len(self.velocity_history)\n",
    "        avg_vy = sum(v[1] for v in self.velocity_history) / len(self.velocity_history)\n",
    "        return (avg_vx, avg_vy)\n",
    "\n",
    "    def is_valid(self, max_invisible_count=10):\n",
    "        return self.consecutive_invisible_count <= max_invisible_count\n",
    "\n",
    "    def get_trajectory_points(self):\n",
    "        return list(self.trajectory)\n",
    "\n",
    "\n",
    "class PersonTracker:\n",
    "    \"\"\"Multi-person tracker using Kalman Filter and Hungarian algorithm\"\"\"\n",
    "\n",
    "    def __init__(self, max_disappeared=400, max_distance=200, min_hits=3):\n",
    "        self.max_disappeared = max_disappeared\n",
    "        self.max_distance = max_distance\n",
    "        self.min_hits = min_hits\n",
    "        self.tracks = []\n",
    "        self.next_track_id = 1\n",
    "\n",
    "    def create_track(self, position, box):\n",
    "        if isinstance(position, (list, np.ndarray)):\n",
    "            position = (int(position[0]), int(position[1]))\n",
    "        if isinstance(box, np.ndarray):\n",
    "            box = [int(x) for x in box]\n",
    "        elif isinstance(box, tuple):\n",
    "            box = list(box)\n",
    "        track = KalmanTracker(position, box, self.next_track_id)\n",
    "        self.tracks.append(track)\n",
    "        self.next_track_id += 1\n",
    "        return track\n",
    "\n",
    "    def update(self, detections, boxes, confidences=None):\n",
    "        detection_points = [(int(d[0]), int(d[1])) for d in detections]\n",
    "        box_list = [[int(x) for x in b] if isinstance(b, (list, np.ndarray, tuple)) else b for b in boxes]\n",
    "\n",
    "        for track in self.tracks:\n",
    "            track.predict()\n",
    "\n",
    "        if len(detection_points) == 0:\n",
    "            for track in self.tracks:\n",
    "                track.update(None)\n",
    "            self.tracks = [t for t in self.tracks if t.is_valid(self.max_disappeared)]\n",
    "            return self.get_confirmed_tracks()\n",
    "\n",
    "        if len(self.tracks) == 0:\n",
    "            for i, detection in enumerate(detection_points):\n",
    "                self.create_track(detection, box_list[i])\n",
    "            return self.get_confirmed_tracks()\n",
    "\n",
    "        predicted_positions = [track.get_predicted_position() for track in self.tracks]\n",
    "        cost_matrix = cdist(np.array(predicted_positions), np.array(detection_points), metric='euclidean')\n",
    "        cost_matrix[cost_matrix > self.max_distance] = 1e6\n",
    "\n",
    "        track_indices, detection_indices = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "        matched_detections = set()\n",
    "        for track_idx, det_idx in zip(track_indices, detection_indices):\n",
    "            if cost_matrix[track_idx, det_idx] < self.max_distance:\n",
    "                self.tracks[track_idx].update(detection_points[det_idx], box_list[det_idx])\n",
    "                matched_detections.add(det_idx)\n",
    "            else:\n",
    "                self.tracks[track_idx].update(None)\n",
    "\n",
    "        unmatched_tracks = set(range(len(self.tracks))) - set(track_indices)\n",
    "        for track_idx in unmatched_tracks:\n",
    "            self.tracks[track_idx].update(None)\n",
    "\n",
    "        unmatched_detections = set(range(len(detection_points))) - matched_detections\n",
    "        for det_idx in unmatched_detections:\n",
    "            self.create_track(detection_points[det_idx], box_list[det_idx])\n",
    "\n",
    "        self.tracks = [t for t in self.tracks if t.is_valid(self.max_disappeared)]\n",
    "        return self.get_confirmed_tracks()\n",
    "\n",
    "    def get_confirmed_tracks(self):\n",
    "        return {\n",
    "            track.track_id: {\n",
    "                'centroid': track.get_current_position(),\n",
    "                'box': track.current_box,\n",
    "                'trajectory': track.get_trajectory_points(),\n",
    "                'velocity': track.get_velocity(),\n",
    "                'age': track.age,\n",
    "                'hits': track.total_visible_count,\n",
    "                'confidence': min(track.total_visible_count / 10.0, 1.0)\n",
    "            }\n",
    "            for track in self.tracks if track.total_visible_count >= self.min_hits\n",
    "        }\n",
    "\n",
    "\n",
    "class PersonTrackingVisualizer:\n",
    "    \"\"\"Visualization utilities for person tracking\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.colors = [\n",
    "            (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
    "            (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
    "            (128, 0, 128), (255, 165, 0), (0, 128, 128), (128, 128, 0),\n",
    "        ]\n",
    "\n",
    "    def get_color_for_id(self, track_id):\n",
    "        return self.colors[track_id % len(self.colors)]\n",
    "\n",
    "    def draw_tracking_info(self, frame, tracked_objects, frame_num, total_frames):\n",
    "        for track_id, track_data in tracked_objects.items():\n",
    "            color = self.get_color_for_id(track_id)\n",
    "            box = track_data['box']\n",
    "            if len(box) >= 4:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "                confidence = track_data['confidence']\n",
    "                label = f\"Person {track_id} ({confidence:.2f})\"\n",
    "                (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                cv2.rectangle(frame, (x1, y1 - h - 10), (x1 + w + 10, y1), color, -1)\n",
    "                cv2.putText(frame, label, (x1 + 5, y1 - 5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "                centroid = track_data['centroid']\n",
    "                cv2.circle(frame, (int(centroid[0]), int(centroid[1])), 4, color, -1)\n",
    "\n",
    "                trajectory = track_data['trajectory']\n",
    "                for i in range(1, len(trajectory)):\n",
    "                    pt1 = (int(trajectory[i-1][0]), int(trajectory[i-1][1]))\n",
    "                    pt2 = (int(trajectory[i][0]), int(trajectory[i][1]))\n",
    "                    cv2.line(frame, pt1, pt2, color, 2)\n",
    "\n",
    "        info_text = f\"Frame: {frame_num}/{total_frames} | Persons: {len(tracked_objects)}\"\n",
    "        cv2.rectangle(frame, (10, 10), (600, 40), (0, 0, 0), -1)\n",
    "        cv2.putText(frame, info_text, (15, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        return frame\n",
    "\n",
    "\n",
    "class PersonVideoTracker:\n",
    "    \"\"\"Main class for person tracking in videos\"\"\"\n",
    "\n",
    "    def __init__(self, model_path='yolov8l.pt', conf_threshold=0.5):\n",
    "        self.model_path = model_path\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.model = None\n",
    "        self.tracker = None\n",
    "        self.visualizer = PersonTrackingVisualizer()\n",
    "        self.tracking_data = []\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model is None:\n",
    "            self.model = YOLO(self.model_path)\n",
    "\n",
    "    def process_video(self, input_video_path, output_video_path=None, save_tracking_data=True):\n",
    "        self.load_model()\n",
    "        self.tracker = PersonTracker()\n",
    "\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise Exception(f\"Could not open video: {input_video_path}\")\n",
    "\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        out = None\n",
    "        if output_video_path:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "        frame_count = 0\n",
    "        start_time = time.time()\n",
    "        total_yolo_time = 0.0\n",
    "        total_tracker_time = 0.0\n",
    "        annotation_time = 0.0\n",
    "        unique_person_ids = set()\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame_count += 1\n",
    "\n",
    "                # ---------- YOLO Inference ----------\n",
    "                t0 = time.time()\n",
    "                results = self.model(frame, conf=self.conf_threshold,iou=0.7, verbose=False)\n",
    "                total_yolo_time += time.time() - t0\n",
    "\n",
    "                detections, boxes, confidences = [], [], []\n",
    "                if len(results) > 0:\n",
    "                    result = results[0]\n",
    "                    if hasattr(result, 'boxes') and result.boxes is not None and len(result.boxes) > 0:\n",
    "                        detected_boxes = result.boxes.xyxy.cpu().numpy()\n",
    "                        classes = result.boxes.cls.cpu().numpy()\n",
    "                        confs = result.boxes.conf.cpu().numpy()\n",
    "\n",
    "                        for box, cls_id, conf in zip(detected_boxes, classes, confs):\n",
    "                            if int(cls_id) == 0:\n",
    "                                x1, y1, x2, y2 = map(int, box.tolist())\n",
    "                                box_list = [x1, y1, x2, y2]\n",
    "                                center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "\n",
    "                                detections.append(center)\n",
    "                                boxes.append(box_list)\n",
    "                                confidences.append(float(conf))\n",
    "\n",
    "                # ---------- Tracker Update ----------\n",
    "                t1 = time.time()\n",
    "                tracked_objects = self.tracker.update(detections, boxes, confidences)\n",
    "                total_tracker_time += time.time() - t1\n",
    "\n",
    "                unique_person_ids.update(tracked_objects.keys())\n",
    "\n",
    "                frame_data = {\n",
    "                    'frame': frame_count,\n",
    "                    'timestamp': frame_count / fps,\n",
    "                    'persons': {\n",
    "                        tid: {\n",
    "                            'box': t['box'],\n",
    "                            'centroid': t['centroid'],\n",
    "                            'confidence': t['confidence'],\n",
    "                            'velocity': t['velocity']\n",
    "                        }\n",
    "                        for tid, t in tracked_objects.items()\n",
    "                    }\n",
    "                }\n",
    "                self.tracking_data.append(frame_data)\n",
    "\n",
    "                # ---------- Annotation Time ----------\n",
    "                t2 = time.time()\n",
    "                annotated_frame = self.visualizer.draw_tracking_info(\n",
    "                    frame, tracked_objects, frame_count, total_frames\n",
    "                )\n",
    "                if out is not None:\n",
    "                    out.write(annotated_frame)\n",
    "                annotation_time += time.time() - t2\n",
    "                # -------------------------------------\n",
    "\n",
    "        finally:\n",
    "            cap.release()\n",
    "            if out is not None:\n",
    "                out.release()\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        tracking_file = None\n",
    "        if save_tracking_data:\n",
    "            tracking_file = input_video_path.replace('.mp4', '_tracking_data.json')\n",
    "            self.save_tracking_data(tracking_file, unique_person_ids, total_time)\n",
    "\n",
    "        def fmt(sec):\n",
    "            return f\"{sec:.2f} sec ({sec/60:.2f} min)\"\n",
    "\n",
    "        return {\n",
    "            'processed_frames': frame_count,\n",
    "            'unique_persons': len(unique_person_ids),\n",
    "            'person_ids': sorted(list(unique_person_ids)),\n",
    "            'total_execution_time': fmt(total_time),\n",
    "            'yolo_inference_time': fmt(total_yolo_time),\n",
    "            'tracker_update_time': fmt(total_tracker_time),\n",
    "            'annotation_time': fmt(annotation_time),\n",
    "            'output_video': output_video_path,\n",
    "            'tracking_data_file': tracking_file\n",
    "        }\n",
    "\n",
    "    def save_tracking_data(self, filename, unique_ids, processing_time):\n",
    "        summary_data = {\n",
    "            'metadata': {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'model_path': self.model_path,\n",
    "                'confidence_threshold': self.conf_threshold,\n",
    "                'total_frames': len(self.tracking_data),\n",
    "                'unique_persons': len(unique_ids),\n",
    "                'person_ids': sorted(list(unique_ids)),\n",
    "                'processing_time_sec': processing_time\n",
    "            },\n",
    "            'frame_data': self.tracking_data\n",
    "        }\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(summary_data, f, indent=2)\n",
    "\n",
    "\n",
    "def track_persons_in_video(input_video_path, output_video_path=None, model_path='yolov8l.pt', conf_threshold=0.5):\n",
    "    if output_video_path is None:\n",
    "        base_name = os.path.splitext(input_video_path)[0]\n",
    "        output_video_path = f\"{base_name}_tracked.mp4\"\n",
    "\n",
    "    tracker = PersonVideoTracker(model_path=model_path, conf_threshold=conf_threshold)\n",
    "    results = tracker.process_video(input_video_path, output_video_path)\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_video = \"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "    # input_video=\"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "    output_video = \"output_tracked_video.mp4\"\n",
    "\n",
    "    print(\"🚀 Starting person tracking...\")\n",
    "    try:\n",
    "        results = track_persons_in_video(\n",
    "            input_video_path=input_video,\n",
    "            output_video_path=output_video,\n",
    "            model_path='yolov8l.pt',\n",
    "            conf_threshold=0.5\n",
    "        )\n",
    "        print(f\"\\n🎉 Success! Results:\\n{json.dumps(results, indent=2)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0324cf",
   "metadata": {},
   "source": [
    "Kalman filter + hungarian matching with appearance embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df3601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import json\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Appearance feature utilities\n",
    "# ---------------------------\n",
    "\n",
    "def extract_appearance_feature(frame: np.ndarray, box: List[int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract a simple HSV 3D histogram feature (8x8x8 bins) from the bbox region.\n",
    "    Returns a L2-normalized 512-D float32 vector.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    h, w = frame.shape[:2]\n",
    "    # Clamp to image\n",
    "    x1 = max(0, min(x1, w - 1))\n",
    "    x2 = max(0, min(x2, w - 1))\n",
    "    y1 = max(0, min(y1, h - 1))\n",
    "    y2 = max(0, min(y2, h - 1))\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        # Fallback: whole frame (rare)\n",
    "        crop = frame\n",
    "    else:\n",
    "        crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "    if crop.size == 0:\n",
    "        crop = frame\n",
    "\n",
    "    hsv = cv2.cvtColor(crop, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2],\n",
    "                        None, [8, 8, 8],\n",
    "                        [0, 180, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist, hist).flatten().astype(np.float32)\n",
    "    # L2 normalize (normalize already does, but be safe)\n",
    "    norm = np.linalg.norm(hist) + 1e-12\n",
    "    hist = hist / norm\n",
    "    return hist  # shape (512,)\n",
    "\n",
    "\n",
    "def cosine_distance(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    1 - cosine similarity (bounded [0, 2]).\n",
    "    For normalized vectors it’s in [0, 2], but with our norm ~1 it's ~[0, 2].\n",
    "    Smaller is better.\n",
    "    \"\"\"\n",
    "    if a is None or b is None:\n",
    "        return 1.0\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b)) + 1e-12\n",
    "    return 1.0 - float(np.dot(a, b) / denom)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Kalman-based single track\n",
    "# ---------------------------\n",
    "\n",
    "class KalmanTracker:\n",
    "    \"\"\"Kalman Filter-based object tracker for person tracking\"\"\"\n",
    "\n",
    "    def __init__(self, initial_position, initial_box, track_id, appearance=None, appearance_momentum=0.9):\n",
    "        self.track_id = track_id\n",
    "        self.age = 0\n",
    "        self.total_visible_count = 1\n",
    "        self.consecutive_invisible_count = 0\n",
    "\n",
    "        # Appearance\n",
    "        self.appearance = appearance  # np.ndarray or None\n",
    "        self.appearance_momentum = float(appearance_momentum)  # EMA momentum in [0,1)\n",
    "\n",
    "        # Ensure initial_position is a tuple of integers\n",
    "        if isinstance(initial_position, (list, np.ndarray)):\n",
    "            initial_position = (int(initial_position[0]), int(initial_position[1]))\n",
    "        \n",
    "        # Ensure initial_box is a list of integers\n",
    "        if isinstance(initial_box, np.ndarray):\n",
    "            initial_box = [int(x) for x in initial_box]\n",
    "        elif isinstance(initial_box, tuple):\n",
    "            initial_box = list(initial_box)\n",
    "\n",
    "        # Kalman filter setup\n",
    "        self.kf = cv2.KalmanFilter(4, 2)\n",
    "        self.kf.transitionMatrix = np.array([\n",
    "            [1, 0, 1, 0],\n",
    "            [0, 1, 0, 1],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ], np.float32)\n",
    "        self.kf.measurementMatrix = np.array([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0]\n",
    "        ], np.float32)\n",
    "        # Tuned for quicker adaptation\n",
    "        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 1e-1\n",
    "        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 1.0\n",
    "        self.kf.errorCovPost = np.eye(4, dtype=np.float32) * 100\n",
    "\n",
    "        self.kf.statePre = np.array([float(initial_position[0]), float(initial_position[1]), 0, 0], dtype=np.float32)\n",
    "        self.kf.statePost = self.kf.statePre.copy()\n",
    "\n",
    "        self.current_position = initial_position\n",
    "        self.predicted_position = initial_position\n",
    "        self.current_box = initial_box\n",
    "        self.trajectory = deque([initial_position], maxlen=50)\n",
    "        self.velocity_history = deque(maxlen=10)\n",
    "        self.box_history = deque([initial_box], maxlen=20)\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Predict next state\"\"\"\n",
    "        self.kf.predict()\n",
    "        predicted_state = self.kf.statePre\n",
    "        self.predicted_position = (int(predicted_state[0]), int(predicted_state[1]))\n",
    "        return self.predicted_position\n",
    "\n",
    "    def update(self, measurement_position, measurement_box=None, appearance_feat=None):\n",
    "        \"\"\"Update with new measurement and (optionally) appearance feature\"\"\"\n",
    "        if measurement_position is not None:\n",
    "            if isinstance(measurement_position, (list, np.ndarray)):\n",
    "                measurement_position = (float(measurement_position[0]), float(measurement_position[1]))\n",
    "            \n",
    "            measurement = np.array([[float(measurement_position[0])],\n",
    "                                    [float(measurement_position[1])]], dtype=np.float32)\n",
    "            self.kf.correct(measurement)\n",
    "\n",
    "            self.current_position = (int(measurement_position[0]), int(measurement_position[1]))\n",
    "            \n",
    "            if measurement_box is not None:\n",
    "                if isinstance(measurement_box, np.ndarray):\n",
    "                    measurement_box = [int(x) for x in measurement_box]\n",
    "                elif isinstance(measurement_box, tuple):\n",
    "                    measurement_box = list(measurement_box)\n",
    "                \n",
    "                self.current_box = measurement_box\n",
    "                self.box_history.append(measurement_box)\n",
    "\n",
    "            # Update appearance with EMA if provided\n",
    "            if appearance_feat is not None:\n",
    "                if self.appearance is None:\n",
    "                    self.appearance = appearance_feat.copy()\n",
    "                else:\n",
    "                    m = self.appearance_momentum\n",
    "                    self.appearance = (m * self.appearance) + ((1.0 - m) * appearance_feat)\n",
    "                    # Re-normalize\n",
    "                    norm = np.linalg.norm(self.appearance) + 1e-12\n",
    "                    self.appearance = (self.appearance / norm).astype(np.float32)\n",
    "\n",
    "            self.trajectory.append(self.current_position)\n",
    "\n",
    "            if len(self.trajectory) >= 2:\n",
    "                prev_pos = self.trajectory[-2]\n",
    "                curr_pos = self.trajectory[-1]\n",
    "                velocity = (curr_pos[0] - prev_pos[0], curr_pos[1] - prev_pos[1])\n",
    "                self.velocity_history.append(velocity)\n",
    "\n",
    "            self.total_visible_count += 1\n",
    "            self.consecutive_invisible_count = 0\n",
    "        else:\n",
    "            self.consecutive_invisible_count += 1\n",
    "\n",
    "        self.age += 1\n",
    "\n",
    "    def get_current_position(self):\n",
    "        return self.current_position\n",
    "\n",
    "    def get_predicted_position(self):\n",
    "        return self.predicted_position\n",
    "\n",
    "    def get_velocity(self):\n",
    "        if len(self.velocity_history) == 0:\n",
    "            return (0, 0)\n",
    "        avg_vx = sum(v[0] for v in self.velocity_history) / len(self.velocity_history)\n",
    "        avg_vy = sum(v[1] for v in self.velocity_history) / len(self.velocity_history)\n",
    "        return (avg_vx, avg_vy)\n",
    "\n",
    "    def is_valid(self, max_invisible_count=15):\n",
    "        return self.consecutive_invisible_count <= max_invisible_count\n",
    "\n",
    "    def get_trajectory_points(self):\n",
    "        return list(self.trajectory)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Multi-target tracker\n",
    "# ---------------------------\n",
    "\n",
    "class PersonTracker:\n",
    "    \"\"\"Multi-person tracker using Kalman Filter + Hungarian with motion and appearance\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_disappeared=600,\n",
    "        max_distance=400,\n",
    "        min_hits=3,\n",
    "        w_motion=0.8,\n",
    "        w_appearance=0.5,\n",
    "        max_app_cost=0.5,     # stricter → fewer hijacks\n",
    "        appearance_momentum=0.9\n",
    "    \n",
    "    ):\n",
    "        self.max_disappeared = int(max_disappeared)\n",
    "        self.max_distance = float(max_distance)\n",
    "        self.min_hits = int(min_hits)\n",
    "\n",
    "        self.w_motion = float(w_motion)\n",
    "        self.w_appearance = float(w_appearance)\n",
    "        self.max_app_cost = float(max_app_cost)\n",
    "        self.appearance_momentum = float(appearance_momentum)\n",
    "\n",
    "        self.tracks: List[KalmanTracker] = []\n",
    "        self.next_track_id = 1\n",
    "\n",
    "    def create_track(self, position, box, appearance_feat=None):\n",
    "        if isinstance(position, (list, np.ndarray)):\n",
    "            position = (int(position[0]), int(position[1]))\n",
    "        if isinstance(box, np.ndarray):\n",
    "            box = [int(x) for x in box]\n",
    "        elif isinstance(box, tuple):\n",
    "            box = list(box)\n",
    "        \n",
    "        track = KalmanTracker(\n",
    "            position, box, self.next_track_id,\n",
    "            appearance=appearance_feat,\n",
    "            appearance_momentum=self.appearance_momentum\n",
    "        )\n",
    "        self.tracks.append(track)\n",
    "        self.next_track_id += 1\n",
    "        return track\n",
    "\n",
    "    def update(self, detections, boxes, confidences=None, appearance_feats=None):\n",
    "        \"\"\"\n",
    "        detections: list[(cx,cy)]\n",
    "        boxes: list[[x1,y1,x2,y2]]\n",
    "        confidences: optional list[float]\n",
    "        appearance_feats: list[np.ndarray] SAME ORDER as detections\n",
    "        \"\"\"\n",
    "        if appearance_feats is None:\n",
    "            appearance_feats = [None] * len(detections)\n",
    "\n",
    "        detection_points = [(int(d[0]), int(d[1])) for d in detections]\n",
    "        box_list = [[int(x) for x in b] if isinstance(b, (list, np.ndarray, tuple)) else b for b in boxes]\n",
    "        \n",
    "        # Predict all tracks\n",
    "        for track in self.tracks:\n",
    "            track.predict()\n",
    "\n",
    "        # No detections → age tracks and purge stale\n",
    "        if len(detection_points) == 0:\n",
    "            for track in self.tracks:\n",
    "                track.update(None)\n",
    "            self.tracks = [t for t in self.tracks if t.is_valid(self.max_disappeared)]\n",
    "            return self.get_confirmed_tracks()\n",
    "\n",
    "        # No existing tracks → start new ones\n",
    "        if len(self.tracks) == 0:\n",
    "            for i, detection in enumerate(detection_points):\n",
    "                self.create_track(detection, box_list[i], appearance_feats[i])\n",
    "            return self.get_confirmed_tracks()\n",
    "\n",
    "        # Build motion cost (Euclidean → normalized to [0,1] by max_distance)\n",
    "        predicted_positions = [track.get_predicted_position() for track in self.tracks]\n",
    "        motion_dists = cdist(np.array(predicted_positions, dtype=np.float32),\n",
    "                             np.array(detection_points, dtype=np.float32),\n",
    "                             metric='euclidean')\n",
    "        motion_cost = motion_dists / max(self.max_distance, 1e-6)\n",
    "        motion_cost = np.clip(motion_cost, 0.0, 1.0)\n",
    "\n",
    "        # Build appearance cost (cosine distance)\n",
    "        num_tracks = len(self.tracks)\n",
    "        num_dets = len(detection_points)\n",
    "        app_cost = np.zeros((num_tracks, num_dets), dtype=np.float32)\n",
    "\n",
    "        for ti, track in enumerate(self.tracks):\n",
    "            for di in range(num_dets):\n",
    "                det_feat = appearance_feats[di]\n",
    "                if track.appearance is None or det_feat is None:\n",
    "                    # Unknown appearance → neutral cost\n",
    "                    app_cost[ti, di] = 0.5\n",
    "                else:\n",
    "                    app_cost[ti, di] = float(cosine_distance(track.appearance, det_feat))\n",
    "        # Clip to [0, 2], then map to [0,1] by /2 (optional); we can keep original [0,2] and weight accordingly.\n",
    "        # To keep scales similar to motion_cost ~ [0,1], compress:\n",
    "        app_cost = np.clip(app_cost, 0.0, 2.0) / 2.0\n",
    "\n",
    "        # Combine\n",
    "        total_cost = (self.w_motion * motion_cost) + (self.w_appearance * app_cost)\n",
    "\n",
    "        # Hard gating: motion too far or appearance too dissimilar → disallow match\n",
    "        gated = total_cost.copy()\n",
    "        gated[motion_dists > self.max_distance] = 1e6\n",
    "        # Gate appearance *before* combining to be strict:\n",
    "        raw_app = (app_cost * 2.0)  # back to [0,2] for threshold\n",
    "        gated[raw_app > self.max_app_cost] = 1e6\n",
    "\n",
    "        # Hungarian assignment\n",
    "        track_indices, detection_indices = linear_sum_assignment(gated)\n",
    "\n",
    "        matched_detections = set()\n",
    "        for track_idx, det_idx in zip(track_indices, detection_indices):\n",
    "            if gated[track_idx, det_idx] < 1e5:\n",
    "                self.tracks[track_idx].update(\n",
    "                    detection_points[det_idx],\n",
    "                    box_list[det_idx],\n",
    "                    appearance_feat=appearance_feats[det_idx]\n",
    "                )\n",
    "                matched_detections.add(det_idx)\n",
    "            else:\n",
    "                # Rejected by gate\n",
    "                self.tracks[track_idx].update(None)\n",
    "\n",
    "        # Unmatched tracks\n",
    "        unmatched_tracks = set(range(len(self.tracks))) - set(track_indices)\n",
    "        for track_idx in unmatched_tracks:\n",
    "            self.tracks[track_idx].update(None)\n",
    "\n",
    "        # New tracks for unmatched detections\n",
    "        unmatched_detections = set(range(len(detection_points))) - matched_detections\n",
    "        for det_idx in unmatched_detections:\n",
    "            self.create_track(detection_points[det_idx], box_list[det_idx], appearance_feats[det_idx])\n",
    "\n",
    "        # Remove stale\n",
    "        self.tracks = [t for t in self.tracks if t.is_valid(self.max_disappeared)]\n",
    "        return self.get_confirmed_tracks()\n",
    "\n",
    "    def get_confirmed_tracks(self):\n",
    "        return {\n",
    "            track.track_id: {\n",
    "                'centroid': track.get_current_position(),\n",
    "                'box': track.current_box,\n",
    "                'trajectory': track.get_trajectory_points(),\n",
    "                'velocity': track.get_velocity(),\n",
    "                'age': track.age,\n",
    "                'hits': track.total_visible_count,\n",
    "                'confidence': min(track.total_visible_count / 10.0, 1.0)\n",
    "            }\n",
    "            for track in self.tracks if track.total_visible_count >= self.min_hits\n",
    "        }\n",
    "\n",
    "    def get_track_statistics(self):\n",
    "        total_tracks = len(self.tracks)\n",
    "        confirmed_tracks = len([t for t in self.tracks if t.total_visible_count >= self.min_hits])\n",
    "        active_tracks = len([t for t in self.tracks if t.consecutive_invisible_count == 0])\n",
    "        \n",
    "        return {\n",
    "            'total_tracks': total_tracks,\n",
    "            'confirmed_tracks': confirmed_tracks,\n",
    "            'active_tracks': active_tracks,\n",
    "            'next_id': self.next_track_id\n",
    "        }\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Visualization\n",
    "# ---------------------------\n",
    "\n",
    "class PersonTrackingVisualizer:\n",
    "    \"\"\"Visualization utilities for person tracking\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.colors = [\n",
    "            (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
    "            (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
    "            (128, 0, 128), (255, 165, 0), (0, 128, 128), (128, 128, 0),\n",
    "        ]\n",
    "\n",
    "    def get_color_for_id(self, track_id):\n",
    "        return self.colors[track_id % len(self.colors)]\n",
    "\n",
    "    def draw_tracking_info(self, frame, tracked_objects, frame_num, total_frames):\n",
    "        for track_id, track_data in tracked_objects.items():\n",
    "            color = self.get_color_for_id(track_id)\n",
    "            box = track_data['box']\n",
    "            if len(box) >= 4:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "                confidence = track_data['confidence']\n",
    "                label = f\"Person {track_id} ({confidence:.2f})\"\n",
    "                (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                y1_text = max(0, y1 - h - 10)\n",
    "                cv2.rectangle(frame, (x1, y1_text), (x1 + w + 10, y1_text + h + 10), color, -1)\n",
    "                cv2.putText(frame, label, (x1 + 5, y1_text + h + 5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "                centroid = track_data['centroid']\n",
    "                cv2.circle(frame, (int(centroid[0]), int(centroid[1])), 4, color, -1)\n",
    "\n",
    "                trajectory = track_data['trajectory']\n",
    "                for i in range(1, len(trajectory)):\n",
    "                    pt1 = (int(trajectory[i-1][0]), int(trajectory[i-1][1]))\n",
    "                    pt2 = (int(trajectory[i][0]), int(trajectory[i][1]))\n",
    "                    cv2.line(frame, pt1, pt2, color, 2)\n",
    "\n",
    "        info_text = f\"Frame: {frame_num}/{total_frames} | Persons: {len(tracked_objects)}\"\n",
    "        cv2.rectangle(frame, (10, 10), (600, 40), (0, 0, 0), -1)\n",
    "        cv2.putText(frame, info_text, (15, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        return frame\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Main video tracker\n",
    "# ---------------------------\n",
    "\n",
    "class PersonVideoTracker:\n",
    "    \"\"\"Main class for person tracking in videos\"\"\"\n",
    "\n",
    "    def __init__(self, model_path='yolov8l.pt', conf_threshold=0.5,\n",
    "                 tracker_kwargs: Optional[dict] = None):\n",
    "        self.model_path = model_path\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.model = None\n",
    "        self.tracker: Optional[PersonTracker] = None\n",
    "        self.visualizer = PersonTrackingVisualizer()\n",
    "        self.tracking_data = []\n",
    "        self.tracker_kwargs = tracker_kwargs or {}\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model is None:\n",
    "            self.model = YOLO(self.model_path)\n",
    "\n",
    "    def process_video(self, input_video_path, output_video_path=None, save_tracking_data=True):\n",
    "        self.load_model()\n",
    "        # You can tune weights/thresholds here\n",
    "        self.tracker = PersonTracker(**self.tracker_kwargs)\n",
    "        \n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise Exception(f\"Could not open video: {input_video_path}\")\n",
    "\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        out = None\n",
    "        if output_video_path:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "        frame_count = 0\n",
    "        unique_person_ids = set()\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame_count += 1\n",
    "                results = self.model(frame, conf=self.conf_threshold, verbose=False)\n",
    "                \n",
    "                detections, boxes, confidences, app_feats = [], [], [], []\n",
    "                if len(results) > 0:\n",
    "                    result = results[0]\n",
    "                    if hasattr(result, 'boxes') and result.boxes is not None and len(result.boxes) > 0:\n",
    "                        detected_boxes = result.boxes.xyxy.cpu().numpy()\n",
    "                        classes = result.boxes.cls.cpu().numpy()\n",
    "                        confs = result.boxes.conf.cpu().numpy()\n",
    "\n",
    "                        for box, cls_id, conf in zip(detected_boxes, classes, confs):\n",
    "                            if int(cls_id) == 0:  # person\n",
    "                                x1, y1, x2, y2 = map(int, box.tolist())\n",
    "                                box_list = [x1, y1, x2, y2]\n",
    "\n",
    "                                center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                                feat = extract_appearance_feature(frame, box_list)\n",
    "\n",
    "                                detections.append(center)\n",
    "                                boxes.append(box_list)\n",
    "                                confidences.append(float(conf))\n",
    "                                app_feats.append(feat)\n",
    "\n",
    "                tracked_objects = self.tracker.update(detections, boxes, confidences, appearance_feats=app_feats)\n",
    "                unique_person_ids.update(tracked_objects.keys())\n",
    "\n",
    "                frame_data = {\n",
    "                    'frame': frame_count,\n",
    "                    'timestamp': frame_count / fps,\n",
    "                    'persons': {\n",
    "                        tid: {\n",
    "                            'box': t['box'],\n",
    "                            'centroid': t['centroid'],\n",
    "                            'confidence': t['confidence'],\n",
    "                            'velocity': t['velocity']\n",
    "                        }\n",
    "                        for tid, t in tracked_objects.items()\n",
    "                    }\n",
    "                }\n",
    "                self.tracking_data.append(frame_data)\n",
    "\n",
    "                annotated_frame = self.visualizer.draw_tracking_info(\n",
    "                    frame, tracked_objects, frame_count, total_frames\n",
    "                )\n",
    "                if out is not None:\n",
    "                    out.write(annotated_frame)\n",
    "\n",
    "        finally:\n",
    "            cap.release()\n",
    "            if out is not None:\n",
    "                out.release()\n",
    "\n",
    "        processing_time = time.time() - start_time\n",
    "        tracking_file = None\n",
    "        if save_tracking_data:\n",
    "            tracking_file = input_video_path.replace('.mp4', '_tracking_data.json')\n",
    "            self.save_tracking_data(tracking_file, unique_person_ids, processing_time)\n",
    "\n",
    "        return {\n",
    "            'processed_frames': frame_count,\n",
    "            'unique_persons': len(unique_person_ids),\n",
    "            'person_ids': sorted(list(unique_person_ids)),\n",
    "            'processing_time': processing_time,\n",
    "            'output_video': output_video_path,\n",
    "            'tracking_data_file': tracking_file\n",
    "        }\n",
    "\n",
    "    def save_tracking_data(self, filename, unique_ids, processing_time):\n",
    "        summary_data = {\n",
    "            'metadata': {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'model_path': self.model_path,\n",
    "                'confidence_threshold': self.conf_threshold,\n",
    "                'total_frames': len(self.tracking_data),\n",
    "                'unique_persons': len(unique_ids),\n",
    "                'person_ids': sorted(list(unique_ids)),\n",
    "                'processing_time': processing_time\n",
    "            },\n",
    "            'frame_data': self.tracking_data\n",
    "        }\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(summary_data, f, indent=2)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Helper function\n",
    "# ---------------------------\n",
    "\n",
    "def track_persons_in_video(\n",
    "    input_video_path,\n",
    "    output_video_path=None,\n",
    "    model_path='yolov8l.pt',\n",
    "    conf_threshold=0.5,\n",
    "    tracker_kwargs: Optional[dict] = None\n",
    "):\n",
    "    if output_video_path is None:\n",
    "        base_name = os.path.splitext(input_video_path)[0]\n",
    "        output_video_path = f\"{base_name}_tracked.mp4\"\n",
    "    \n",
    "    tracker = PersonVideoTracker(\n",
    "        model_path=model_path,\n",
    "        conf_threshold=conf_threshold,\n",
    "        tracker_kwargs=tracker_kwargs\n",
    "    )\n",
    "    results = tracker.process_video(input_video_path, output_video_path)\n",
    "    return results\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # input_video = \"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "    input_video=\"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "    output_video = \"output_tracked_video.mp4\"\n",
    "    \n",
    "    print(\"🚀 Starting person tracking with appearance matching...\")\n",
    "    try:\n",
    "        results = track_persons_in_video(\n",
    "            input_video_path=input_video,\n",
    "            output_video_path=output_video,\n",
    "            model_path='yolov8l.pt',\n",
    "            conf_threshold=0.5,\n",
    "            tracker_kwargs=dict(\n",
    "                max_disappeared=600,   # was 600\n",
    "                max_distance=400,     # was 400\n",
    "                min_hits=3,\n",
    "                w_motion=0.8,\n",
    "                w_appearance=0.5,\n",
    "                max_app_cost=0.5,     # stricter → fewer hijacks\n",
    "                appearance_momentum=0.9\n",
    "            )\n",
    "        )\n",
    "        print(f\"\\n🎉 Success! Results: {results}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f0aa02",
   "metadata": {},
   "source": [
    "detection code only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d9dc02",
   "metadata": {},
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ------------------------------\n",
    "# Load YOLO model (trained for 2 classes)\n",
    "# ------------------------------\n",
    "model = YOLO(\"best_nano.pt\")  # Replace with your trained model path\n",
    "\n",
    "# ------------------------------\n",
    "# Video paths\n",
    "# ------------------------------\n",
    "input_video_path = \"gudivada_CP IP Cam_main_20250723112155_30sec (online-video-cutter.com).mp4\"\n",
    "output_video_path = \"output_labelled.mp4\"\n",
    "\n",
    "# ------------------------------\n",
    "# Open video\n",
    "# ------------------------------\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# ------------------------------\n",
    "# Process frames\n",
    "# ------------------------------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLO inference (returns list of results)\n",
    "    results = model(frame)[0]  \n",
    "\n",
    "    # Draw boxes\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "\n",
    "        # Optional: skip low-confidence detections\n",
    "        if conf < 0.3:\n",
    "            continue\n",
    "\n",
    "        label = f\"{model.names[cls]} {conf:.2f}\"\n",
    "        color = (255, 0, 0) if cls == 0 else (0, 0, 255)  # color per class\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # Write frame to output\n",
    "    out.write(frame)\n",
    "\n",
    "# ------------------------------\n",
    "# Release resources\n",
    "# ------------------------------\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Labelled video saved to:\", output_video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd10a7",
   "metadata": {},
   "source": [
    "detection + tracking "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde8c90",
   "metadata": {},
   "source": [
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ------------------------------\n",
    "# Load YOLO TensorRT model\n",
    "# ------------------------------\n",
    "# Export once (CLI): yolo export model=yolov8l.pt format=engine device=0 half=True\n",
    "# This creates yolov8l.engine (TensorRT optimized file)\n",
    "model = YOLO(\"yolov8l.onnx\")  # Load TensorRT-optimized model\n",
    "\n",
    "# ------------------------------\n",
    "# Video paths\n",
    "# ------------------------------\n",
    "input_video_path = \"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\"\n",
    "output_video_path = \"output_tracked_labelled.mp4\"\n",
    "\n",
    "# ------------------------------\n",
    "# Open video\n",
    "# ------------------------------\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit()\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# ------------------------------\n",
    "# Sets to store unique IDs\n",
    "# ------------------------------\n",
    "unique_person_ids = set()\n",
    "unique_face_ids = set()\n",
    "\n",
    "# ------------------------------\n",
    "# Process frames\n",
    "# ------------------------------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLO track on single frame\n",
    "    results = model.track(frame, tracker=\"botsort.yaml\", persist=True, verbose=False)\n",
    "\n",
    "    # The result is a list (batch=1), get first\n",
    "    result = results[0]\n",
    "\n",
    "    # Draw boxes\n",
    "    if hasattr(result, \"boxes\") and result.boxes is not None:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            \n",
    "            if conf < 0.3:\n",
    "                continue\n",
    "\n",
    "            # Both classes: display TID if exists\n",
    "            if hasattr(box, \"id\") and box.id is not None:\n",
    "                tid = int(box.id[0])\n",
    "                if cls == 0:  # person\n",
    "                    unique_person_ids.add(tid)\n",
    "                    label = f\"Person {tid} {conf:.2f}\"\n",
    "                    color = (255, 0, 0)\n",
    "                else:  # face or other class\n",
    "                    unique_face_ids.add(tid)\n",
    "                    label = f\"Face {tid} {conf:.2f}\"\n",
    "                    color = (0, 0, 255)\n",
    "            else:\n",
    "                label = f\"{model.names[cls]} {conf:.2f}\"\n",
    "                color = (0, 255, 0)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Tracked and labelled video saved to:\", output_video_path)\n",
    "print(\"Total unique person IDs:\", len(unique_person_ids))\n",
    "print(\"Total unique face IDs:\", len(unique_face_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972f2a48",
   "metadata": {},
   "source": [
    "face db index and names creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDB:\n",
    "    def __init__(self, db_path):\n",
    "        with open(db_path, \"rb\") as f:\n",
    "            face_db_list = pickle.load(f)\n",
    "        self.names, embeddings = zip(*face_db_list)\n",
    "        self.names = np.array(self.names)\n",
    "        embeddings = np.stack(embeddings).astype(\"float32\")\n",
    "\n",
    "        N, dim = len(embeddings), embeddings.shape[1]\n",
    "        nlist = max(1, min(N, int(4 * np.sqrt(N))))\n",
    "        nprobe = max(1, nlist // 4)\n",
    "\n",
    "        quantizer = faiss.IndexFlatIP(dim)\n",
    "        self.index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "        print(\"Training FAISS index...\")\n",
    "        self.index.train(embeddings)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        self.index.add(embeddings)\n",
    "        self.index.nprobe = nprobe\n",
    "\n",
    "        print(f\"--- FAISS Config: N={N}, dim={dim}, nlist={nlist}, nprobe={nprobe} ---\")\n",
    "\n",
    "# Load DB once\n",
    "face_db = FaceDB(\"face_database_gudivada.pkl\")\n",
    "print(face_db.index)\n",
    "print(face_db.names)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Suppose `face_db.names` is the array of names and `face_db.index` is the FAISS index\n",
    "# Save the FAISS index\n",
    "faiss.write_index(face_db.index, \"faiss_gudivada.index\")\n",
    "\n",
    "# Save the names\n",
    "with open(\"faiss_gudivadanames.pkl\", \"wb\") as f:\n",
    "    pickle.dump(face_db.names, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ceddb",
   "metadata": {},
   "source": [
    "code with sequential face execution and manual buffalo onnx models loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ultralytics import YOLO\n",
    "import json\n",
    "import pytz\n",
    "from collections import defaultdict\n",
    "import faiss\n",
    "import torch\n",
    "from ultralytics.engine.results import Boxes\n",
    "from ultralytics.trackers.bot_sort import BOTSORT\n",
    "from types import SimpleNamespace\n",
    "import time\n",
    "\n",
    "# # insightface ONNX models\n",
    "# from insightface.model_zoo import RetinaFace, ArcFaceONNX\n",
    "# from insightface.utils.face_align import Face\n",
    "\n",
    "\n",
    "class FaceReIDPipeline:\n",
    "    def __init__(self, video_path, db_path, output_path, yolo_model=\"yolov8l.pt\", sim_threshold=0.40):\n",
    "        # Config\n",
    "        self.ist = pytz.timezone(\"Asia/Kolkata\")\n",
    "        self.video_path = video_path\n",
    "        self.output_path = output_path\n",
    "        self.sim_threshold = sim_threshold\n",
    "\n",
    "        # ---------------- YOLO Detector ----------------\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = YOLO(yolo_model).to(self.device)\n",
    "\n",
    "        # ---------------- Tracker (BoT-SORT) ----------------\n",
    "        tracker_args = {\n",
    "            \"tracker_type\": \"botsort\",\n",
    "            \"track_high_thresh\": 0.5,\n",
    "            \"track_low_thresh\": 0.3,\n",
    "            \"new_track_thresh\": 0.5,\n",
    "            \"track_buffer\": 500,\n",
    "            \"match_thresh\": 0.95,\n",
    "            \"fuse_score\": True,\n",
    "            \"gmc_method\": None,\n",
    "            \"proximity_thresh\": 0.5,\n",
    "            \"appearance_thresh\": 0.8,\n",
    "            \"with_reid\": False,\n",
    "            \"model\": \"auto\"\n",
    "        }\n",
    "        args = SimpleNamespace(**tracker_args)\n",
    "        self.tracker = BOTSORT(args=args)\n",
    "\n",
    "        # ---------------- RetinaFace + ArcFace ----------------\n",
    "        self.detector = RetinaFace(model_file=\"/home/jovyan/.insightface/models/buffalo_l/det_10g.onnx\")\n",
    "        self.detector.prepare(ctx_id=0, input_size=(640, 640))\n",
    "\n",
    "        self.embedder = ArcFaceONNX(model_file=\"/home/jovyan/.insightface/models/buffalo_l/w600k_r50.onnx\")\n",
    "        self.embedder.prepare(ctx_id=0, input_size=(640, 640))\n",
    "\n",
    "        # Load DB + FAISS\n",
    "        self.names, self.index = self._load_faiss_index(db_path)\n",
    "\n",
    "        # Bookkeeping\n",
    "        self.id_name_map = {}\n",
    "        self.timing = defaultdict(float)\n",
    "        self.timing[\"retina_detect\"] = 0.0\n",
    "        self.timing[\"arcface_embed\"] = 0.0\n",
    "        self.timing[\"faiss_search\"] = 0.0\n",
    "\n",
    "    def _load_faiss_index(self, db_path):\n",
    "        with open(db_path, \"rb\") as f:\n",
    "            face_db_list = pickle.load(f)\n",
    "        names, embeddings = zip(*face_db_list)\n",
    "        names = np.array(names)\n",
    "        embeddings = np.stack(embeddings).astype(\"float32\")\n",
    "\n",
    "        N, dim = len(embeddings), embeddings.shape[1]\n",
    "        nlist = max(1, min(N, int(4 * np.sqrt(N))))\n",
    "        nprobe = max(1, nlist // 4)\n",
    "\n",
    "        quantizer = faiss.IndexFlatIP(dim)\n",
    "        index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "        print(\"Training FAISS index...\")\n",
    "        index.train(embeddings)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        index.add(embeddings)\n",
    "        index.nprobe = nprobe\n",
    "\n",
    "        print(f\"--- FAISS Config: N={N}, dim={dim}, nlist={nlist}, nprobe={nprobe} ---\")\n",
    "        return names, index\n",
    "\n",
    "    def _process_crop(self, tid, crop):\n",
    "        # RetinaFace detection\n",
    "        t0 = time.perf_counter()\n",
    "        bboxes, kpss = self.detector.detect(crop, input_size=(640, 640))\n",
    "        self.timing[\"retina_detect\"] += time.perf_counter() - t0\n",
    "\n",
    "        if bboxes is None or bboxes.shape[0] == 0:\n",
    "            return tid, \"No face\"\n",
    "\n",
    "        best_score, best_match = -1.0, \"Unknown\"\n",
    "        for i in range(bboxes.shape[0]):\n",
    "            bbox = bboxes[i, 0:4]\n",
    "            det_score = bboxes[i, 4]\n",
    "            kps = kpss[i] if kpss is not None else None\n",
    "\n",
    "            if det_score > 0.55:\n",
    "                face = Face(bbox=bbox, kps=kps, det_score=det_score)\n",
    "\n",
    "                # ArcFace embedding\n",
    "                t0 = time.perf_counter()\n",
    "                emb = self.embedder.get(crop, face).astype(\"float32\")\n",
    "                self.timing[\"arcface_embed\"] += time.perf_counter() - t0\n",
    "\n",
    "                # FAISS search\n",
    "                t0 = time.perf_counter()\n",
    "                faiss.normalize_L2(emb.reshape(1, -1))\n",
    "                scores, indices = self.index.search(emb.reshape(1, -1), 1)\n",
    "                self.timing[\"faiss_search\"] += time.perf_counter() - t0\n",
    "\n",
    "                score, idx = scores[0][0], indices[0][0]\n",
    "                match_name = self.names[idx].replace(\".jpg\", \"\")\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_match = match_name if score >= self.sim_threshold else \"Unknown\"\n",
    "\n",
    "        return tid, best_match\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(\"Error: Could not open video file.\")\n",
    "\n",
    "        width, height = int(cap.get(3)), int(cap.get(4))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        out = cv2.VideoWriter(\n",
    "            self.output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"XVID\"),\n",
    "            fps,\n",
    "            (width, height)\n",
    "        )\n",
    "\n",
    "        frame_idx = 0\n",
    "        start_time = time.perf_counter()\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            if frame_idx%4!=0:\n",
    "                frame_idx+=1\n",
    "                continue\n",
    "\n",
    "            # ---------------- YOLO Detection ----------------\n",
    "            results = self.model(frame, classes=[0], conf=0.4, iou=0.7, verbose=False)[0]\n",
    "            if results.boxes is None or len(results.boxes) == 0:\n",
    "                out.write(frame)\n",
    "                continue\n",
    "\n",
    "            # Convert YOLO boxes to tracker input\n",
    "            bboxes = results.boxes.xyxy.detach().cpu()\n",
    "            confs = results.boxes.conf.detach().cpu()\n",
    "            cls = results.boxes.cls.detach().cpu()\n",
    "            dets_tensor = torch.hstack([bboxes, confs.unsqueeze(1), cls.unsqueeze(1)])\n",
    "            dets = Boxes(dets_tensor, frame.shape[:2])\n",
    "\n",
    "            # ---------------- Tracker Update ----------------\n",
    "            tracks = self.tracker.update(dets, frame)\n",
    "\n",
    "            # ---------------- Sequential Face Recognition ----------------\n",
    "            for t in tracks:\n",
    "                x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                h = y2 - y1\n",
    "                face_crop = frame[y1:y1 + int(h * 0.5), x1:x2]  # top half crop\n",
    "                if face_crop.size:\n",
    "                    tid, name = self._process_crop(int(track_id), face_crop)\n",
    "                    if tid not in self.id_name_map:\n",
    "                        self.id_name_map[tid] = []\n",
    "                    self.id_name_map[tid].append(name)\n",
    "\n",
    "            # # ---------------- Draw and Write ----------------\n",
    "            # for t in tracks:\n",
    "            #     x1, y1, x2, y2, track_id, cls_id, conf = t[:7]\n",
    "            #     x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "            #     name = self.id_name_map.get(int(track_id), [\"No face\"])[-1]\n",
    "            #     color, label = self._get_color_label(name, track_id)\n",
    "            #     cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            #     cv2.putText(frame, label, (x1, y1 - 10),\n",
    "            #                 cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            # out.write(frame)\n",
    "            frame_idx += 1\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        end_time = time.perf_counter()\n",
    "        total_exec_time = end_time - start_time\n",
    "        self._finalize_results()\n",
    "        print(f\"Total Execution Time: {total_exec_time:.2f} seconds ({total_exec_time/60:.2f} minutes)\")\n",
    "\n",
    "    def _get_color_label(self, name, tid):\n",
    "        if name == \"No face\":\n",
    "            return (0, 255, 0), f\"No face (ID:{tid})\"\n",
    "        elif name != \"Unknown\":\n",
    "            return (255, 0, 0), f\"{name} (ID:{tid})\"\n",
    "        else:\n",
    "            return (0, 0, 255), f\"Unknown (ID:{tid})\"\n",
    "\n",
    "    def _finalize_results(self):\n",
    "        finalized = {}\n",
    "        for tid, names_list in self.id_name_map.items():\n",
    "            valid_names = [n for n in names_list if n not in [\"Unknown\", \"No face\"]]\n",
    "\n",
    "            if valid_names:\n",
    "                final_name = max(set(valid_names), key=valid_names.count)\n",
    "            else:\n",
    "                if \"Unknown\" in names_list:\n",
    "                    final_name = \"Unknown\"\n",
    "                else:\n",
    "                    final_name = \"No face\"\n",
    "\n",
    "            finalized[tid] = final_name\n",
    "\n",
    "        with open(\"id_name_map.json\", \"w\") as f:\n",
    "            json.dump(self.id_name_map, f, indent=2)\n",
    "        with open(\"finalized_id_name_map.json\", \"w\") as f:\n",
    "            json.dump(finalized, f, indent=2)\n",
    "\n",
    "        print(f\"Unique IDs: {len(finalized)}\")\n",
    "        unique_names = sorted({name for name in finalized.values() if name not in [\"Unknown\", \"No face\"]})\n",
    "\n",
    "        if unique_names:\n",
    "            print(\", \".join(unique_names))\n",
    "            print(f\"total persons detected: {len(unique_names)}\")\n",
    "        else:\n",
    "            print(\"No valid persons detected\")\n",
    "\n",
    "        print(\"===== Timing Summary =====\")\n",
    "        for k, v in self.timing.items():\n",
    "            print(f\"{k}: {v:.4f}s\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = FaceReIDPipeline(\n",
    "        video_path=\"nandyala_ch4_20250510145025_20250510145201 (online-video-cutter.com).mp4\",\n",
    "        db_path=\"face_database_nandhyala.pkl\",\n",
    "        output_path=\"gudivada-testing.avi\"\n",
    "    )\n",
    "    pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
